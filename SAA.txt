CLF 취득했으니 강의 섹션 3, 4, 5 & 12 는 패스

<공용 IP와 사설IP, 그리고 탄력적 IP>
- 공용 IP
ㄴ 공용 IP는 곧 기기가 인터넷상에서 식별될 수 있음을 의미
ㄴ 공용 IP는 고유해야됨
ㄴ 구글 검색을 통해 그 위치를 찾을 수 있음

- 사설 IP
ㄴ 사설 네트워크에서만 식별
ㄴ IP가 사설 네트워크 안에서만 유일하면됨
ㄴ 지정된 범위의 IP만 사설 IP로 사용가능

- 탄력적 IP
ㄴ EC2 인스턴스를 시작하고 중지할 때 공용 IP를 바꿀 수 있음
ㄴ IPv4 구조, 한번에 한 인스턴스에만 첨부할 수 있음
ㄴ 계정당 탄력적 IP를 5개 쓸 수 있음
ㄴ 결정적으로 탄력적 IP는 사용하지 않는게 좋음
    ㄴ 매우 좋지 않은 구조적 결정으로 종종 언급됨
    ㄴ 대신 임의의 공용 IP를 써서 DNS 이름을 할당하는 것이 좋음

특정 EC2 인스턴스에 Elastic IPs를 사용하여 인스턴스 실행동안 탄력적 IP 부여 가능 
인스턴스는 생성될 때마다 공용 IPv4 주소를 부여받는데,
종료 후 재실행 시 기존에 사용하던 것과는 다른 공용 IP 주소를 부여받게 된다.
이를 해결하기 위해 탄력적 IP 주소 할당을 시켜주는 것이고
이 탄력적 IP 주소 할당은 인스턴스와 네트워크 인터페이스에 할당할 수 있다.
탄력적 IP를 할당해 줄 경우 인스턴스의 종료 시작 여부에 상관없이 탄력적 IP 주소로 IP 주소가 고정된다.

<배치 그룹>
- 클러스터 배치 그룹
ㄴ 단일 가용 영역 내에서 지연 시간이 짧은 하드웨어 설정으로 인스턴스를 그룹화
ㄴ 높은 성능을 제공하지만 위험 또한 높음
ㄴ 모든 EC2 인스턴스가 동일한 가용영역에 존재
ㄴ 모든 인스턴스 간에 초당 약 10기가비트의 대역폭을 확보하여 향상된 네트워킹을 활성화
ㄴ 지연 시간이 짧고 처리량이 많은 네트워크를 확보
ㄴ 어떤 종류의 계산 작업에서도 뛰어난 성능을 얻을 수 있음
ㄴ 단점으론 가용 영역에 장애가 발생하면 모든 인스턴스가 동시에 장애를 일으킴

- 분산 배치 그룹 - EC2 인스턴스를 여러 AZ에 걸쳐 서로 다른 물리적 하드웨어에 배치
ㄴ 인스턴스가 다른 하드웨어에 분산된다는 의미
ㄴ 가용 영역별로 분산된 배치 그룹당 7개의 EC2 인스턴스만 가질 수 있다는 제한 사항이 있음
ㄴ 크리티컬 애플리케이션이 있는 경우 분산 배치 그룹을 사용
ㄴ 실패 위험을 최소화
ㄴ 모든 EC2 인스턴스가 다른 하드웨어에 위치함
ㄴ 여러 가용 영역에 걸쳐 있을 수 있으며 동시 실패의 위험이 감소
ㄴ 단점으론 가용 영역당 7개의 인스턴스로 제한됨
ex) 사용 사례는 가용성을 극대화 하고 위험을 줄여야 하는 애플리케이션

- 분할 배치 그룹
ㄴ 여러 파티션에 인스턴스가 분할되어 있고 이 파티션은 가용 영역 내의 다양한 하드웨어 랙 세트에 의존
ㄴ 즉 인스턴스가 여전히 분리되어 있지만 다른 실패로부터 격리되지 않음
ㄴ 하지만 다른 오류 파티션과 격리되어야 함
ㄴ 여러 가용 영역 파티션에 인스턴스를 분산 가능 
ㄴ 가용 영역당 최대 7개의 파티션 존재

<탄력적 네트워크 인터페이스(ENI)>
ㄴ VPC의 논리적 구성 요소이며 가상 네트워크 카드를 나타냄
ㄴ ENI는 EC2 인스턴스가 네트워크에 액세스 할 수 있게 해줌
ㄴ 각 ENI는 다음과 같은 속성을 가질 수 있음
    1. 주요 사설 IPv4와 하나 이상의 보조 IPv4를 가질 수 있음
    2. 각 ENI는 사설 IPv4당 탄력적 IPv4를 갖거나 혹은 하나의 공용 IPv4를 가질 수 있으므로 사설 및 공용 IP가
    한개씩 제공됨
    3. ENI에 하나 이상의 보안 그룹을 연결할 수 있음
    4. EC2 인스턴스와 독립적으로 ENI를 생성하고 즉시 연결하거나 장애 조치를 위해 EC2 인스턴스에서 이동시킬 수 있음
ㄴ ENI는 특정 가용 영역 즉 AZ에 바인딩됨
    즉 특정 AZ에서 ENI를 생성하면 해당 AZ에만 바인딩할 수 있음을

    -ENI 실습
    1. 인스턴스가 생성될 때 자동으로 ENI가 하나 생성됨, 인스턴스 생성 후 네트워크 탭의 아래쪽에 가보면
    연결된 ENI를 확인할 수 있음
    2. 왼쪽에 네트워크&시크릿 탭에 네트워크 인터페이스가 있는데 여기서 ENI를 관리할 수 있음
    3. 인스턴스 종료 시 인스턴스 생성 시에 만들어진 ENI는 삭제되지만 사용자가 직접 생성한
    ENI는 삭제되지 않음
    4. ENI를 직접 생성하면 프라이빗 IPv4 주소를 더 많이 활용할 수 있고 따라서 네트워킹 작업도 수월해짐
    ENI는 있어도 비용 발생x

<EC2 절전모드(Hibernate)>
ㄴ EC2 인스턴스가 절전모드가 되면 RAM에 있던 인 메모리 상태는 그대로 보존
ㄴ 인스턴스 부팅이 더 빨라짐    / 운영체제를 완전히 중지하거나 다시 시작하지 않고 그대로 멈춰두었으니까
ㄴ RAM에 기록되었던 인 메모리는 루트 경로의 EBS 볼륨에 기록되기 때문에 
    루트 EBS 볼륨을 암호화해야 하고 볼륨 용량도 RAM을 저장하기에 충분해야함
    (볼륨에 덤프된 데이터를 인스턴스 실행시 그대로 가져오기 때문)
ㄴ 모든 종류의 인스턴스에서 사용 가능
ㄴ 최대 60일까지 절전모드 사용 가능
ex) 오래 실행되는 프로세스를 갖고 있고 중지하지 않을 때, RAM 상태를 저장하고 싶을 때, 빠르게 재부팅하고 싶을때

사용중인 EC2 인스턴스의 상태를 절전모드로 변경하면 EC2 볼륨에 있던 모든 데이터를 EBS 볼륨에 저장함
EC2 인스턴스 운영체제 입장에선 운영체제를 종료한 것이 아니라 절전모드로 두었다가 도로 킨 것이기 때문에
인스턴스 uptime에도 가장 마지막에 인스턴스를 실행한 시간이 출력되는 것

<EBS 볼륨>
EBS 볼륨은 네트워크 USB 스틱(물리적인 드라이브x)
프리티어는 매달 30 GB SSD gp2 or gp3 사용 가능
네트워크로 연동되기에 다른 컴퓨터로 전송될 때 지연이 발생할 수 있음
다른 리전으로 볼륨을 옮기는 것은 불가능하지만 스냅샷을 이용하면 다른 가용 영역으로 볼륨을 옮길 수 있음
IOPS는 단위 초당 전송 수
하나의 인스턴스에 두개의 EBS 볼륨을 연결하는건 문제 없음
종료시 삭제 라는 기능이 있음
ㄴ EC2 인스턴스의 스토리지 오른쪽 끝에 보면 있음

EBS 스냅샷 아카이브와 EBS 스냅샷 휴지통
스냅샷 아카이브는 24~72시간 이내 복구 (즉시 복구x)
EBS 스냅샷 휴지통은 실주로 삭제하는 경우 복원 가능 기간은 1일~1년 사이
FSR(빠른 스냅샷 복원)은 스냅샷을 완전히 초기화 해 첫 사용하는것처럼 지연 시간을 없애는 기능
EC2 인스턴스를 초기화 할때 유용하지만 비용 ↑

<AMI>
EC2 인스턴스를 통해 만든 이미지
AMI에다 원하는 소프트웨어 또는 설정 파일 추가, 별도의 운영체제 설치, 모니터링 툴 추가
AMI는 아마존에서 재공하는 버전이 있고, 유저가 직접 추가해서 쓸 수도 있음
유저 데이터를 사용해 만드는 EC2 인스턴스는 최초 실행 시 약간의 시간을 기다려야함
EC2 인스턴스에 이미지 생성을 눌러 이미지를 만들면 좌측에 AMIs 옵션에 AMI 이미지가 등록됨

그 후에 인스턴스 생성 시에 퀵스타트는 내버려두고 my AMIs 탭으로 가면 내가 소유한 AMI를 기반으로 인스턴스 생성 가능

EC2 인스턴스 스토어는 I/O 성능 향상을 위해 활용 가능
인스턴스를 종료하면 날라가기 때문에 버퍼나 캐시, 스크래치 데이터 또는 임시 데이터 컨텐츠를 저장할때 사용하면 됨
인스턴스가 날아가면 데이터 손실 가능성도 있어서 데이터를 복제나 백업 해두는게 좋음

<EBS 볼륨 종류>
gp2 gp3
    ㄴ 성능과 균형 범용 SSD 볼륨
Io1과 Io2 Block Express
    ㄴ 가장 높은 성능의 SSD 볼륨 ex) 미션 크리티컬, 저지연, 고처리량 작업에 사용
    ㄴ 자주 액세스하고 처리량이 많은 작업을 위해 설계
SC1 볼륨
    ㄴ 가장 저렴한 HDD 볼륨
    ㄴ 액세스빈도가 낮은 작업을 위해 설계

<루팅 볼륨으로 사용 가능한 볼륨들>
gp2, gp3, Io1, Io2만 부팅 볼륨으로 사용 가능
gp2 : 최대 3000 IOP까지 제공, 볼륨의 크기는 IOP과 연관되어 있음, 최대 5334GB(16000 IOPS)까지 제공
gp3 : 기본적으로 3000 IOP와 초당 125MB 처리량 제공, 최대 16000 IOP와 초당 처리량 1GB까지 독립적으로 증가 가능

<프로비저닝된 IOPS 볼륨>
Io1 : 4TB~16TB까지 지원하며 최대 IOP를 프로비저닝 가능, 최대 IOP는 Nitro EC2 인스턴스의 경우 약 64000이고 다른 종류의 인스턴스는 32000,
      스토리지 크기와 별도로 프로비저닝된 IOPS를 늘릴 수 있음
Io2 Block Express : 4 GB ~ 64 TB 지원, 서브 밀리초 발생, IOPS : 기가 바이트비율 -> 1000:1, 최대 IOPS 256000
                    프로비저닝된 IOP 볼륨은 EBS 다중 연결 기능 지원
위 두 볼륨은 하나의 가용영역에 여러 EC2 인스턴스에 연결할 수 있는 다중 연결 기능 활성화
ex) 클러스터링된 Linux 애플리케이션, 애플리케이션에서 동시 쓰기 작업을 관리할 때
한번에 16개의 EC2 인스턴스만 같은 볼륨에 연결 가능
다중 연결을 사용하려면 클러스터 인식 파일 시스템을 사용해야함

EBS 다중 연결 : 동일한 EBS 볼륨을 동일한 AZ에 있는 다수의 EC2 인스턴스에 연결
ㄴ 쉽게 풀자면 동일 AZ에서 하나의 EBS가 여러 EC2 인스턴스에 연결 될 수 있다는 뜻
    여러 EC2 -> 하나의 EBS 볼륨 o / 여러 EBS 볼륨 -> EC2 인스턴스 x
ㄴ io1, io2만 가능 gp2(x)

<루팅 볼륨으로 사용할 수 없는 볼륨>
ST1(HDD)
ㄴ ex) 빅데이터, 데이터 웨어하우징, 로그 처리

SC1(Cold HDD)
ㄴ ex) 아카이브 데이터용(자주 액세스 되지 않는 데이터용)
ㄴ 최대 처리량은 초당 250MB, 최대 IOPS 250

<EBS 볼륨 암호화>
1. EBS 볼륨 생성(암호화x) -> 암호화가 되지 않았다면 생성하는 스냅샷도 암호화x
2. 스냅샷 복사할 때 동일 리전에 복사할 경우 아래쪽에 암호화 버튼이 생김, 활성화 시 스냅샷 암호화됨 이때 KMS 키도 선택
3. 방금 복사한 스냅샷에서 볼륨을 생성할 때 기초가 되는 스냅샷이 암호화되어 있어서 볼륨도 자동으로 암호화

암호화 되지 않은 스냅샷을 클릭해서 볼륨을 통해 새로운 스냅샷 생성하기 -> 동일 리전 시 EBS 볼륨 암호화 활성화, 키는 aws/ebs 키 선택

<EFS>
ex) 콘텐츠 관리, 웹 서빙, 데이터 공유, Wordpress
ㄴ 가격이 비쌈(gp2 EBS 볼륨의 약 3배)
ㄴ 내부적으로 NFS 프로토콜을 사용하며 EFS에 대한 액세스 제어를 하려면 보안 그룹 설정해야함
ㄴ KMS를 사용하여 EFS 드라이브에서 미사용 암호화 활성화
ㄴ 사용량에 따라 비용 청구(완벽한 종량제)
ㄴ EFS 스케일은 NFS 클라이언트 수천 개와 10GB 이상의 처리량 확보 + PB 규모의 네트워크 파일 시스템 자동 확장

성능 모드들이 존재
범용 - 기본값
ㄴ 지연 시간에 민감한 사용 사례에 사용됨
ex)웹서버, CMS

최대 I/O 모드 - 처리량 최대화
ㄴ 지연 시간이 더 긴 네트워크 파일 시스템이지만 처리량 높고 병렬성 높음
ex)빅데이터 애플리케이션, 미디어 처리

처리량 모드들
버스팅 - 초당 50MB~100MB 버스트 더한것 / 스토리지 양에 따른 처리량
프로비저닝 - 스토리지 크기에 관계없이 처리량 설정, 1TB의 스토리지에서 초당 1GB 처리 가능
엘라스틱(종량제) - 워크로드에 따라 처리량 자동으로 조절, 워크로드를 예측하기 어려울 때 유용

<EFS 스토리지 클래스>
스탠다드 - 자주 액세스 하는 파일을 위한 계층
EFS-IA - 자주 액세스 하지 않는 용도, 저장하면 비용 감소하지만 파일 검색 시 비용 발생, 
아카이브 - 거의 액세스 하지 않는 데이터용
수명 주기 정책 구현
스탠다드 - 다중AZ 설정있는 경우 스탠다드 권장, 재해 대비
원존(EFS One Zone-IA) - 개발만 하고 싶고 더 저렴한 옵션을 원한다면 권장, 하나의 AZ에 있고 백업은 기본적으로 활성화

일반 - 엘라스틱 모드 시엔 범용 모드만 선택 가능
프로비저닝과 버스팅 - Max I/O 모드 선택 가능(빅데이터 유형의 설정)
EC2 인스턴스 생성 시 서브넷을 EFS 보안그룹을 적용한 서브넷으로 선택하면 파일 시스템에서 EFS나 FSx를 선택 가능

<고가용성과 확장성>

확장성 : 애플리케이션 시스템이 조정을 통해 더 많은 양을 처리할 수 있다는 의미
확장성은 수직 / 수평 확장성이 있음

수직 확장성 : 인스턴스의 크기를 확장
ex) 능력치가 올라가는것(업그레이드), t2.micro -> t2.large로 만들기
수평 확장성 : 애플리케이션에서 인스턴스나 시스템의 수를 늘리는 방법
ex) 분배 시스템의 확장(증축)

고가용성 : 애플리케이션 또는 시스템을 적어도 둘 이상의 AWS의 AZ나 데이터 센터에 가동중이라는 걸 의미
고가용성의 목표는 데이터 센터에서의 손실에서 살아남는 것(가동시간을 손실 없이 최대로)

수직 확장은 업그레이드 / 수평 확장은 증축의 개념 
고가용성은 가동시간 없이 손실을 최소한으로 하기 위함

<로드 밸런싱>
로드 밸런서 : 서버 혹은 서버셋으로 트래픽을 백엔드나 다운스트림 EC2 인스턴스 또는 서버들로 전달하는 역할
ㄴ 여러 서버에 트래픽을 고르게 분산시켜서 시스템의 안정성과 성능을 높이기 위해
트래픽 분산, 가용성 향상, 확장성 확보, 빠른 응답 제공 등

**CLB는 AWS에서 지원하지 않으며 시험에도 안나옴**
클래식 로드 밸런서(2009년) V1 or CLB(Classic)
ㄴ HTTP, HTTPS, TCP, SSL와 secure TCP 지원

신형 로드 밸런서(2016년) ALB(Application)
ㄴ HTTP, HTTPS, WebSocket 프로토콜 지원

네트워크 로드 밸런서(2017년) NLB(Network)
ㄴ TCP, TLS, secure TCP와 UDP 프로토콜 지원

게이트웨이 로드 밸런서(2020년) GWLB(Gateway Load)
ㄴ 네트워크 층에서 작동하므로 3계층과 IP 프로토콜에서 작동

ALB - 7계층 즉 HTTP 전용 로드 밸런서
ㄴ HTTP/2와 WebSocket 지원
ㄴ 경로 라우팅 지원
ㄴ 도커와 아마존 ECS의 경우 ALB가 가장 적합함
    ㄴ 이유는 포트 매핑 기능이 있어 ECS 인스턴스의 동적 포트로의 리다이렉션을 가능하게 해줌
ㄴ IP 주소들의 앞에 위치할 수도 있음 단 꼭 사설 IP 주소여야만 함
ㄴ 접근하려는 URL에 ?Platform=Mobile인 경우엔 모바일 대상 그룹으로 리다이렉팅 되게 하고,
   ?Platform=Desktop인 경우엔 데스크탑 대상 그룹으로 리다이렉팅 시킬 수 있음 (모바일/데스크탑 화면의 차이)

보안 그룹을 통해 EC2 인스턴스에 오는 트래픽의 허용을 로드 밸런서를 통해서만 접근 가능하게 바꿀 수 있음
ALB -> 리스너 -> 리스너 세부정보 -> 아래쪽에 보면 리스너 규칙이 있는데 이 리스너 규칙을 통해 몇가지 규칙을 추가할 수 있음

NLB - 4계층 TCP/UDP 트래픽 처리
ㄴ 초당 수백만 건의 요청을 처리할 수 있음
ㄴ 지연시간 매우 짧음
ㄴ 가용 영역당 하나의 고정 IP만 가지고 있으며 각 가용 영역에 탄력적 IP를 할당할 수 있음
Q. 애플리케이션이 하나, 두개 또는 세 개의 다른 IP로만 접근할 수 있다면? A. NLB
ㄴ 극한의 성능, TCP 또는 UDP, 고정 IP
ㄴ ALB 앞에 NLB가 올 수 있음
    ㄴ 이렇게 하는 이유는 NLB를 통해 고정 IP 주소를 얻고, ALB를 통해 HTTP 유형의 트래픽에 처리하는 모든 규칙을 적용할 수 있기 때문
ㄴ NLB 타겟 그룹이 수행하는 상태 검사에는 TCP, HTTP, HTTPS 프로토콜을 지원함

GWLB - IP패킷의 네트워크인 3계층
ㄴ 모든 트래픽이 방화벽을 통과하게 하거나 침입 탐지 및 방지 시스템에 사용
ㄴ GWLB를 생성하면 VPC에서 라우팅 테이블이 업데이트됨
    ㄴ 이 라우팅 테이블이 수정되면 모든 사용자 트래픽은 GWLB를 통과
        ㄴ GWLB는 가상 어플라이언스의 대상 그룹 전반으로 트래픽을 확산 -> 모든 트래픽이 어플라이언스에 도달 -> 트래픽 분석&처리     (방화벽같은 과정)
            ㄴ 이상이 없다면 GWLB로 보내고 GWLB로 온 트래픽 -> 애플리케이션
ㄴ **GENEVE 프로토콜을 사용해 6081번 포트를 사용할것
    ㄴ GENEVE는 네트워크 가상화 터널링 프로토콜 / 트래픽을 가상의 캡슐로 감싸서 다른 네트워크 장비로 보내주는 역할
    ㄴ 6081번 포트는 GENEVE 기본 UDP 포트
    ex) 배달 음식으로 비유하자면 음식주문(GWLB) -> 포장(GENEVE 캡슐) -> 배달(UDP 6081번 포트) -> 고객이 배달음식 수령(최종 목적지(집)에서 포장지(GENEVE 캡슐화)를 열고 음식(트래픽)을 확인)

<스티키 세션>
ㄴ 클라이언트가 로드 밸런서에 두 번의 요청을 할 때 백엔드에서 동일한 인스턴스가 요청에 응답하도록 하는 것
ㄴ ALB, NLB에서 활성화 가능
ㄴ 세션 데이터를 잃지 않도록 하는 것

쿠키는 애플리케이션 쿠키 / 지속 시간 기반 쿠키
ㄴ 이 쿠키 이름이 CloudFront에 대해 이야기할 때 고려 사항
애플리케이션 쿠키
커스텀 쿠키 -  애플리케이션 자체에서 생성하는 사용자 정의 쿠키
    AWSLAB, AWSALBAPPOR 또는 AWSALBTG는 이미 ELB 자체에서 예약되어 사용되고 있기 때문에 이름 사용x
애플리케이션 쿠키 - 로드 밸런서 자체에서 생성, 이름은 AWSALBAPP

지속 기반 쿠키 (AWSALB)
ㄴ 로드밸런서에서 생성
ㄴ 특정 지속 시간에 따라 만료되며 그 지속 시간은 로드 밸런서 자체에서 생성

로드 밸런서 -> 타겟 그룹 -> 내 타겟 그룹 -> 액션(속성 편집) -> stickness 아래 스티키세션 설정 가능

교차 영역 밸런싱(Cross-Zone Load Balancing)
on : AZ에 있는 모든 인스턴스를 커다란 하나의 풀(pool)로 보고 트래픽을 균등하게 분배하는 방식
off : 각 AZ에 트래픽을 분배 후, AZ안의 인스턴스의 개수에 따라 트래픽 분배

ALB는 기본적으로 교차 영역 밸런싱이 on
ㄴ 일반적으로 AWS에선 다른 AZ로 데이터를 옮길 때 비용을 지불하지만 ALB는 교차 영역 밸런싱 디폴트값이 on 이기에 데이터 이동 비용 발생x

NLB와 GWLB는 기본적으로 교차 영역 밸런싱이 off
ㄴ 다른 AZ로 데이터를 옮길때 디폴트가 off 라서 교차 영역 밸런싱을 on으로 활성화 시킨 후에 사용해야하기에 데이터 이동 비용 발생

<SSL/TLS>
SSL 인증서는 클라이언트 <-> 로드 밸런서 트래픽이 전송중 암호화
ㄴ SSL은 '보안 소켓 계층'을 의미하고 연결을 암호화 하는데 사용
ㄴ 만료 날짜 존재, 주기적으로 갱신해줘야 함
TLS는 새로운 버전의 SSL, '전송 계층 보안'

HTTPS를 통해 접속 -> 로드 밸런서에서 내부적으로 SSL 종료 수행, 백엔드에서 HTTP <-> EC2 인스턴스 통신(암호화x) 하지만 VPC를 이용한 프라이빗 네트워크를 사용하기에 안전하게 보호됨
로드밸런서는 X.509 인증서 사용(SSL 또는 TLS 서버 인증서)
AWS에는 이 인증서들을 관리할 수 있는 ACM(Certicate Manager)
HTTP 리스너를 구성할 때 반드시 HTTPS 리스너로 해야함

SNI(Server Name Indication)
ㄴ 클라이언트가 서버에 접속할 때 접속하려고 하는 서버(도메인)를 알려주는 서비스
ㄴ 서버는 적절한 인증서를 선택해 클라이언트에게 제시

<오토 스케일링(ASG)>
ASG(Auto Scaling Group)
수요에 따라 EC2 인스턴스를 추가하거나 제거하는 것
ㄴ 로드 밸런서와 페어링 하는 경우 ASG에 속한 모든 EC2 인스턴스가 로드 밸런서에 연결됨
    ㄴ 추가로 ELB(Elastic Load Balancer)는 상태 확인을 통해 EC2 인스턴스의 상태를 확인하고 ASG로 전달 가능
        ㄴ 이로 인해 로드 밸런서가 비정상이라 판단하는 EC2 인스턴스를 종료할 수 있어 매우 편리
ㄴ 무료이며 EC2 인스턴스와 같은, 생성된 하위 리소스에 대한 비용만 청구
ㄴ 인스턴스의 최소~최대 개수를 설정하고 최대 용량 내에서 희망 최대 용량보다 높은 숫자를 설정하면 스케일 아웃이 됨 -> 즉 EC2 인스턴스 추가
ㄴ 시작 탬플릿을 통해 생성함
ㄴ ASG 생성시에 최대 용량(Max Capacity)를 넘어서는 희망 용량을 요청할 경우 인스턴스를 생성할 수 없음
    ex) 최대 용량이 5인 ASG에 희망 용량 6을 요청하면 인스턴스를 생성할 수 없기에 아무 일도 발생하지 않음

오토 스케일링 - 스케일링 정책
동적 스케일링
1. 목표 추적 스케일링(Target Tracking) - 원하는 수치의 점유율을 설정하고 ASG가 확장/축소를 통해 이 희망 점유율 수치를 유지하는것
2. 단순 단계 스케일링(Simple/Step) - ASG에 용량을 추가하거나 제거할 때 알림이 발생하도록 하는 것
3. 예약 스케일링(Scheduled) - 알려진 사용 패턴을 기반으로 스케일링을 예상
4. 예측 스케일링(Example) - 지속적인 부하를 예측한 다음 미리 예약을 시작

스케일링 쿨다운
ㄴ ASG이 인스턴스를 확장/축소한 직후 또 다른 스케일링 액션이 발생하지 않도록 일정 시간 기다리는 시간

<RDS + Aurora + ElastiCache>
ㄴ RDS는 SSH를 통한 인스턴스 접근x / RDS 인스턴스
ㄴ RDS는 스토리지 오토 스케일링
ㄴ RDS는 기저 운영 체제나 사용자 지정 기능에 액세스x
    ㄴ 그러나 RDS Custom은 가능

읽기 전용 복제본
ㄴ 읽기 전용 복제본 최대 15개 생성 가능하며 동일한 AZ 또는 리전에 걸쳐 생성됨
ㄴ 읽기 전용 복제본과 기본 DB 사이에는 비동기식 복제가 발생함
ㄴ 복제본을 DB로 승격시켜 이용할 수 있음, 그 후에 복제본은 복제 매커니즘 탈피, 하지만 자체적인 생애 주기 보유
ㄴ 읽기 복제본은 SELECT 문만 사용 가능 (INSERT, UPDATE, DELETE 사용불가)
ㄴ 가용 영역 간의 데이터 이동에는 비용이 발생하는데 RDS 복제본은 비용이 발생하지 않음
    ㄴ 이는 RDS가 관리형 서비스이기 때문에 복제 트래픽이 다른 가용 영역으로 넘어가도 비용 발생x
    ㄴ 하지만 다른 리전으로 복제할 경우 네트워크 비용에 대한 복제 비용 발생

다중 AZ - 재해 복구
ㄴ 동기식으로 가용 영역의 DB를 복제하여 마스터 DB의 모든 변화를 동기적으로 복제
ㄴ 하나의 DNS 이름으로 통신하여 마스터에 문제 발생 -> 백업용 동기식 DB 사용 으로 재해 복구
ㄴ 단일 AZ -> 다중 AZ 전환 가능하고 다운타임x

RDS Custom
ㄴ 지원하는 데이터베이스 유형은 Oracle, MSSQL
ㄴ 내부 설정 구성, 패치 적용 그리고 네이티브 기능 활성화 가능
ㄴ SSH 또는 SSM 세션 관리자를 사용하여 RDS 뒤에 있는 기저 EC2 인스턴스에 액세스 가능

RDS Vs RDS Custom
ㄴ RDS는 데이터베이스 전체를 관리, 운영체제와 나머지는 AWS에서 관리
ㄴ RDS Custom은 Oracle, MSSQL Server에서만 사용가능, 기저 운영 체제와 데이터베이스에 대한 관리자 권한 가짐
* 기저 운영 체제란? : DB가 설치되어 돌아가는 기반이 되는 운영체제 ex) Amazon RDS는 AWS가 관리하는 리눅스 기반 OS 위에서 실행됨

Aurora
ㄴ AWS 고유 기술(오픈소스x)
ㄴ postgres 및 MySQL과 호환됨
ㄴ Aurora 스토리지는 자동 확장(최대 128TB)
ㄴ 읽기 전용 복제본은 15개까지 만들 수 있음
ㄴ 다중 AZ나 RDS보다 재해 복구 속도가 훨씬 빠름
ㄴ 3개의 AZ에서 무언가를 기록할때마다 6개의 사본 저장
    ㄴ 쓰기에는 6개중 4개만 동작하면 ok / 읽기에는 6개중 3개만 동작하면 ok
        ㄴ> 가용성이 높다는 특징
ㄴ 일부 데이터가 손상되거나 문제가 있으면 백엔드에서 P2P 복제를 통한 자가복구
ㄴ 백트랙(BackTrack) : 데이터베이스를 과거의 특정 시점으로 빠르게 되돌리는 기능 ex) SQL 실수 취소, 반복 테스트, 임시 롤백 등
ㄴ 라이터(Writer) 엔드포인트 : DNS 이름으로 항상 마스터를 가르키는 것 ex) 장바구니 담기, 결제 등
ㄴ 장애 조치 후에도 클라이언트는 라이터 엔드포인트에 의해 올바른 인스턴스로 자동으로 리다이렉트됨
ㄴ 리더(Reader) 엔드포인트 : 모든 읽기 전용 복제본과 자동으로 연결됨(== 연결 로드 밸런싱에 도움이 됨) ex) 책 상세 페이지 조회 등
    ㄴ 세션 지속성이 없음
    ㄴ 쓰기 불가능 오로지 읽기만

RDS 백업
ㄴ 자동으로 매일 데이터베이스의 전체 백업을 수행
ㄴ 5분마다 트랜잭션 로그가 백업되기에 가장 빠른 백업은 5분 전의 백업
ㄴ 자동 백업 기간은 1~35일까지 설정 가능, 0일로 설정하면 자동 백업을 사용하지 않겠다는 의미
ㄴ 수동 DB스냅샷 기능도 있음, 수동으로 한 백업을 원하는 기간 동안 유지 가능
    ㄴ S3에 업로드된 백업 파일을 이용해 RDS 인스턴스에 데이터베이스 복원 가능

Aurora 백업
ㄴ 자동화된 백업 존재, 1~35일까지 설정 가능, 하지만 비활성화 불가능(RDS는 비활성화o)
ㄴ 백트랙 기능 존재 (원하는 시점으로 돌아가는 기능)
ㄴ 수동 DB 스냅샷 
    ㄴ Percona ExtraBackup을 통해 Aurora MySQL 클러스터에 백업 생성 -> S3에 저장(업로드) -> Aurora MySQL 클러스터에 복원 -> 복원 완료 후 데이터베이스 활성화(읽기/쓰기 접근 가능)
ㄴ COW(Copy-On-Write) 프로토콜을 이용한 복제
    * COW(Copy-On-Write)
        ㄴ 데이터 복제하는 시점에 변경 사항이 있으면 복사본 생성, 없으면 생성x (스냅샷과 비슷)
        ㄴ 원본 데이터에 변동 사항이 있을때 복사본을 생성해 사용하기에 파일 시스템, 가상 메모리, 데이터베이스, 컨테이너화된 환경(Docker) 등에 사용
        ㄴ 데이터 변경시마다 복사본을 생성하기에 쓰기 성능 저하, 복사본 개수↑ -> 저장 공간 차지하는 비율↑

RDS & Aurora 보안
ㄴ KMS를 사용해 마스터와 모든 복제본의 암호화, 첫 시작시 암호화 하지 않았다면 기존 DB, 읽기 전용 복제본의 암호화를 할 수 없음
ㄴ RDS 및 Aurora는 전송중 암호화 기능을 갖추고 있음 클라이언트는 데이터베이스에 액세스 하기 위해 대표적으로 아래 3가지 방법을 선택해서 사용
    ㄴ TLS 루트 인증서
    ㄴ IAM 역할
    ㄴ 보안 그룹
ㄴ SSH 액세스x
ㄴ 감사 로그를 활성화하면 RDS 및 Aurora에서 어떤 쿼리가 생성되고 있는지 데이터베이스를 확인할 수 있음
    ㄴ 로그를 장기간 보관하고 싶다면 AWS CloudWatch Logs에 전송하면됨

RDS 프록시
    * 프록시(Proxy)
        ㄴ중계 서버로 클라이언트와 서버 간의 중간에서 요청과 응답을 중계하는 역할을 함 ex) 보안, 성능 최적화, 접근 제어 등
        ㄴ 클라이언트의 요청을 직접 서버로 보내지 않고 요청을 대신 처리하여 결과를 반환하는 방식
            ㄴ 포워드(클라이언트) : 클라이언트 -> 프록시 서버 -> 외부 서버 순으로 통신 / 실사례로 기업 네트워크에서 직원들이 인터넷에 접근할 때 ex) 인터넷 필터링, 캐싱, 익명성 보호
            ㄴ 리버스(서버) : 서버 -> 리버스 프록시 서버 -> 클라이언트 / 웹서버가 여러개일 때 클라이언트가 어떤 서버에 연결하는지 알 수 없게 할 때 ex) 부하 분산, SSL 종료, 보안, 캐싱
            ㄴ VPN(가상 사설망) : 클라이언트 <-> 서버 간의 연결 암호화 ex) 원격 근무, 익명성 보호, 지역 우회 
ㄴ RDS 프록시를 사용하면 일일이 RDS DB 인스턴스에 연결하는 대신 프록시가 하나의 풀에 연결을 모아 RDS 인스턴스로 가는 연결이 줄어듬
ㄴ RDS 인스턴스에 연결이 많은 경우 CPU, RAM 등 데이터베이스 리소스의 부담을 줄여 데이터베이스 효율성 향상 및 개방된 연결과 시간초과를 최소화할 수 있기 때문
ㄴ 완전한 서버리스
ㄴ 오토스케일링을 통해 용량 관리 필요x 가용성↑
ㄴ 다중 AZ 지원
ㄴ 장애조치시 대기 인스턴스가 실행되며 장애 조치 시간을 66%까지 줄일 수 있음
    ㄴ 애플리케이션이 직접 처리하지 않고 RDS 프록시가 장애조치를 해 애플리케이션 상관x, 장애 조치 대응 부담↓
ㄴ IAM 인증을 강제함으로써 IAM 인증을 통해서만 DB에 액세스 가능
    ㄴ 이때 자격 증명은 AWS Secrets Manager 서비스로 함
ㄴ RDS는 퍼블릭 액세스가 절대 불가능한데 VPC 내에서만 액세스 가능함 그렇기에 보안이 훌륭한편

Amazon ElastiCache (를 이용한 검색 및 로그 분석용 Amazon OpenSearch도 있음)
ㄴ 관리형 Redis, Memcached 제공하여 캐시 기술을 활용할 수 있음
ㄴ 캐시 무효화를 사용자의 의도에 맞게 맞춤형으로 수정해서 쓸 수 있는 탬플릿 같은 기능
ㄴ 애플리케이션에서 쿼리문을 실행할 때 ElastiCache에 쿼리문이 저장된 경우 이를 캐시히트라고 하며 바로 ElastiCache에서 답을 얻어 수정함
   캐시 미스의 경우엔 데이터베이스에서 직접 데이터를 가져와야함
   RDS 데이터베이스에 부하를 줄이는 데 도움이 되지만 데이터를 캐시에 저장하기 때문에 항상 최신 데이터를 사용할 수 있도록 캐시 무효화 전략이 필요
ㄴ 사용자 로그인 상태 유지 시에도 ElastiCache를 사용해 세션을 가져옮으로 애플리케이션 상태 비저장으로 만들 수 있음

ElastiCache 보안
ㄴ Redis에서만 IAM 인증 지원, 나머지 경우엔 사용자 이름과 비밀번호 사용
ㄴ IAM 정책을 정의하면 AWS API 수준 보안만 적용
ㄴ Redis AUTH라는 Redis 내 보안을 통해 비밀번호 토큰 설정 가능
ㄴ SSL 전송중 암호화 지원
ㄴ Memcached는 SASL 기반 승인 제공 (이름만 기억)
ㄴ ElastiCache에 데이터를 로드하는 패턴 3가지
    1. 지연 로딩(Lazy Loading) : 모든 데이터가 캐시되고 데이터가 캐시에서 지체될 수 있음
    2. Write Through : DB에 데이터가 기록될 때마다 캐시에 데이터를 추가하거나 업데이트 하는 것
    3. Write Behind : 캐시에 먼저 쓰고, 일정 시간 뒤에 비동기적으로 DB에 반영하는 방식

<Route 53>
DNS amazon.com <- 에서 마지막 "."을 도메인 이름의 루트, .com은 TLD(최상위 도메인)
ㄴ 100% SLA 가용성을 제공하는 유일한 AWS 서비스
    *SLA 가용성 : 서비스가 정상적으로 운영되는 시간을 퍼센트로 표시한 서비스 신뢰성 보장 수치
ㄴ 레코드 종류로 A, AAAA, CNAME, NS 정도 알고 있으면 됨
    A : 호스트 이름과 IPv4 매핑 ex) example.com은 1.2.3.4에 연결
    AAAA : 호스트 이름을 IPv6에 매핑 ex) example.com은 2001:db8::1에 연결
    CNAME : 호스트 이름을 다른 호스트 이름과 매핑 ex) www.example.com -> example.com에 연결
    NS : 호스팅 존의 이름 서버 ex) example.com -> ns-123.awsdns-45.org
ㄴ 호스팅 존엔 두가지 종류가 있는데 퍼블릭과 프라이빗 호스팅 존이 존재
    퍼블릭 존 : 쿼리에 도메인 이름의 IP가 무엇인지 알 수 있음
    프라이빗 호스팅 존 : 공개되지 않은 도메인 이름 지원
        ㄴ 가상 프라이빗 클라우드(VPC)만이 URL을 리졸브 할 수 있음
    ㄴ 호스팅존은 월에 50센트를 지불해야함 (무료x)
ㄴ 도메인을 타사 등록 대행사에서 구매해도 DNS 서비스 제공자로 Route53을 사용 가능

TTL(Time To Live)
데이터나 정보가 얼마나 오래 유효한지를 정하는 시간 또는 횟수
ㄴ 정해둔 시간동안 컴퓨터에 캐시가 저장되어 값을 불러오는 방식으로 레코드의 값이 변경되어도 TTL의 시간이 만료되기 전까진 변경 전 값을 불러옴

CNAME과 Alias의 차이점
ㄴ CNAME은 루트 도메인이 아닌 경우, 호스트 A -> 호스트 B 지정 가능
ㄴ Alias는 호스트 이름 -> 특정 AWS 리소스 지정 가능(EC2 DNS 이름은 x), 무료, 자체적으로 확인 가능
ㄴ Alias는 루트 및 비루트 도메인에 모두 작동
ㄴ Alias 레코드를 사용하면 TTL 설정x (Route 53에 의해 자동으로 설정)
ㄴ Alias 레코드의 대상으로는 ELB, CloudFront, API Gateway, Elastic Beanstalk, 버킷이 웹사이트로 활성화시 S3(기본 S3는 x), Global Accelerator 등

Route53 라우팅
ㄴ 단순, 가중치 기반, 장애 조치 지연 시간 기반, 지리적, 다중 값 응답, 지리 근접 라우팅 정책
    1. 단순 라우팅 정책은 트래픽 -> 단일 리소스로 보내는 방식 foo.example.com으로 가고자 한다면 Route53이 IP 주소를 알려줌(=A 레코드)
       DNS에 의해 여러 개의 값을 받은 경우엔 클라이언트 쪽에서 그 중 하나를 무작위로 고르게됨
       Alias 레코드를 함께 사용하면 하나의 AWS 리소스만을 대상으로 지정 가능
       간단하기에 단순 정책, 그렇기에 상태 확인x
    2. 가중치 라우팅 정책 -> 가중치를 활용해 요청의 일부 비율을 특정 리소스로 보내는 식의 제어가 가능
       서로 다른 지역에 로드밸런싱 할때나 적은 양의 트래픽을 보내 새 어플리케이션을 테스트 하는 경우 사용
       A B C 인스턴스가 있을 때 A 70%, B 20%, C 10%로 트래픽을 보내고 싶을때 사용(가중치의 합이 100이 아니여도 ok)
    3. 지연 시간 기반 라우팅 정책 -> 지연 시간(레코드로 가장 가까운 식별된 AWS 리전에 연결하기까지 걸리는 시간)이 가장 짧은 즉 가장 가까운 리소스로 리다이렉팅 하는 정책
       지연 시간에 민감한 웹사이트나 애플리케이션이 있는 경우 유용함
    4. 장애 조치 라우팅 정책 -> 기본과 보조 유형의 레코드 타입을 선택해 기본 레코드에서 장애 발생시 보조 레코드에서 장애 조치
    5. 지리적 위치 라우팅 정책 -> 사용자의 실제 위치에 따라 특정 리전으로 트래픽을 보내는 방식 ex) 지역별로 다른 콘텐츠나 서비스를 제공하고 싶을 때 사용(넷플릭스)
    6. 지리 근접 라우팅 정책 -> 사용자의 위치와 서버 리전 사이의 물리적 거리를 계산해서 가까운 리전(or 서버)으로 보내는 방식 ex) 금융앱, 쇼핑몰 서비스(쿠팡, 마켓컬리), 영상 스트리밍
       bias를 이용한 가중치 값을 조절해 특정 리전으로 트래픽을 의도적으로 보낼 수 있음 ex) 서울과 부산 서버가 있는데 서울 서버가 더 고사양이라 더 많은 트래픽을 서울로 보내고 싶을 때
    7. IP 주소 기반(CIDR) 라우팅 정책 -> 사용자의 IP 주소 범위를 기준으로 특정 응답을 보내도록 설정
    8. 다중 값 라우팅 정책 -> 트래픽을 다중 리소스로 라우팅 할 때 사용

Route53 상태확인
공용 리소스에 대한 상태를 확인하는 방법, 개인 리소스 확인하는 방법 또한 존재
ㄴ 엔드포인트 모니터링
    ㄴ 전 세계에서 온 15개의 상태 확인이 엔드포인트의 상태를 확인하고 임계값을 정상 or 비정상으로 설정 (HTTP, HTTPS, TCP 등 많은 프로토콜을 지원)
    ㄴ 18% 이상의 상태 확인이 정상이라 판단 -> 정상, 그렇지 않다면 비정상
    ㄴ 위치도 선택 가능
    ㄴ 로드밸런서로부터 2xx나 3xx의 코드를 받아야만 통과
    ㄴ 텍스트 기반 응답일 경우 첫 응답에 5120 바이트를 확인
    ㄴ 네트워크 관점에서 상태 확인 작동 여부를 확인하려면 ALB나 엔드포인트에 접근이 가능해야함 => Route53의 상태 확인 IP 주소 범위에서 들어오는 모든 요청을 허용해야 함(비공개 VPC 엔드포인트나 EC2 웹서버라면 보안 그룹을 열어줘야함)
ㄴ 계산된 상태 확인(Calculated Health Check), 계산된 상태 확인이란 여러 상태 확인 결과를 종합해 최종적으로 살아있는지 판단하는 기능
    여러 상태 확인의 결과를 OR, AND, NOT으로 조합해 최종 상태를 판단함
ㄴ 개인 리소스 상태 확인(Private Hosted Zone)
    ㄴ Route53의 상태 확인이 공용 웹에 존재하기에 VPC 외부에 위치 -> 개인 엔드 포인트 접근x
    ㄴ 그렇기에 CloudWatch 지표를 만들어 CloudWatch 알람을 할당, ALARM 모드 일 때 Route53이 비정상이라 간주하고 트래픽 차단

<Elastic Beanstalk>
용량 프로비저닝, LB 구성, 자동 확장, 애플리케이션 안정성 모니터링과 인스턴스 구성 등을 자동으로 처리해주는 관리형 서비스
ㄴ Elastic Beanstalk 서비스는 무료지만 사용하는 인스턴스나 ASG, ELB 등에 대한 비용은 청구
ㄴ 개발, 테스트, 프로덕션 등의 여러 애플리케이션을 생성 가능
ㄴ 환경 내에서는 하나의 버전만 사용 가능, 환경 내에서 버전 업그레이드 가능
ㄴ 버전 업로드하고 애플리케이션 환경 시작 -> 애플리케이션 생애 주기 관리 가능
ㄴ 개발 목적에 적합한 단일 인스턴스 ex) 개인 개발용 웹앱, 기능 테스트 중인 프로토타입
    ㄴ 탄력적 IP를 가진 EC2 인스턴스, ASG, LB 없음
    ㄴ RDS 사용 가능
ㄴ 운영(프로덕션) 환경에 적합한 로드 밸런서 + 오토스케일링 환경 ex) 다수의 사용자가 접속하는 실서비스(이커머스, 동영상 플랫폼 등), 장애에 민감한 기업용 웹 애플리케이션
    ㄴ ELB를 통한 트래픽 분산
    ㄴ ASG로 인스턴스수 수 자동 조정
    ㄴ Multi AZ RDS 구성
    ㄴ 여러 가용 영역에 인스턴스 배치 -> 고가용성 확보

<고급 S3>
수명 주기 규칙(Lifecycle rules)
ㄴ Transition Actions / 객체를 다른 스토리지 클래스로 자동 전환시키는 작업 ex) 저장 비용 최적화, 자주 접근하지 않는 데이터를 더 저렴한 스토리지로 옮기기 위함
ㄴ Expiration Actions / 설정된 시간 이후에 객체를 자동 삭제하는 작업
    ㄴ 업로드 후 365일이 지난 객체 자동 삭제, 특정 태그가 달린 객체만 90일 후 삭제
    ㄴ 모든 파일 버전을 삭제 -> 이걸 이용하면 불완전한 멀티파트 업로드도 삭제 가능(업로드가 2주 이상 된 경우에도 완료되지 않은 경우 삭제 가능)
    ㄴ 버전 관리가 활성화 된 경우 delete marker, non-currrent version에 대한 만료도 설정 가능

S3 요청자 지불(S3 Requester Pays)
일반적으로 S3 스토리지 및 데이터 전송 비용을 버킷 소유자가 지불하였음, 그러나 대형 파일의 경우엔 이야기가 다름 
ㄴ 대형 파일이 있고 일부 고객이 이를 다운로드 하고자 할 때 버킷 소유자가 아닌 요청자가 객체 데이터 다운로드 비용 지불
ㄴ 대량의 데이터셋을 공유하려고 할 때 사용함
    ㄴ 요청자는 익명x AWS에서 인증을 받아야 함

S3 이벤트 알림
객체가 생성, 삭제, 복구, 복제 등 객체 상태에 변화가 생겼을 때 이벤트가 발생했다고 하고 이를 필터링 할 수 있음
ㄴ 이벤트 알림이 작동하려면 IAM 권한을 갖고 있어야 함
ㄴ 추가 서비스(SNS, SQS, 람다)를 사용해서 이벤트 알림을 설정해도 이벤트는 S3 버킷으로 감 -> 모든 이벤트는 Amazon EventBridge를 통함

S3 퍼포먼스
ㄴ 100MB가 넘는 파일에는 멀티파트 업로드를 사용하는 것이 좋음, 5GB가 넘어갈 시 반드시 사용해야함
    ㄴ 멀티파트 업로드는 업로드를 병렬화 -> 전송속도↑ -> 대역폭 최대화
ㄴ S3 전송 가속은 파일을 AWS 엣지 위치로 전송 => 전송속도↑
        *엣지 위치 : 데이터 전송 지점
    ㄴ 전송 가속은 공공 인터넷의 사용량을 최소화하고 프라이빗 AWS 네트워크의 사용량을 최대화

S3 바이트
파일의 특정 바이트 범위를 가져와 가져오기를 병렬화 하는 것
ㄴ 특정 바이트 범위를 가져오는데 실패한 경우 더 작은 바이트 범위를 다시 시도할 수 있음
ㄴ 실패시 복원력 향상 -> 다운로드 속도를 높이는데 사용

S3 Batch Operations
단일 요청으로 기존 S3 객체에서 대량 작업을 수행하는 서비스
ㄴ S3 버킷 내 암호화되지 않은 모든 객체를 암호화할 수 있음
ㄴ ACL이나 태그를 수정하지 않고 S3 Glacier에서 한 번에 많은 객체를 복원할 수 있음
ㄴ 람다 함수를 호출해 S3 Batch Operations의 모든 객체에서 사용자 지정 작업을 수행할 수 있음
ㄴ 객체 작업에서 원하는 작업은 무엇이든지 수행할 수 있음
ㄴ 직접 하지 않고 Batch Operations을 쓰느냐?
    ㄴ 재시도를 관리할 수 있고
    ㄴ 진행 상황을 추적하고 작업 완료 알림을 보내고 보고서 생성 등을 할 수 있음
ㄴ S3 Inventory라는 기능을 사용해 객체 목록을 가져오고 S3 Select를 사용해 객체를 필터링함
ㄴ 주요 사용 사례는 S3 Inventory를 사용해 암호화되지 않은 모든 객체를 찾아 S3 Batch Operations를 사용해 한번에 모두 암호화 하는 것

S3 스토리지 렌즈(Storage Lens)
S3 사용량 및 스토리지 상태를 시각적으로 분석, 비용 최적화 및 성능 개선을 위한 인사이트를 제공하는 도구
ㄴ 이상 징후를 발견하고 비용 효율성 파악
ㄴ 전체 AWS 조직에 보호 모범 사례 적용
ㄴ 30일 사용량 및 활동 메트릭 제공
ㄴ 조직 계정, 지역 버킷, 접두사별로 데이터를 집계해서 데이터 분석에 도움이 되는 보고서로 집계
    ㄴ 요약 인사이트, 데이터 보소, 비용 효율성을 위해 보고서를 전송하여 S3 사용 최적화
ㄴ 기본 대시보드 제공
    ㄴ 무료 및 고급 지표에 대한 요약된 인사이트와 트렌드 확인, 여러 지역과 여러 계정의 데이터가 표시 -> 필터 설정 필요x
    ㄴ 삭제x 원하는 경우 비활성화o
    ㄴ 중앙 집중식 구성

S3 스토리지 렌즈 메트릭 종류
무료 메트릭과 유료 메트릭으로 나뉨
유료 메트릭의 경우 CloudWatch에 추가 비용 없이 액세스 가능
    ㄴ S3 버킷 내의 접두사 수준에서 메트릭 수집가능
    ㄴ 결제 시 데이터는 15개월 동안 사용 가능

요약 메트릭 (기본)
    ㄴ 일반적인 인사이트 제공
    ㄴ 스토리지 용량, 객체 수, 객체 평균 크기, 활성화된 버킷 수 등을 요약
비용 최적화 메트릭 (기본 + 고급)
    ㄴ 현재 버전이 아닌 버전에 대한 정보 제공
    ㄴ 최신이 아닌 버전의 객체 수, 실제로 차지하는 공간 또는 불완전한 멀티파트 업로드 스토리지 바이트 수 등을 요약
    ㄴ 스토리지 클래스 활용도와 비효율 식별
데이터 보호 메트릭 (기본 + 고급)
    ㄴ 암호화/암호화 되지 않은 객체 용량
    ㄴ 복제 여부에 따른 객체 용량
    ㄴ 이전 버전 객체 만료/삭제 수
    ㄴ 암호화, 복제 상태 등 데이터 안전성 관리
액세스 관리 메트릭 (고급)
    ㄴ 버킷이 현재 어떤 객체 소유권을 설정하고 있는지 식별
    ㄴ 퍼블릭 접근 허용된 버킷 수, 버킷 정책에 의한 접근 허용 상태, ACL 사용 여부 확인
이벤트 메트릭 (고급)
    ㄴ S3 이벤트 알림에 대한 인사이트를 얻고 S3 이벤트 알림이 구성된 버킷의 수 파악
퍼포먼스 메트릭 (고급)
    ㄴ S3 전송 가속에 대한 인사이트를 얻고, S3 전송 가속이 활성화된 버킷의 수 확인
액티비티 메트릭 (고급)
    ㄴ 요청수, 업로드/다운로드된 바이트 수, 요청 오류 수 등
    ㄴ 객체에 대한 작업 및 트래픽 활동 식별
Detail Status Code 메트릭 (고급)
    ㄴ 상태 코드별 응답 수(200OKStatus Count, 403ForbiddenErrorCount)
    ㄴ 요청 제한 발생 수 ex)503 Slow Down

<S3 암호화>
서버 측 암호화(SSE)
S3에서 관리하는 키를 이용한 서버측 암호화 (기본값)
SSE KMS, KMS 키를 이용해서 암호화 키를 관리
SSE-C키, 고객이 제공한 키 사용
클라이언트 측 암호화

S3 > SSE-S3
AWS 처리하고 관리하고 소유한 키를 이용해 암호화
ㄴ 키에 액세스 x
ㄴ 서버측 암호화, 암호화 보안 유형은 AES-256

SSE KMS (SSE라고 적힌건 전부 서버측 암호화) / DSSE-KMS는 KMS를 기반으로 한 이중 암호화, 시험에 출제되지 않으나 이름 정도는 알아두면 좋음
ㄴ 사용자가 키를 통제할 수 있다는 장점
ㄴ CloudTrail을 이용해 키 사용 검사 가능
ㄴ 자체 API 키가 있고 이를 이용해 복호화를 하기에 API 호출을 필요로 함
ㄴ S3 버킷의 처리량이 아주 많고 모든게 KMS키로 암호화 되어 있다면 KMS API 요청 한도에 도달했을때 생기는 현상인 스로틀링 현상이 발생할 수 있음

SSE-C (콘솔이 아니라 CLI에서 다뤄야 함)
키가 AWS 외부에서 관리되지만 서버측 암호화, 이유는 키 -> AWS 전송
ㄴ 사용한 암호화 키는 폐기됨
ㄴ 키를 S3로 전송하기 때문에 HTTPS를 사용 -> 모든 요청에 HTTP 헤더의 일부로서 키 전달 필요

클라이언트 측 암호화(Client-Side Encryption)
클라이언트가 데이터를 직접 암호화 후 -> S3에 전송
ㄴ 데이터 복호화는 S3 외부의 클라이언트 측에서 이루어짐
ㄴ 의료, 금융, 공공기관 등 규제가 엄격한 곳에서 사용
ㄴ 키 분실 시 복구 불가

CORS(Cross-Origin-Resource Sharing) 교차 오리진 리소스 공유
웹 브라우저에서 다른 도메인의 리소스에 접근할 수 있게 해주는 메커니즘
ㄴ 오리진이 다른 경우 사용
    ㄴ 오리진 - 체계(프로토콜)ㆍ호스트(도메인) 포트로 구성

ex) 정적 웹페이지 호스팅하는 버킷 mybucket, 이미지가 저장된 mybucket/images
    브라우저에서 S3 mybucket에게 이미지 요청 -> S3는 CORS 정책 확인 -> S3 응답 헤더에 리소스에 접근하는 권한 여부 확인 -> 권한o 이미지 렌더링 / 권한x 이미지 로드 실패

MFA Delete
추가 보호 기능, 특정 객체 버전의 영구 삭제를 방지하는 역할
ㄴ 객체 버전을 영구적으로 삭제할 때, 버킷에서 버저닝을 중단할 때 MFA가 필요

S3 액세스 로그
감사 목적으로 S3 버킷에 대한 모든 액세스를 기록
ㄴ Amazon Athena 같은 데이터 분석 도구로 분석 가능
ㄴ 로깅 버킷은 같은 AWS 리전에 있어야 하며 로깅 버킷 = 모니터링 버킷 동일 설정x
    ㄴ 동일하면 로깅 루프 생성되고 무한 반복되어 버킷의 크기가 기하급수적으로 증가

S3 미리 서명된 URL(Pre-Signeed URLs)
S3 콘솔, CLI, SDK를 사용하여 생성할 수 있는 URL
ㄴ S3 콘솔로 생성 시 최대 12시간, CLI로 생성 시 168시간까지 사용 가능
ㄴ 사용 사례로는 AWS 외부의 사용자에게 한 파일에 대한 액세스 권한을 부여해야할 때 미리 서명된 URL를 생성하고 제공해 해당 파일에만 액세스 권한을 부여하고, 
   권한이 부여된 시간 동안 S3 버킷에서 파일에 액세스 할 수 있고, 만료 기간 후엔 S3 버킷에서 파일을 다시 가져옴

S3 Glacier Vault Lock
객체를 가져와서 S3 볼트에 넣은 다음 수정이나 삭제할 수 없도록 잠그는 것
ㄴ Glacier 위에 볼트 잠금 정책을 생성 -> 향후 편집을 위해 정책을 잠금
ㄴ 볼트 잠금 정책을 성정하고 잠근 후엔 누구도 변경이나 삭제x -> 규정 준수와 데이터 보존에 유용
ㄴ 객체를 절대 삭제x(관리자 or AWS 서비스 사용해도 안됨)

유사한 기능으로 S3 Object Lock(Versioning 필수)
여기서 WORM 모델 채택
    WORM : '한번 쓰고 여러번 읽는다'는 뜻
ㄴ 버킷 내의 모든 객체에 각각 적용할 수 있는 잠금
ㄴ 특정 시간 동안 삭제되는걸 차단
두가지 모드로 규정 준수 모드와 거버넌스 보존 모드
    규정 준수 모드 ex) 규정 준수를 엄격히 적용할 때 사용
    ㄴ S3 Glacier Vault Lock과 거의 동일
    거버넌스 보존 모드
    ㄴ 관리자 or 일부 권한을 받은 IAM 사용자는 객체의 보존 기간을 변경 or 바로 삭제 가능
두 모드 모두 보존 기간 필요
법적 보존 설정 시 보존 모드나 기관에 상관x 객체가 영구적으로 보호됨

S3 엑세스 포인트
S3 액세스 포인트는 S3 버킷에 대한 접근 경로를 따로 분리해서 설정할 수 있도록 하는 기능
ㄴ S3 버킷의 보안 관리를 간소화, 각각의 액세스 포인트는 각자의 DNS 이름을 가짐 -> 각자의 DNS로 액세스 포인트에 접속
ㄴ 특정 유저/앱마다 별도 접근 경로 제공

S3 객체 람다
S3의 객체를 반환하기 전에 Lambda 함수를 통해 실시간으로 가공 처리할 수 있게 해주는 기능
ㄴ S3에 저장된 데이터의 원본은 그대로 두고, 가공된 형태로 반환하고 싶을때 사용

<CloudFront>
CDN, 서로 다른 엣지 로케이션에서 미리 캐싱하여 읽기 성능을 높이는 것
CloudFront로 접근하는 방식에는 두가지가 있는데 둘 다 퍼블릭이여야 함
    ㄴ 첫번째는 CloudFront와 EC2 인스턴스 둘이 퍼블릭이여야 하고 공용IP가 CE2에 접근할 수 있또록 보안 그룹을 설정해주는 방법
    ㄴ 어플리케이션 로드 밸런서를 사용해 연결하는 방법 (이때 EC2 인스턴스는 프라이빗 설정해도 무관 그 이유는 EC2 인스턴스 -> LB 허용 -> 엣지 로케이션 접근)
ㄴ GeoIP 데이터베이스를 사용함 지리적 제한을 둘 수 있는데 보안탭에서 허용 지역 / 비허용지역 으로 나누어 특정 지역의 CloudFront를 차단할 수 있음
엣지 로케이션마다 전송 비용이 다름(운영 비용 차이, 지역 경제나 환율, 정책 및 세금 등의 이유가 있음)
ㄴ 더 많은 데이터가 전송될수록 비용↓
엣지 로케이션 수를 줄이는 세가지 방법
ㄴ 1. Price Class All, 모든 리전을 사용하며 최상의 성능을 제공하는
ㄴ 2. Price Class 200, 대부분의 리전을 지원하지만 가장 비싼 리전은 제외하는
ㄴ 3. Price Class 100, 가장 저렴한 리전만 사용 

CloudFront 캐시 무효화
항상 백엔드 오리진이 존재
ㄴ /대상 파일 로 특정 파일 무효화 ex) /index.html <- index 파일 캐시 초기화
ㄴ /* 로 전체 캐시 초기화

유니캐스트와 애니캐스트 IP
유니캐스트 IP = 하나의 서버가 하나의 IP 주소를 가짐, 1:1 대응 ex) 특정 친구 집에 찾아가는 것
애니캐스트 IP = 하나의 서버가 다수의 IP 주소를 가짐, 1:N 대응 ex) 가장 가까운 스타벅스 지점을 찾아가는 것 (스타벅스 라는 브랜드 중 내 기준 가장 가까운 지점)

Global Accelerator
애니캐스트 IP 방식을 사용해 네트워크 트래픽을 최적화
ㄴ 두 개의 고정 IP 주소 제공 (그 이상 추가x)
    ㄴ 두 개를 제공하는 이유는 이중화(가용성 + 장애 복원력 증가), 경로 다양성, 멀티 리전 분산 등의 이유
    ㄴ 이 IP는 ALB, NLB, EC2 인스턴스와 연결o , 실제 내부의 EC2 인스턴스나 LB는 사설 IP 사용 가능
ㄴ 아무것도 캐시하지 않기에 캐시 문제x
ㄴ 상태 확인 기능이 있으며 ALB에 대해 상태 확인을 실패하면 자동화된 장애 조치가 이루어지고 정상 엔드포인트로 실행됨

CloudFront와 Global Accelerator의 차이점
ㄴ CloudFront는 이미지나 비디오처럼 캐시 가능한 내용과 API 가속 및 동적 사이트 전달 같은 성능 향상에 사용
    ㄴ 대부분의 경우에 CloudFront는 엣지로부터 캐시된 내용을 가져옴, 즉 엣지 -> 캐시확인 -> 콘텐츠 가져오기 -> 브라우저 출력
ㄴ Global Accelerator는 TCP나 UDP상의 다양한 애플리케이션 성능 향상
    ㄴ 트래픽 라우팅에 집중하며 캐싱x
    ㄴ 하나 이상의 AWS 리전에서 실행되는 애플리케이션으로 전달(프록시)
        *프록시 : 사용자 또는 클라이언트가 다른 네트워크 서비스에 접속할 때 중계 역할을 하는 서버 또는 프로그램
    ex) 게임, IoT, VoIP, 비 HTTP 사용 시 사용

<Snowball Family>
연결이 제한적이거나 대역폭이 제한적이거나, 네트워트 비용이 매우 높거나, 대역폭을 공유 중이라 라이선스를 극대화 할 수 없거나, 연결 안정성에 문제가 있는 경우 snow Family 사용
ㄴ 데이터 전송하는데 일주일 이상 걸리는 겅유 snowball 장치 사용
휴대용 저장장치 콘과 볼 엣지
snowcone(8~14TB) -> snowball edge(80~210TB)
스노우볼 엣지 디바이스의 경우 EC2 인스턴스나 람다 함수를 직접 실행할 수 있음

휴대용 저장장치와 AWS 간의 통신
콘솔 -> 스노우볼 디바이스 요청 -> 서버에 스노우볼 클라이언트 or AWS OpsHub라는 것을 설치하여 데이터 전송 -> 스노우볼 장치를 서버에 연결 -> 클라이언트 복사 시작
ㄴ 스노우볼 디바이스 -> S3 데이터 전송 시 수명 주기 정책을 사용해 두었다면 S3 Glacier로 옮기는게 가능(S3에 전송된 데이터의 스토리지 계층을 이동시키는 것이 가능, 바로 스노우볼 디바이스 -> S3 Glacier 는 안됨)

엣지 컴퓨팅
엣지 위치에서 생성된 데이터를 처리하기 위한 것
    *엣지 위치 : 도로 위의 트럭, 바다 위의 선박, 지상의 채굴장 등의 장소

Amazon FSx
완전 관리형 서비스로 타사 고성능 파일 시스템을 실행시킴
4가지 파일 시스템은 꼭 알아야 됨

1. FSx for Windows File Server
ㄴ 완전 관리형 Windows 파일 서버 공유 드라이브
ㄴ SMB 프로토콜과 Windows NTFS를 지원
ㄴ Microsoft Active Directory 통합을 지원하므로 사용자 보안 추가, ACL로 사용자 할당량 추가해 액세스 제어
ㄴ Linux EC2 인스턴스에도 마운트 가능
ㄴ 초당 수십 GB에 수백만 IOPS, 수백 PB 데이터까지 확장
ㄴ SSD로 지연 시간이 짧아야 하는 워크로드 저장 ex) 데이터베이스, 미디어 처리 데이터 분석 등
ㄴ HDD로 넓은 스펙트럼의 워크로드 저장 ex) 홈 디렉터리, CMS
ㄴ 프라이빗 연결로 온프레미스 인프라에서 액세스 가능

2. FSx for Lustre
    *Lustre : Linux + Cluster의 합성어, 머신러닝 HPC, 즉 고성능 연산에 쓰였음
동영상 처리나 금융 모델링 전자 설계 자동화 등의 애플리케이션에서 쓰이고 확장성↑
ㄴ 초당 수백 GB의 데이터에 수백만 IOPS로 확장, 밀리초보다 짧은 지연 시간
ㄴ 낮은 지연 시간의 SSD, 크기가 작은 무작위 파일 작업이 많으면 IOPS도 사용 가능
ㄴ S3와 무결절성 통합 가능 => FSx로 S3를 파일 시스템처럼 읽어들일 수 있음, FSx의 연산 출력값을 다시 S3에 쓸 수 있음
ㄴ VPN과 직접 연결을 통해 온프레미스 서버에 사용 가능
스크래치 파일 시스템과 영구 파일 시스템
스크래치 파일 시스템 : 임시 스토리지, 데이터 복제x 기저 서버가 오작동하면 파일이 모두 유실됨, 최적화로 초과 버스트 사용하면 영구 파일 시스템보다 여섯배 성능을 보임(TiB 처리량당 초당 200MB 속도)
    ㄴ 단기 처리 데이터에 사용, 데이터 복제가 없어 비용 최적화

영구 파일 시스템 : 장기 스토리지, 동일한 AZ에 데이터 복제, 기저 서버 오작동하면 단 몇분 내에 해당 파일이 대체, 민감한 데이터의 장기 처리 및 스토리지

3. FSx for NetApp ONTAP
관리형 NetApp ONTAP 파일 시스템으로 NFS, SMB, iSCSI 프로토콜과 호환
ㄴ 온프레미스 시스템의 ONTAP이나 NAS에서 실행 중인 워크로드를 AWS로 옮길 수 있음
ㄴ 다양한 운영 체제에서 사용 가능
ㄴ 스토리지 오토 스케일링, 복제와 스냅샷 기능 지원
ㄴ 지정 시간 복제 기능 / 신속히 복제 가능, 스테이징 파일 시스템을 둘 수 있음 ex) 새 워크로드 테스트

4. FSx for OpenZFS
관리형 OpenZFS 파일 시스템으로 여러 버전에서의 NFS 프로토콜과 호환
ㄴ NFS 에서 실행되느 워크로드를 내부적으로 AWS 옮길 때 사용
ㄴ Linux, Mac, Windows 에서 사용 가능
ㄴ 백만 IOPS끼지 확장 가능, 지연 시간은 0.5밀리초 이하
ㄴ 스냅샷, 압축 지원하고 비용이 적지만 데이터 중복제거 기능x
ㄴ 지정 시간 동시 복제 기능 / NetApp ONTAP과 동일

AWS Storage Gateway
온프레미스 데이터와 클라우드 데이터 간의 다리 역할
ㄴ 재해 복구 목적으로 온프레미스 데이터를 클라우드에 백업
ㄴ 백업과 복구 목적으로 클라우드 마이그레이션, 혹은 온프레미스에서 클라우드 간 스토리지 확장을 사용 ex) 클라우드에는 콜드 데이터, 온프레미스에는 더 자주 쓰는 웜 데이터 저장식으로
S3 파일 게이트웨이
애플리케이션 서버가 NFS나 SMB 프로토콜을 사용하도록 함 -> 이 프로토콜을 통해 S3 파일 게이트웨이가 해당 요청을 HTTPS 요청으로 반환 S3 버킷으로 전송
ㄴ 수명 주기 정책을 사용하여 S3 Glacier로도 옮길 수 있음
ㄴ SMB 프로토콜을 사용중인 경우, 사용자 인증을 위해 Active Directory와 통합해야함
FSx 파일 게이트웨이
FSx for Windows File Server에 네이티브 액세스 제공
ㄴ 자주 액세스 하는 데이터의 로컬 캐시를 확보해 액세스 시 지연 시간을 단축시킴 (로컬 캐시는 회사 데이터 센터에 확보)
ㄴ Active Directory가 호환 가능
ㄴ 그룹 파일 공유, 온프레미스를 연결할 홈 디렉터리로 사용
볼륨 게이트웨이
블록 스토리지, S3가 백업하는 iSCSI 프로토콜 사용
ㄴ 볼륨이 EBS 스냅샷으로 저장, 필요에 따라 온프레미스 볼륨을 복구
ㄴ 최근 데이터 액세스 시 지연 시간이 낮은 캐시 볼륨 / 전체 데이터 세트가 온프레미스에 있으며 주기적으로 S3 백업이 따르는 저장 볼륨으로 나뉨
ㄴ 온프레미스 서버에 볼륨을 백업
테이프 게이트웨이(Tape Gateway)
물리적으로 테이프를 사용하는 회사가 테이프 대신 클라우드를 활용해 데이터를 백업할 수 있게 해주는 서비스
ㄴ 가상 테이프 라이브러리(VTL)는 S3 + Glacier
ㄴ 테이프 기반 프로세스의 기존 백업 데이털르 iSCSI 인터페이스를 사용하여 백업

게이트웨이는 회사 데이터 센터에 설치되어 있어야 함 -> 회사 데이터 센터 내에서 운영
    그러나 종종 게이트웨이를 실행할 가상 서버가 없는 경우 AWS의 하드웨어 사용 -> Storage Gateway 어플라이언스라고 하며 온프레미스 서버가 없는 경우 사용할 수 있음

AWS Transfer Family(전송 제품군)
S3또는 EFS의 안팎으로 데이터를 전송하려고 하는데 S3 APIs는 사용하고 싶지 않고 EFS 네트워크 파일 시스템도x FTP 프로토콜만 사용하려는 경우 사용
세가지 프로토콜을 지원(FTP, FTPS, SFTP)
1. FTP(파일 전송 프로토콜)의 AWS 전송 지원 / 비암호화
2. SSL을 통한 파일 전송 프로토콜인 FTPS / 암호화
3. 보안 파일 전송 프로토콜 SFTP / 암호화
시간당 프로비저닝된 엔드 포인트 비용에 전송 제품군 안팎으로 전송된 데이터의 GB당 요금을 더하는 가격 책정 구조

AWS DataSync
데이터를 자동화해서 빠르게 이동시켜주는 완전 관리형 데이터 전송 서비스
ㄴ 온프레미스 -> AWS, AWS -> AWS 간에 대용량 데이터를 빠르고 안정적으로 복제할 수 있음
ㄴ 복사하는 데이터의 메타데이터도 함께 복사

<SQS, SNS, Kinesis>
동기 커뮤니케이션 : 애플리케이션 <-> 애플리케이션 직접 연결 ex) 온라인 물품 판매 서비스가 있을 때 판매 완료 요청 -> 배송 서비스에 연락해 물건을 배송해야함 이 과정이 판매 서비스 <-> 배송 서비스 간의 직접 연결
비동기 or 이벤트 기반 유형 : 대기열
대기열 모델에선 SQS, 비동기 or 이벤트 기반 유형에선 SNS
실시간 스트리밍을 하면서 대용량 데이터를 다룬다면 Kinesis

SQS 개념
핵심은 대기열, 간단한 대기 서비스
SQS 대기열엔 메시지 포함 -> SQS 대기열에 메시지를 전송해야하는데 보내는 주체를 생산자라고 함
생산자는 한 개거나 그 이상
생성한 모든 메시지는 대기열에 들어감
대기열에서 소비자는 메시지 폴링 -> 대기열에게 소비자 앞으로 온 메시지가 있는지 확인 -> 있다면 메시지 폴링 -> 정보 전달 -> 대기열에서 폴링된 메시지 삭제
    *소비자 : 메시지를 처리하고 수신해야 하는 대상
대기열 서비스 : 생산자와 소비자 사이를 분리하는 버퍼 역할

Amazon SQS(Simple Queue Service) - 프론트엔드에서 들어오는 요청을 직접적으로 처리하는 것이 아닌 버퍼로 사용하여 로직 처리하는데 사용
완전 관리형 서비스, 애플리케이션 분리에 대한 문제? -> SQS
ㄴ 무제한 처리량을 얻을 수 있음
ㄴ 메시지 수명이 짦음(기본값으로 4일동안 대기열에 잔류, 최대 시간은 14일)
    ㄴ 대기열에 보내자마자 소비자가 읽고 보존 기간 내에 처리한 후 대기열에서 삭제해야함, 그렇지 않은 경우 소실
ㄴ 지연 시간이 짧아서 SQS는 메시지 보내기&읽기시 10밀리초 이내로 응답
ㄴ 전송된 메시지는 256KB 미만이어야 함
ㄴ SQS는 대기열 서비스라 높은 처리량, 높은 볼륨 등이 있어 중복 메시지가 있을 수 있음
ㄴ 생산자가 SDK 소프트웨어 개발키트를 사용하여 SQS 메시지를 보냄(이때 메시지를 보내는 API를 SendMessage 라고 함)
ㄴ 소비자는 EC2 인스턴스(가상 서버)에서 실행됨, 람다 함수를 사용하여 메시지를 수신할 수도 있음
ㄴ SQS 대기열은 메시지를 동시에 수신하고 처리할 소비자를 여러개 가질 수 있음
    ㄴ 만일 메시지가 소비자에 의해 충분히 빠르게 처리되지 않으면 다른 소비자가 수신하게 됨 -> 이것이 최선의 노력으로 메시지 순서 지정을 하는 이유
    ㄴ 이 경우처럼 더 많은 메시지를 처리하는 처리량을 늘려야 하면 소비자를 추가하고 수평 확장을 수행해서 처리량 개선
ㄴ 분리나 급격히 증가한 로드 혹은 시간초과 등의 문제에서 신속한 스케일링이 필요한 경우엔 SQS 대기열을 사용

SQS 보안
ㄴ HTTPS API를 사용하여 메시지를 보내고 생성함으로 비행 중 암호화, KMS 키를 사용하여 미사용 암호화
ㄴ 원한다면 클라이언트 측 암호화(클라이언트가 자체적으로 암호 해독을 수행)도 가능하지만 SQS에서 기본적으로 지원x
ㄴ 액세스 제어를 위한 IAM 정책은 SQS API에 대한 액세스를 규제할 수 있음
ㄴ S3 버킷 정책과 유사한 SQS 액세스 정책도 있음
    ㄴ SQS 대기열에 대한 교차 계정 액세스, SNS, S3 같은 다른 서비스가 SQS 대기열에 S3 이벤트 같은 것을 쓸 수 있도록 허용하려는 경우 매우 유용함

메시지 가시성 시간초과(Message Visibility Timeout)
대기열에서 소비자가 메시지를 풀링하면 다른 소비자는 그 메시지가 보이지 않게 되는데 이 유지시간을 가시성 시간초과
ㄴ 가시성 시간초과는 기본값으로 30초, 시간 안에 메시지 풀링 안하면 다른 사용자 메시지 풀링 가능
ㄴ 소비자는 메시지를 처리하는 데 시간이 더 필요하다면 ChangeMessageVisibility 라는 API를 호출하여 SQS에 알려야 함
ㄴ 만일 이 가시성 시간초과 값이 큰 경우 소비자가 충돌했을 때 이 메시지가 SQS 대기열에 보이기까지 많은 시간이 걸림 -> 대기열에 많은 메시지가 모이게 됨 -> 지연 시간 증가

롱 풀링
소비자가 큐에서 메시지 요청할 때 현재 큐에 메시지가 없다면 도착할 때까지 기다릴 수 있다는 개념
ㄴ 소비자가 API 호출 수를 줄일 수 있음
ㄴ 소비자는 SQS 큐에 10초동안 메시지를 요청할 수 있음, 또한 API 호출수↓ -> 지연시간↓ => 이유는 SQS에서 메시지 받자마자 소비자에게 전송되기 때문
ㄴ 최소한의 지연시간으로 메시지를 받을 수 있음
ㄴ 롱 풀링은 1~20초 사이로 설정 가능
ㄴ 전체적으로 짧은 풀링보다 롱 풀링을 선호해야 함

Amazon SQS FIFO 큐
선입선출 개념이 적용된 큐, 메시지를 전달받는 순서를 확실히 보장하기에 SQS 대기열 처리량에 제한이 있음
ㄴ 분리가 발생하거나 메시지의 순서를 유지할 필요가 있을 때 FIFO 대기열을 사용
ㄴ .fifo를 붙여야 FIFO 대기열 생성
ㄴ 메시지 중복 풀링 방지 설정도 있음

SQS 오토스케일링(ASG)
ASG 내의 EC2 인스턴스에 메시지를 SQS 대기열에서 풀링함
ㄴ 오토 스케일링 그룹을 자동으로 대기열 크기에 따라 확장시키기 위함 -> CloudWatch 지표인 대기열 길이를 보고 결정할 수 있음
ㄴ 세일 행사 중일때 수많은 고객이 주문 -> RDS나 DynamoDB에 엄청난 주문 및 요청을 처리할텐데 모종의 이유로 트랜잭션에 오류가 발생하면 고객의 요청 처리x -> 비즈니스에 좋지 못함
    ㄴ 이런 경우에 쓰기 대상 데이터베이스말고 SQS를 버퍼로 사용할 수 있음
    ㄴ 이 경우는 클라이언트에게 따로 데이터베이스에 입력됐다는 확인을 전송할 필요가 없을 때 사용 ex) 점심시간 식권 구매 등

Amazon SNS(Simple Notification Service)
Pub/Sub, 게시/구독
어떤 주제에 많은 구독자가 있으며 각 구독자는 SNS 주제에서 해당 메시지를 수신하고 보관 -> Pub/Sub 패턴
ㄴ 이벤트 생산자와 구독자는 해당 주제와 관련한 SNS 알림을 받으려는 사람
ㄴ SNS 주제 구독자는 해당 주제로 전송된 메시지 모두 받게 됨, 메시지 필터링하는 기능 사용가능
ㄴ 주제별 최대 구독자 수는 1200만 이상의 구독자 
ㄴ 계정당 가질 수 있는 주제는 최대 10만개
ㄴ SNS에서 직접 이메일을 보내거나, HTTP 또는 HTTPS 엔드포인트로 직접 데이터를 보내거나, SQS와 같은 특정 AWS 서비스와 통합하여 메시지를 대기열로 보낼 수 있고, Lambda에 보내거나, Firehose를 통해 데이터를 보낼 수도 있음
ㄴ SDK 주제 게시를 사용해 SNS에 메시지를 게시 가능
    ㄴ 주제 만든 후 하나 또는 여러 개의 구독을 만들고 SNS 주제에 게시
ㄴ 보안 기술로는 전송중 암호화, KMS 키를 사용한 저장 데이터 암호화, 클라이언트 측 암호화 등
ㄴ 액세스 제어는 IAM 정책 중심
ㄴ SNS 액세스 정책은 SNS 주제에 교차 계정 액세스 권한을 갖거나, S3 이벤트와 같은 SNS 주제에 작성할 수 있도록 허용하는 경우 유용

SNS + SQS : Fan Out
SNS 토픽으로 메시지 전송 후 원하는 만큼 SQS 대기열을 SNS 토픽에 구독시키는 것
ㄴ 여러 개의 대기열로 동일한 S3 이벤트 알림을 보내고 싶다면 Fan Out 패턴을 사용
ㄴ SNS FIFO = SQS FIFO -> SQS FIFO를 사용해 Fan Out을 할 때 정렬, 중복제거 필요
    ㄴ 구매 서비스는 SNS FIFO 토픽 -> 두 개의 SQS FIFO 토픽으로 Fan Out
    ㄴ 사기 탐지 서비스와 배송 서비스가 FIFO 대기열을 읽을 수 있음
ㄴ 메시지 필터링 : SNS 토픽 구독자들에게 전송할 메시지를 필터링하는 JSON 정책

Amazon Kinesis
실시간 스트리밍 데이터를 손쉽게 수집하고 처리하여 분석할 수 있는 서비스
ㄴ 실시간 데이터엔 애플리케이션 로그, 계측, 웹사이트 클릭 스트림, IoT 원격 측정 데이터
    ㄴ 데이터가 빠르게 실시간으로 생성된다면 모두 실시간 데이터 스트림
ㄴ 크게 4가지 서비스로 구성되어 있음

1. Kinesis Data Stream
스트리밍 데이터를 실시간으로 수집하고 저장하는 데 사용되는 서비스
ㄴ 데이터 스트림을 수집하여 처리하고 저장
ㄴ 실시간 데이터를 Kinesis 데이터 스트림으로 보내기 위해서는 프로듀서라는 도구를 사용함
    *프로듀서 : 애플리케이션이나 실제로 웹사이트나 디바이스에서 데이터를 가져와 Kinesis 데이터 스트림으로 보내기 위해 작성해야 하는 코드, 메트릭과 로그의 경우엔 Kinesis 에이전트라는 것을 설치하는데 이 역시 프로듀서
ㄴ 프로듀서를 사용하는 이유는 consumer 애플리케이션이 이 데이터를 실시간으로 소비하고 활용하기를 원하기 때문
ㄴ 데이터를 최대 365일동안 스트림에 보관할 수 있음
ㄴ 데이터가 지속되므로 소비자에 의해 데이터를 재처리하여 재생할 수 있음
    ㄴ Kinesis 데이터 스트림으로 데이터를 전송한 후에는 삭제할 수 없다는 뜻
ㄴ 최대 1MB의 데이터를 Kinesis 데이터 스트림으로 전송할 수 있음
ㄴ 동일한 파티션 ID를 가진 두 개의 데이터 포인트를 전송하면 데이터가 순서대로 정렬
    ㄴ 동일한 파티션 ID를 공유하여 두 데이터 포인트가 시잔적으로 관련이 있고 미사용, KMS 암호화 및 기내 HTTPS 암호화와 같은 보안 기능을 구현
ㄴ 높은 처리량을 위해 최적화된 프로듀서 애플리케이션을 작성하려면 키네시스 프로듀서 라이브러리 KPL 사용
ㄴ 최적화된 소비자 애플리케이션을 작성하려면 키네시스 클라이언트 라이브러리 or Ksql을 사용해야함
ㄴ 두가지 용량 모드가 있는데
    ㄴ 프로비저닝 모드, 스트림의 샤드(스트림의 크기) 개수를 선택
        ㄴ 시간당 프로비저닝된 각 샤드에 대해 비용을 지불
    ㄴ 온디맨드 모드, Kinesis 데이터 스트림 용량 프로비저닝하거나 관리x
    ㄴ 초당 약 404,000개의 레코드 또는 4MB 기본 용량 제공, 30일 동안 관찰된 처리량에 따라 자동으로 용량 확장
    ㄴ 사용한 스트림의 시간당 요금이 부과, Kinesis 데이터 스트림에 들어오고 나가는 데이터의 양에 따라 요금 청구
    
2. Kinesis Data Firehose
실시간 스트리밍 데이터를 자동으로 수집하고, 변환해서, 저장소로 전송해주는 완전관리형 서비스
ㄴ 데이터 전송하려면 애플리케이션, client와 같은 프로듀서 필요
ㄴ 직접 작성하여 SDK를 사용해 데이터를 파이어호스로 전송
ㄴ Kinesis 에이전트 사용해 서버 로그 등을 자동 수집하여 파이어호스로 전송
ㄴ Kinesis 데이터 스트림, CloudWatch 로그, IoT 같은 서비스에서 직접 데이터를 받을 수 있음
ㄴ 자동 확장 기능
ㄴ 서버리스 방식, 서비스 내에서 사용한 만큼만 비용 지불
ㄴ Near Real-Time은 Amazon 파이어호스를 가리킴
    ㄴ 즉각적인 반응은 필요 없지만, 가능한 한 빨리 데이터를 처리해서 활용할 수 있도록 하는 처리 방식

3. Kinesis Data Analytics ex) 시계열 분석, 실시간 대시보드, 실시간 지표 등
ㄴ SQL 언어나 Apache Flink를 활용하여 데이터 스트림을 분석
SQL용 Kinesis Data Analytics
ㄴ 서버리스 서비스이며 오토스케일링 가능
ㄴ 전송된 데이터만큼 비용 지불
ㄴ Kinesis Data Stream이나 Kinesis Data Firehose에 데이터를 출력할 수 있음
Apache Flink용 Kinesis Data Analytics
ㄴ Java, Scala, SQL로 애플리케이션 작성하고 스트리밍 데이터를 처리, 분석
ㄴ Flink는 코드로 작성해야 하는 특별한 애플리케이션
ㄴ Apache Flink는 표준 SQL보다 훨씬 강력하기 때문에 고급 쿼리 능력이 필요하거나 Data Stream, AWS의 관리형 Kafka인 Amazon MSK 같은 서비스로부터 스트리밍 데이터를 읽는 능력이 필요할 때 사용
ㄴ 컴퓨팅 리소스를 자동 프로비저닝 + 병렬 연산과 오토 스케일링
ㄴ 체크포인트와 스냅샷으로 백업 구현
ㄴ Apache Flink는 Data Stream이나 MSK의 데이터는 읽지만 Data Firehose의 데이터는 못 읽음

4. Kinesis Video Stream
ㄴ 비디오 스트림을 수집하고 처리하여 저장

Amazon Kinesis Data Stream vs Amazon Kinesis Firehose
데이터 스트림은 "실시간 감지·처리"가 필요한 고급 개발자나 데이터 엔지니어용
파이어호스는 복잡한 처리 없이 빠르게 데이터를 저장하고 싶은 사람용

SQS vs SNS, Kinesis
SQS는 소비자가 SQS 대기열에서 메시지를 요청해서 데이터를 가져오는(pull) 모델
ㄴ 데이터를 처리한 후 소비자가 대기열에서 삭제해서 다른 소비자가 못 읽게 해야함
ㄴ 관리된 서비스이므로 처리량을 프로비저닝 할 필요 없음
ㄴ FIFO 대기열을 이용해 순서 보장 가능, 지연 기능도 있음
SNS는 게시/구독 모델로 데이터 푸시 -> 주제를 구독한 다수의 구독자에게 메시지의 복사본 전송
ㄴ 주제별로 약 1250만 명의 구독자 가능, 데이터가 한 번 SNS에 전송되면 지속되지 않음(제대로 전달되지 않으면 데이터 유실 가능성)
ㄴ 팬아웃 아키텍쳐 패턴을 이용하면 SNS와 SQS를 결합하거나 SNS FIFO 주제를 SQS FIFO 대기열과 결합 가능
Kinesis는 두가지 소비 모드가 있음
1. 소비자 -> Kinesis로부터 데이터를 가져오는(pull) 표준 모드
ㄴ 샤드당 2 MB/s의 속도 지원
2. 향상된 팬아웃 유형의 소비 매커니즘
ㄴ 키네시스 -> 소비자 데이터 푸시, 처리량이 훨씬 높아 키네시스 스트림에서 더 많은 애플리케이션 읽기 가능
ㄴ 실시간 빅 데이터 분석, ETL 등에 활용
용량 모드에는 두가지
1. 프로비저닝 용량 모드는 키네시스 데이터 스트림으로부터 원하는 샤드 양을 미리 지정
2. 온디맨드 용량 모드에서는 샤드 수가 키네시스 데이터 스트림에 따라 자동으로 조정

<도커 ECS EKS>
도커 : 앱 배포를 위한 소프트웨어 개발 플랫폼
ㄴ 컨테이너 기술
ㄴ 컨테이너에 앱이 패키징 되는데 컨테이너는 표준화되어 있어서 아무 운영체제나 호환성 문제x
ㄴ 도커의 사용 사례엔 마이크로서비스 아키텍쳐
ㄴ 온프레미스 -> 클라우드로 앱을 리프트-앤-시프트 하는 경우에도 사용
ㄴ 서버가 있는데 다수의 도커 애플리케이션이 동시에 실행될 수 있어 아주 다용도로 활용
ㄴ 도커 리포지토리에 이미지 저장
    ㄴ Docker Hub는 유명한 퍼블릭 리포지토리
        ㄴ 우분투, MySQL과 같은 OS용 기본 이미지가 이에 해당
        ㄴ Amazon ECR Public Gallery라 불리는 퍼블릭 리포지토리 옵션도 있음
    ㄴ Amazon ECR(Elastic Container Registry)는 프라이빗 리포지토리

도커와 가상머신의 차이점
가상 머신 아키텍쳐
ㄴ 리소스가 호스트와 공유되어 한 서버에서 다수의 컨테이너를 공유할 수 있음
ㄴ 그 위에 하이퍼바이저가 있고 앱과 Guest 운영 체제가 있음 -> EC2 원리
ㄴ 가상 머신의 EC2 인스턴스는 각자 분리되어 있음 -> 리소스 공유x
도커 컨테이너 아키텍쳐
ㄴ 인프라와 EC2 인스턴스 같은 호스트 OS가 있고 도커 Daemon 위에 많은 컨테이너가 있음
ㄴ 도커 Daemon에서 가볍게 실행되는 컨테이너라 공존 가능
ㄴ 네트워킹이나 데이터 등 공유
ㄴ> 가상 머신보다 덜 안전하지만 하나의 서버에 많은 컨테이너를 실행할 수 있기 때문에 도커 컨테이너를 많이 사용

도커 시작
ㄴ 시작하려면 Dockerfile을 작성해야함 (도커 컨테이너 구성 파일)
ㄴ 베이스 도커 이미지에 몇 가지 파일을 추가해서 구축한 도커 이미지는 푸시를 통해 도커 리포지토리, Docker Hub, Amazon ECR에 저장 가능
ㄴ 도커 이미지(=EC2 AMI와 유사)를 가져와 실행하고 도커 이미지를 실행 -> 도커 컨테이너가 되고 도커를 구축할 때 사용한 코드를 실행

Amazon ECS(Elastic Container Service)
도커 관리를 위한 Amazon 전용 플랫폼
EC2 시작 유형으로 인프라o 직접 프로비저닝하고 유지
ㄴ ECS 인스턴스는 특별하게 각각 ECS 에이전트를 실행해야함
ㄴ ECS 에이전트 -> EC2 인스턴스를 Amazon ECS 서비스와 지정된 ECS 클러스터에 등록, 이후에 ECS 태스크 수행하기 시작하면 AWS가 컨테이너를 시작하거나 멈출것
ㄴ ECS 태스크를 시작하거나 멈추면 자동으로 위치가 지정됨
Fargate 시작 유형(=서버리스)은 인프라 프로비저닝x 관리할 EC2 인스턴스x
ㄴ ECS 태스크를 정의하는 태스크 정의만 생성하면 필요한 CPU나 RAM에 따라 ECS 태스크를 AWS가 대신 실행
ㄴ 새 도커 컨테이너를 실행하면 그냥 실행됨, 작업을 위해 백엔드 EC2 인스턴스 생성 필요x
ㄴ 확장은 태스크 수↑
ECS 태스크의 IAM 역할
EC2 시작 유형을 예시로 EC2 인스턴스 프로파일을 생성 -> ECS 에이전트가 프로파일 사용해 API 호출 -> ECS 서비스가 CloudWatch로그에 API 호출 -> 컨테이너 로그와 ECR로부터 도커 이미지 가져옴
ㄴ ECS 태스크는 EC2와 Fargate 방식 모두 해당하며 각자에 특정 역할을 만들 수 있음 (태스크a엔 A역할, 태스크b엔 B역할)
ㄴ 역할을 다르게 하는 이유는 역할이 각자 다른 ECS 서비스에 연결할 수 있게 하기 때문
로드 밸런서 통합
ECS 클러스터 안에 HTTP나 HTTPS 엔드 포인트로 태스크를 활용하기 위해 ALB 앞에서 실행 -> 모든 사용자가 ALB 및 백엔드의 ECS 태스크에 직접 연결
ㄴ NLB는 AWS Private Link와 사용할때 권장되는 옵션
ㄴ 구세대 ELB는 Fargate와 연결x, 그렇기에 ALB 권장
ECS 데이터 볼륨
ㄴ 어느 AZ에 실행되는 태스크든 네트워크 파일 시스템인 EFS에서 자주 사용됨
ㄴ Fargate로 서버리스 방식으로 ECS 태스크 실행하고 파일 시스템 지속성을 위해 EFS를 사용, EFS 역시 서버리스기 때문
ㄴ S3는 ECS 태스크에 파일 시스템으로 마운트 될 수 없음
ECS 오토스케일링
ㄴ ECS 서비스의 CPU 사용률, 메모리 사용률, ALB 관련 지표인 타겟탕 요청수를 기준으로 오토스케일링이 가능함
ㄴ 대상 추적, 단계, ECS 서비스 확장을 설정하는 예약 스케일링 등의 스케일링 종류가 있음
ㄴ EC2 시작 유형은 태스크 레벨에서의 ECS 서비스 확장이 EC2 인스턴스 클러스터 확장과 다르다는것을 알아야 함
ㄴ ECS 클러스터 용량 공급자(Capacity Provider)는 ASG과 함께 사용되며 새 태스크를 실행할 용량이 부족하면 자동으로 ASG 확장

Amazon EKS(Elastic Kubernetes Service)
AWS에 Kubernetes 클러스터를 실행할 수 있는 서비스
*kubernetes는 오픈소스 시스템으로 도커를 컨테이너화한 애플리케이션의 자동 배포, 확장, 관리를 지원
ㄴ 컨테이너를 실행한다는 목적은 ECS와 비슷하지만 사용하는 API가 다름, ECS는 오픈 소스x / Kubernetes는 오픈소스이고 여러 클라우드 제공자가 사용함 -> 표준화
EC2 시작 모드는 EC2 인스턴스에서 작업자 모드를 배포할 때 사용
Fargate 모드는 EKS 클러스터에 서버리스 컨테이너를 배포할 때 사용
ㄴ 회사가 온프레미스나 클라우드에서 Kubernetes나 Kubernetes API를 사용중일 때 Kubernetes 클러스터를 관리하기 위해 EKS를 사용함
ㄴ Kubernetes는 클라우드 애그노스틱으로 Azure, Google Cloud 등 모든 클라우드에서 지원
    *클라우드 애그노스틱(cloud-agnostic)은 특정 클라우드 서비스 제공자(AWS, Azure, GCP 등)에 종속되지 않는 시스템 또는 소프트웨어
관리형 노드 그룹의 경우
ㄴ AWS로 노드(EC2 인스턴스)를 생성하고 관리함
    *노드는 EKS 서비스로 관리되는 오토 스케일링 그룹의 일부
ㄴ 온디맨드와 스팟 인스턴스를 지원
자체 관리형 노드의 경우 
ㄴ 사용자 지정 사항이 많고 제어 대상이 많은 경우 직접 노드를 생성하고 EKS 클러스터에 등록한 다음 ASG의 일부로 관리해야함
ㄴ 사전 빌드된 AMI인 Amazon EKS 최적화 AMI를 사용하면 시간 절약
ㄴ 온디맨드와 스팟 인스턴스 지원
노드를 원치 않는 경우
ㄴ EKS가 지원하는 Fargate 모드를 선택하면 유지 관리x 노드 관리x EKS에서 컨테이너만 실행하면 됨
ㄴ EKS 클러스터에 데이터볼륨을 연결하려면 스토리지 클래스 매니페스트를 지정해야함
    *스토리지 클래스 매니패스트(StorageClass Manifest)는 동적 볼륨 프로비저닝을 정의하는 설정 파일(=스토리지 프로파일)
ㄴ 컨테이너 스토리지 인터페이스(CSI)라는 규격 드라이버를 활용
ㄴ EBS와 Fargate 모드가 작동하는 EFS를 지원하고 FSx for Lustre와 FSx for NetAPP ONTAP을 지원함

AWS Fargate
Amazon의 서버리스 컨테이너 플랫폼
ㄴ ECS, EKS 둘 다 함께 작동

Amazon ECR(Elastic Continer Registry) -> 도커 이미지를 저장할 땐 ECR
AWS에 도커 이미지를 저장하고 관리하는 데 사용
ㄴ 계정에 한해 이미지를 비공개 저장
    ㄴ 여러 계정을 설정하거나 퍼블릭 저장소를 사용해 Amazon ECR Public Gallery에 게시하는 방법
ㄴ ECR은 ECS와 완전히 통합되어 있고 이미지는 백그라운드에서 S3에 저장됨
ㄴ ECR 저장소에 여러 도커 이미지가 있는데 ECS 클러스터의 EC2 인스턴스 이미지를 끌어오기 위해선 EC2 인스턴스에 IAM 역할 지정
    ㄴ ECR에 대한 모든 접근은 IAM이 보호중 그러므로 EC2 인스턴스 이미지를 끌어오기 위해선 IAM 역할을 지정해줘야 함, 권한 에러가 생긴다면 정책을 살펴보는것을 추천
ㄴ 이미지 취약점 스캐닝, 버저닝 태그 및 수명 주기 확인 지원

AWS App Runner
완전관리형 서비스로 규모에 따라 웹 애플리케이션, API 배포를 돕는 서비스
ㄴ 소스코드나 Docker 컨테이너 이미지를 가지고 원하는 구성을 설정
    ㄴ vCPU 수, 컨테이너 메모리 크기, 오토 스케일링 여부 등
ㄴ 오토스케일링이 가능하고 가용성↑
ㄴ 로드밸런싱 및 암호화 기능 지원 (VPC에 액세스 할 수 있어 데이터베이스와 캐시 메시지 대기열 서비스에 연결할 수 있음)
ex) 웹앱, API, 마이크로서비스

AWS App2Container(A2C)
Java 및 .NET 웹 애플리케이션을 Docker 컨테이너로 마이그레이션하고 현대화 하는데 사용되는 CLI 도구
ㄴ 현대화를 가속화하되 코드를 변경하지 않고 레거시 앱을 클라우드로 마이그레이션 하는 것(=CloudFormation 탬플릿 생성)
ㄴ 생성된 Docker 컨테이너를 ECR에 등록하며, ECS, EKS 또는 App Runner에 배포하도록 선택할 수 있음
ㄴ 사전 구축된 CI/CD 파이프라인도 지원

<서버리스>
서버를 관리할 필요가 없는 서비스 (서버가 없다는 말x)

AWS Lambda
ㄴ 함수당 최대 10GB의 RAM을 프로비저닝 할 수 있음
ㄴ 커스텀 런타임 API라는 것을 통해 많은 다른 언어를 지원함 ex) Rust, Golang

Lambda의 한도
람다의 한도는 리전당 존재
ㄴ 실행 시 메모리 할당량은 128MB~10GB이고 메모리는 1MB씩 증가
ㄴ 최대 실행 시간은 900초(=15분)
ㄴ 환경변수는 4KB까지 가질 수 있음
ㄴ 압축 시 최대 크기는 50MB, 압축하지 않았을 경우엔 최대 250MB
    ㄴ 이 용량을 넘는 경우 /tmp 공간을 사용해야함
ㄴ 큰파일을 가져올 때 사용할 수 있는 임시공간(/tmp 폴더)이 있으며 최대 10GB까지 가능
ㄴ 최대 1000개 까지 동시 실행 가능

Lambda Snap Start
람다 함수의 성능을 높이기 위한 람다의 기능으로 Java 11 이상에서 실행되는 람다 함수들의 성능을 추가비용없이 최대 10배 높여줌
ㄴ 함수를 불러올 때 함수 초기화를 미리 사전에 해서 초기화 단계를 건너뛰고 바로 호출하는 방법
ㄴ 메모리와 초기화된 함수의 디스크 상태의 스냅샷이 생성된 후 이 스냅샷이 저지연 액세스를 위해 캐시

CloudFront 함수와 람다 엣지(Lambda@Edge)
*엣지 함수 : 애플리케이션에 도달하기 전에 엣지에서 로직을 실행하도록 요구하는 것
CloudFront 함수는 JavaScript로 작성된 경량 함수로 뷰여 요청과 응답을 수정
고성능, 고확장성이 필요할 때, 뷰어 요청과 뷰어 응답에만 사용됨
ㄴ 확장성이 높고 지연 시간에 민감한 CDN 사용자 지정에 사용
ㄴ 시작 시간은 1밀리초 미만, 초당 백만개의 요청을 처리
ㄴ 모든 코드가 CloudFront에서 직접 관리됨
Lambda@Edge는 Node.js나 Python으로 작성하며 초당 수천 개의 요청을 처리할 수 있음
ㄴ 모든 CloudFront 요청 및 응답을 변경할 수 있음
ㄴ 함수는 us-east-1(=CloudFront 배포를 관리하는 리전) 리전에만 작성할 수 있음
ㄴ 함수를 작성하면 CloudFront가 모든 로케이션에 해당 함수를 복제
뷰어 요청과 오리진 요청으로 나뉘는데
    ㄴ 뷰어 요청(CloudFront -> 뷰어쪽으로 응답 보내기 전에 수정)
    ㄴ 오리진 응답(CloudFront가 오리진에서 응답을 받은 후에 수정)

CloudFront / Lambda@Edge의 차이점
ㄴ JavaScript / Node.js, Python 제공
ㄴ 수백만 개의 요청처리 / 수천 개의 요청처리
ㄴ 뷰어 / 뷰어 + 오리진
ㄴ 최대 실행 시간 1밀리초 / 실행에 5~10초 소요
ex) CloudFront 함수는 캐시키를 정규화홤(요청 속성을 변환하여 최적의 캐시 키 생성) -> 요청이나 응답에 HTTP 헤더 삽입, 수정, 삭제하도록 헤더 조작, URL 다시 쓰거나 리다이렉션, 요청 허용 또는 거부하기 위해 JWT 생성하거나 검증하는 인증 및 권한 부여
    Lambda@Edge는 CPU와 메모리가 증가하므로 여러 라이브러리를 로드할 수 있고 타사 라이브러리에 코드 의존 가능, SDK -> 다른 AWS 서비스로 액세스, 외부서비스에서 데이터 처리가 가능해 대규모 데이터 옹합, 파일 시스템이나 HTTP 요청 본문에 바로 액세스

Lambda in VPC
람다 함수는 기본적으로 외부 VPC에서 실행됨, 퍼블릭 설정이 아닌 서비스에 액세스 하려면 VPC 안에서 람다를 실행하면 됨
람다 함수를 프라이빗 서브넷에 시작하는 방법
    ㄴ VPC ID Laambda 함수를 시작하려는 서브넷을 지정 -> 람다 함수에 보안 그룹을 추가 -> 람다가 서브넷에 엘라스틱 네트워크 인터페이스 생성 -> VPC에서 실행되는 타 AWS 서비스에 액세스 가능
ㄴ VPC에서 람다를 사용하는 대표적인 사용 사례는 RDS 프록시

DynamoDB
완전 관리형 데이터베이스로 데이터가 다중 AZ 간에 복제되므로 가용성이 높음, AWS의 독점 서비스 이자 NoSQL 데이터베이스
ㄴ 초당 수백만 개의 요청을 처리하고 수조 개의 행, 수백 TB의 스토리지를 가짐
ㄴ 테이블로 구성되며 데이터베이스 생성x
ㄴ Aurora나 RDS와 달리 데이터베이스가 이미 존재하는 서비스
ㄴ 보안과 관련된 모든 기능은 IAM과 통합되어 있음
ㄴ 비용이 적게 들고 오토 스케일링 기능이 탑재되어 있음
ㄴ 유저 관리나 패치 없이도 항상 사용
ㄴ 데이터베이스 프로비저닝x
ㄴ 행을 무한히 추가가 가능해 상당한 장점(스키마 전개에 어려움이 없음)
ㄴ 테이블 클래스는 두 종류로 Standard / IA
ㄴ 항목의 최대 크기는 400KB
ㄴ DynamoDB를 사용하려면 읽기/쓰기 용량 모드도 설정해야되며 용량 관리 방식을 제어하는데엔 두가지 모드가 있음
    ㄴ 프로비저닝 모드는 미리 용량을 프로비저닝, 프로비저닝된 RCU와 WCU만큼의 비용을 지불하는 방식
    *RCU(Read Capacity Unit)는 읽기 용량 단위, WCU(Write Capacity Unit)는 쓰기 용량 단위
    ㄴ 프로비저닝 모드도 오토 스케일링 기능이 있으므로 자동으로 RCU와 WCU를 늘리거나 줄일 수 있음
    ㄴ 온디맨드 모드는 읽기/쓰기 용량이 워크로드에 따라 자동으로 확장됨
    ㄴ 모든 읽기/쓰기 사용에 비용이 청구됨

DynamoDB Acclerator(DAX)
DynamoDB를 위한 고가용성의 완전 관리형 무결절인 메모리 캐시
ㄴ DynamoDB 테이블에 읽기 작업이 많을 때 DAX 클러스터를 생성하고 데이터를 캐싱해 읽기 혼잡을 해결
ㄴ 캐시 데이터에 마이크로초 수준의 지연 시간을 제공
ㄴ 캐시의 기본 TTL은 5분으로 설정되어 있으나 변경 가능
ㄴ ElastiCache가 아닌 DAX를 사용하는 이유는 DAX는 DynamoDB 앞에 있고 개별 객체 캐시와 쿼리와 스캔 캐시를 처리하는데 유용
    ㄴ 집계 결과를 저장할 땐 ElastiCache, 대용량의 연산을 저장할 땐 DynamoDB

DynamoDB - 스트림 처리
테이블의 모든 수정 사항(생성, 업데이트, 삭제)을 포함한 스트림 생성
ex) DynamoDB 테이블의 변경 사항에 실시간 사용 분석, 파생 테이블 삽입, 리전간 복제, DynamoDB 변경 사항에 대해 람다 함수 실행 등에 사용
두가지 스트림 처리 방법이 있는데
DynamoDB 스트림
ㄴ 보존 기간 24시간, 소비자 수 제한
ㄴ 자체적으로 읽기를 실행하려면 DynamoDb Stream Kinesis 어댑터 사용
Kinesis Data Streams
ㄴ 보존 기간 1년, 더 많은 소비자 수
ex) Kinesis dAta Firehose, Glue, 스트리밍, ETL 등

DynamoDB 글로벌 테이블
여러 리전 간에 복제가 가능한 테이블
ㄴ 복수의 리전에서 짧은 지연 시간으로 액세스 할 수 있게 해줌
ㄴ 다중 활성 복제가 가능 -> 애플리케이션이 모든 리전에서 테이블을 읽기/쓰기 가능
ㄴ DynamoDB 스트림을 활성화 해야 리전 간 테이블 복제 할 수 있는 인프라 구축

DynamoDB TTL
만료스탬프가 지나면 자동으로 항목을 삭제하는 기능
ex) 최근 항목만 저장하도록 하거나, 2년 후 데이터를 삭제해야 한다는 규정을 따라야 할때 사용

DynamoDB 복구
ㄴ 지정 시간 복구(PITR)를 사용하여 지속적인 백업 가능 (35일 지속)
ㄴ PITR보다 더 긴 백업 옵션으로 온디맨드 백업이 있음 (직접 삭제할 때까지 보존)
ㄴ 백업을 좀 더 제대로 관리할 수 있는 방법인 AWS Backup 서비스 사용

AWS API Gateway
람다와 통합하면 완전 서버리스 애플리케이션이 구축되므로 인프라 관리x
ㄴ WebSocket 프로토콜 지원
ㄴ dev, test, prod 등 여러 환경 핸들링 가능
ㄴ 인증, 권한 부여 등 수많은 보안 기능을 API Gateway에 활성화 시킬 수 있음
ㄴ API키 생성, API Gateway에 클라이언트 요청이 과도할 때 요청을 스로틀링할 수 있음
ㄴ API Gateway 수준에서 요청과 응답을 변형하거나 유효성을 검사해 올바른 호출이 실행되게 할 수 있음
ㄴ SDK나 API 스펙을 생성하거나 API 응답 캐시

API GAteway 통합
ㄴ 람다 함수를 지연 호출(람다 함수를 사용하는 REST API를 완전 서버리스 애플리케이션에 노출시키는 간단한 방법)
ㄴ 백엔드의 HTTP의 엔드포인트를 노출시킬 수 있음
ㄴ 온프레미스에 HTTP API가 있거나 클라우드 환경에 ALB가 있을 때 API Gateway 활용하여 속도 제한 가능
ㄴ 캐싱, 사용자 인증, API 키 등의 기능을 추가할 수 있음

API Gateway 배포 방법(=엔드포인트 유형)
엣지 최적화
글로벌 클라이언트 용, 전세계 누구나 API Gateway에 액세스
ㄴ 모든 요청이 CloudFront 엣지 로케이션을 통해 라우팅 -> 지연 시간 개선
리전 배포
API Gateway == 클라이언트 요청 리전인 경우
ㄴ 엣지 최적화랑 동일한 결과를 내며 캐싱 전략과 CloudFront 설정에 더 많은 권한을 가져갈 수 있음
API Gateway 배포 유형
ㄴ 프라이빗으로 퍼블릭 배포x
    프라이빗 API Gateway는 VPC 내에서만 액세스 할 수 있기에 ENI 같은 인터페이스 VPC 엔드포인트를 사용
ㄴ 액세스를 정의할 땐 리소스 정책 사용

API Gateway 보안
사용자 식별 방법
ㄴ IAM 역할 사용
ㄴ Amazon Cognito 사용 ex) 모바일 애플리케이션이나 웹 애플리케이션의 외부 사용자에 대한 보안 조치
ㄴ 사용자 지정 권한 부여자 ex) 람다 함수, HTTPS 보안
사용자 지정 도메인 이름을 ACM과 통합
ㄴ 엣지 최적화 엔드포인트를 사용할 경우 인증서는 us-east-1에 있어야 함
ㄴ 리전 엔드포인트를 사용한다면 인증서는 API Gateway 단계와 동일한 리전에 있어야 함
ㄴ Route 53에 CNAME이나 별칭(Alias) 레코드를 설정해 도메인 및 API Gateway를 가리키게 함

AWS Step functions
서버리스 워크플로를 시각적으로 구성할 수 있는 기능으로 주로 람다 함수 오케스트레이션 하는데 활용
ㄴ 시퀀싱, 병행 실행, 조건 설정, 타임아웃, 에러 처리하기 등의 기능이 있음
ㄴ 람다 함수만 처리하는게 아니라 EC2, ECS, 온프레미스 서버, API Gateway, SQS 큐 등 다양한 AWS 서비스를 워크플로에 넣을 수 있음
ㄴ 워크플ㄷ로에 사람이 개입해서 승인을 해야만 진행되는 단계를 설정할 수 있음

Amazon Cognito
사용자에게 웹 및 모바일 앱과 상호작용할 수 있는 자격 증명을 부여
ㄴ 이 사용자들은 AWS 외부에 있음
두 종류의 하위 서비스가 있는데
ㄴ 앱 사용자에게 가입 기능을 제공하는 Cognito 사용자 풀, API Gateway 및 ALB와 통합
ㄴ 페더레이션 자격 증명이라고 불렸던 Cognito 자격 증명 풀, 앱에 등록된 사용자에게 임시 AWS 자격 증명을 제공해 일부 AWS 리소스에 직접 액세스 할 수 있도록 해주고 Cognito 사용자 풀과 활히 통합됨

Cognito 사용자 풀(CUP)
웹 및 모바일 앱을 대상으로 하는 서버리스 사용자 데이터베이스
ㄴ 사용자 이름, 이메일, 비밀번호 조합으로 간단한 로그인 절차 정의
ㄴ 비밀번호 재설정, 이메일 및 전화번호 검증
ㄴ MFA 인증
ㄴ Facebook이나 Google과 통합할 수 있어 소셜 로그인 가능
ㄴ API Gateway나 ALB와 통합됨

Cognito 자격증명 풀(GIP, = Federated Identities)
사용자에게 자격 증명을 제공, 임시 AWS 자격 증명을 사용해 AWS 계정에 직접 액세스
ㄴ 직접 또는 API Gateway를 통해 서비스에 액세스
ㄴ 자격 증명에 적용되는 IAM 정책은 Cognito 자격 증명 풀 서비스에 사전 정의되어 있음
ㄴ user_id를 기반으로 사용자 정의하여 세분화된 제어 가능
ㄴ 게스트 사용자나 특정 역할이 정의되지 않은 인증된 사용자는 기본 IAM 역할을 상속
ㄴ Cognito 자격증명 풀을 사용하면 DynamoDB에 행 수준 보안을 설정할 수 있음
ㄴ 자격증명풀의 개념은 웹에서의 소셜 로그인과 유사하지만 소셜 로그인은 오롯이 '사용자 인증'을 위한 수단일 뿐이고 자격증명풀은 인증된 사용자에게 AWS 리소스를 접근할 수 있는 권한(IAM 역할)을 부여하는 것

<AWS 데이터베이스>
RDBMS ex) RDS, Aurora
    ㄴ SQL을 사용하거나 온라인 트랜잭션을 처리할 때 사용
    ㄴ 조인에 유용함
NoSQL ex) DynamoDB, ElastiCache, Neptune DocumentDB, KeySpaces
    ㄴ 조인 기능이 없고 일반적으로 SQL 쿼리 언어를 사용하지 않음
객체 스토어 ex) S3, 백업, 아카이브용 Glacier
데이터 웨어하우스 ex) OLAP유형의 데이터베이스인 RedShift, Athena, EMR
    ㄴ SQL 분석이나 비즈니스 인텔리전스(BI)를 사용
검색 유형의 데이터베이스 ex) OpenSearch
    ㄴ 자유롭게 텍스트를 입력하거나 비정형 데이터를 검색
    ㄴ 그래프는 데이터 세트 간의 관계 표시 ex) Amazon Neptune
원장 데이터베이스 ex) QLDB(퀀텀 원장 DB)
    ㄴ 트랜잭션 목록과 원장을 기록
시계열 데이터베이스 ex) TimeStream

RDS
ㄴ 관리형 PostgreSQL, MySQL, Oracle SQL, DB2, MariaDB
ㄴ RDS 인스턴스 크기와 EBS 볼륨 유형 및 크기 프로비저닝
ㄴ 읽기 전용 복제본을 지원하여 읽기 처리 능력 확장
ㄴ 고가용성 목적으로 Multi-AZ를 사용하여 대기 데이터베이스 보유 가능
ㄴ RDS 데이터베이스의 보안은 IAM을 통해 관리
ㄴ 네트워크 보안은 보안 그룹을 통해 관리되며 저장 데이터 암호화는 KMS 사용
ㄴ SSL/TLS를 사용하여 전송중 암호화
ㄴ 백업은 최대 35일까지 지원되는 자동 백업, 수동 데이터베이스 스냅샷
ㄴ IAM 인증을 지원하며 RDS 프록시를 통해 강제할 수 있음
ㄴ Secret Manager와 통합하여 데이터베이스 자격 증명 관리

Aurora
ㄴ 두 개의 데이터베이스 엔진과 호환이 가능한 API (PostgreSQL, MySQL)
ㄴ 스토리지와 컴퓨팅이 구분되어 있음
ㄴ 기본설정으로 세 개의 가용 영역에 걸친 여섯 개의 레플리카에 데이터를 저장
ㄴ 스토리지에 문제 발생 시 자가 복구
ㄴ 스토리지 오토 스케일링 o (읽기 전용본도 오토 스케일링 ok)
ㄴ 라이터/리더 엔드포인트 존재
ㄴ 자동화된 백업 존재, 1~35일까지 설정 가능, 하지만 비활성화 불가능(RDS는 비활성화o)
ㄴ 백트랙 기능
ㄴ 수동 DB 스냅샷 
    ㄴ Percona ExtraBackup을 통해 Aurora MySQL 클러스터에 백업 생성 -> S3에 저장(업로드) -> Aurora MySQL 클러스터에 복원 -> 복원 완료 후 데이터베이스 활성화(읽기/쓰기 접근 가능)
ㄴ COW(Copy-On-Write) 프로토콜을 이용한 복제
ㄴ Aurora 서버리스
ㄴ Aurora global : 16개에 달하는 데이터베이스 리드 인스턴스 제공하고 DB가 복제된 리전마다 제공됨
ㄴ 메인 리전에 문제가 생길 경우 서브 리전을 메인 리전으로 승급시킬 수 있음
ㄴ 기계학습을 하고 싶다면 Aurora 기계 학습 모듈 사용 (SageMaker, Comprehend)

ElastiCache
관리형 Redis/Memcached
ㄴ 캐싱 작업을 이용
ㄴ 캐싱 작업을 위해 EC2 인스턴스 프로비저닝해야함
ㄴ Redis용에서 클러스터 생성, 다중AZ, 샤딩을 위한 읽기 전용 복제본
ㄴ IAM을 통해 프로비저닝한 보안과 보안 그룹 사용
ㄴ 저장 데이터 암호화를 위한 KMS, Redis 인증
ㄴ 백업 및 스냅샷 가능
ㄴ 사용하기 위해선 애플리케이션 코드를 수정해줘야 함

DynamoDB ex) 데이터베이스가 필요한 경우, 서버리스 애플리케이션 개발을 하는 경우
관리형 서버리스 NoSQL 데이터베이스
ㄴ 오토스케일링이 제공되는 프로비저닝된 용량 모드 : 시간에 따라 증가/감소하는 유형의 워크로드를 사용할 때
ㄴ 온디맨드 용량 모드 : 워크로드 예측이 어려울 때
ㄴ 키 값 저장소로 ElastiCache로 대체 가능
ㄴ DAX 클러스터(=DynamoDB 액셀러레이터)
ㄴ 보안과 승인 등 모두 IAM에서 이루어짐
ㄴ DynamoDB Streams를 이용해 데이터베이스의 모든 변경사항 스트리밍 가능하고 람다 호출할 수 있음
ㄴ Kinesis Data Stream, Kinesis Firehose 등과 통합 가능
ㄴ 자동백업(PITR 활성화 필요) 최대 35일, 35일안에 S3로 내보내기 기능을 이용해 내보내기 가능
ㄴ 장기간 백업엔 온디맨드 백업 사용
ㄴ 빠르게 스키마를 변경해야 하거나 유연한 타입의 DB 스키마가 필요하다면 DynamoDB

DocumentDB(=MongoDB의 Aurora 버전)
ㄴ DocumentDB는 MongoDB 기반
ㄴ MongoDB는 또 하나의 NoSQL 데이터베이스
ㄴ 데이터는 세 개의 가용 영역에 걸쳐 복제

Amazon Keyspaces ex) IoT 장치 정보와 시계열 데이터 저장
AWS의 관리형 Apache Cassandra 보조
Cassandra는 오픈소스 NoSQL 분산 데이터베이스
ㄴ 애플리케이션 트래픽에 따라 자동으로 확장/축소
ㄴ 테이블의 데이터는 여러 AZ에 걸쳐 세번 복제
ㄴ Keyspaces에서 쿼리를 수행하려면 Cassandra쿼리 언어(CQL)을 사용
ㄴ 어떤 규모든 지연 시간 10 밀리초 미만, 초당 수천건의 요청 처리
ㄴ 온디맨드 모드와 프로비저닝 모드가 있는데 DynamoDB와 동일
ㄴ 암호화 백업(자동, 최대 35일) 제공

<머신러닝>
Amazon Rekognition
이미지와 비디오의 장면을 찾는 서비스
ㄴ 인적 검토가 필요할 경우엔 Amazon Augmented AI(A2I) 사용
ㄴ 인적 검토는 선택 옵션으로 민감한 이미지에 자동으로 플래그를 지정하도록 설정한 다음 최종 인적 검토를 사용해 유지 or 삭제를 결정

Amazon Transcribe
음성 -> 텍스트 변환시켜 주는 서비스
ㄴ 자동 음성 인식(ASR)이라는 딥러닝 프로세스 사용하여 음성 -> 텍스트 변환
ㄴ Redaction을 사용하여 개인 식별 정보(PII)를 자동으로 제거
ㄴ 다국어 오디오를 자동으로 언어 식별

Amazon Polly
텍스트 -> 음성
ㄴ '발음 어휘 목록'을 사용해 사용자 지정 발음을 생성할 수 있음
    ㄴ 원하는 발음으로 읽게 하고자 할때 사용 ex) 'AWS'라고 읽는 대신 'Amazon Web Service'라고 풀어 읽게 하기
ㄴ SSML(음성 합성 마크업 언어) 기능, 사용자 지정 음성을 만들 수 있는 기능

Amazon Lex ex) 챗봇 구축, 콜 센터 봇 구축
자동 음성 인식 서비스, ASR(Automatic Speech Recognition)
ㄴ 자연어 이해를 통해 말의 의도를 파악하고 문장 이해 가능

Amazon Comprehend
자연어를 처리하는 NLP 서비스
완전관리형 서버리스 서비스, 머신 러닝을 사용하여 텍스트에서 인사이트와 관계 도출
ㄴ 텍스트 혹은 구조화 되지 않은 데이터를 Comprehend를 사용해 구조화

Amazon Comprehend Medical
비정형 의료 텍스트에서 유용한 정보를 탐지해서 반환해주는 서비스
ㄴ 의사 소견서나 퇴원 요약서, 검사 결과서 등의 의료 사례 기록을 발견하면 NLP, 자연어 처리를 사용해 텍스트를 탐지하고 문서속에 보호된 개인 건강 정보(PHI)를 DetectPHI API로 탐지

Amazon SageMaker
완전 관리형 서비스이며 머신 러닝 모델을 구축하는 개발자와 데이터 과학자를 위한 서비스
ㄴ 머신 러닝 모델을 구축하기 위한 모든 과정을 SageMaker를 이용해 처리
ㄴ 라벨링, 구축, 훈련 및 조정, 적용 모두 SageMaker로 가능

Amazon Forecast ex) 미래의 비옷 판매량 예측
예측을 도와주는 완전 관리형 서비스
ㄴ 머신 러닝을 사용하여 매우 정확한 예측 제공

Amazon Kendra
머신 러닝으로 제공되는 완전 관리형 문서 검색 서비스
ㄴ 문서 내에서 답변 추출, 문서는 (text, pdf, html, PowerPoint, Word, FAQ 등)

Amazon Textract
텍스트 추출하는 서비스

<데이터&분석>
Amazon Athena ex) 임시 쿼리 수행, 비즈니스 인텔리전스 분석 및 보고, AWS 서비스에서 발생하는 모든 로그를 쿼리하고 분석(VPC 흐름로그, LB 로그, CloudTrail 추적 등)
=> 서버리스 SQL 엔진을 사용한 Amazon S3 분석 -> Amazon Athena
S3버킷에 저장된 데이터 분석에 사용하는 서버리스 쿼리 서비스
SQL언어를 사용하는 Presto 엔진에 빌드
ㄴ S3 버킷에 데이터를 로드하면 Athena 서비스를 사용해 이동하지 않고 S3에서 데이터를 쿼리하고 분석 가능
ㄴ CSV, JSON, ORC, Avro Parquet 등의 형식 지원
ㄴ 스캔된 데이터의 TB당 고정 가격을 지불
ㄴ 서버리스여서 프로비저닝 x
ㄴ Amazon QuickSight라는 도구와 함께 사용해 보고서와 대시보드 생성
ㄴ 파일이 클수록 스캔과 검색이 쉬우므로 128MB 이상의 파일을 사용해야함
ㄴ 연합 쿼리라는 기능이 있어 S3 뿐만 아니라 어떤 곳의 데이터도 쿼리할 수 있음

Amazon RedShift
OLAP 유형의 데이터베이스, 온라인 분석 처리, 데이터 웨어하우징에 사용함
ㄴ PB의 데이터로 확대 가능
ㄴ Columnar(열 기반) 스토리지 -> 병렬 쿼리 엔진 존재
ㄴ 빠른 쿼리와 조인을 통합할 수 있음
ㄴ 인덱스가 있고 고성능 데이터 웨어하우스를 위해 인덱스를 빌드함
RedShift 클러스터는 두가지
리더 노드 : 쿼리 계획과 결과 집합을 시킴
계산 노드 : SQL 쿼리를 병렬로 처리하고 결과 데이터를 리더에게 전송하는 노드
ㄴ Redshift는 대부분의 클러스터에 대해 싱글 AZ지만 특정 클러스터 유형에 대해 멀티 AZ 모드가 있음
ㄴ 스냅샷은 point-in-time 백업이며 S3에 내부적으로 저장되고 증가
ㄴ 스냅샷 자동화는 8시간 or 5GB마다 스냅샷, 수동 스냅샷은 계속 이야기하던 것과 동일(원할때 저장, 삭제 기간x)
ㄴ RedShift는 자동 수동의 여부와 관계없이 해당 클러스터에서 다른 AWS 리전으로 스냅샷 자동복사

RedShift 데이터 수집 방법
1. Amazon Kinesis Firehose
ㄴ 데이터를 S3로 로드 후 RedShift에서 복사 -> IAM 역할을 사용해 S3 버킷에서 RedShift 클러스터로 데이터 복사
ㄴ 퍼블릭의 경우 인터넷을 통해 복사, 프라이빗의 경우 VPC 라우팅을 허용하여 VPC를 통해 복사
ㄴ JDBC 드라이버를 사용해서 RedShift 클러스터로 데이터 유입도 가능
2. RedShift Spectrum ex) Data Lake 쿼리(S3에 저장된 로그, 데이터 등을 바로 분석), 저비용 분석, ETL 보완(필요 시점에 쿼리, 필터된 데이터만 RedShift 가져오기)
S3에 데이터가 있고 Redshift를 이용해 분석하고 싶지만 RedShift로 로드하고 싶지 않을때 사용
ㄴ 더 많은 처리 능력을 사용하고 싶을때 사용
ㄴ S3 데이터 저장 -> Glue Data Catalog에 테이블 등록(or Spectrum 자체 가탈로그 사용) -> RedShift에서 외부 스키마 생성 -> 쿼리 실행

Amazon EMR(Elastic MapReduce) ex) 데이터 처리와 기계학습, 웹 인덱싱 빅 데이터 작업 등
AWS에서 빅 데이터 작업을 위한 하둡 클러스터 생성에 사용
ㄴ Apache Spark, HBase, Presto Apache Flink 이 3개 서비스에 관한 프로비저닝과 구성을 대신 처리해줌
ㄴ 전체 클러스터를 자동으로 확장, 스팟 인스턴스와 통합되므로 가격 할인 혜택도 받을 수 있음
ㄴ 마스터 노드는 클러스터 관리(다른 모든 노드의 상태를 조정하며 장기 실행)
ㄴ 코어 노드는 태스크를 실행하고 데이터 저장
ㄴ 태스크 노드(선택) 테스트만 실행하는 노드

Amazon QuickSight
서버리스 머신 러닝 기반 비즈니스 인텔리전스 서비스
ㄴ 대화형 대시보드 생성
ㄴ 대시보드를 생성하고 소유한 데이터 소스와 연결 -> 시각화 + 오토스케일링 가능
ㄴ 웹사이트에 임베드 가능, 세션당 비용 지불
ㄴ 엔터프라이즈 에디션에선 액세스 권한이 없는 사용자에게 일부 열이 표시되지 않도록 열 수준 보안(CLS) 설정 가능
ㄴ 스탠다드 버전은 사용자 정의
ㄴ 그룹은 엔터프라이즈 버전에서만 사용 가능
ㄴ 사용자와 그룹은 QuickSight 전용 (IAM과 다름)
ㄴ 대시보드는 읽기 전용 스냅샷이며 분석 결과 공유 가능

AWS Glue
추출과 변환 로드 서비스를 관리 -> ETL 서비스
서버리스 서비스
ㄴ 데이터를 Parquet 형식으로 변환
ㄴ Glue 작업 북마크 : 새 ETL 작업을 실행할 때 이전 데이터의 재처리를 방지
ㄴ Glue Elastic Views : SQL을 사용해 여러 데이터 스토어의 데이터를 결합하고 복제 (커스텀 코드 지원x)
ㄴ Glue DataBrew : 사전 빌드된 변환을 사용해 데이터를 정리하고 정규화함
ㄴ Glue Studio : Glue에서 ETL 작업을 생성, 실행 및 모니터링 하는 GUI
ㄴ Glue Streaming : APache Spark Structured Streaming 위에 빌드되며 ETL 작업을 배치 작업이 아니라 스트리밍 작업으로 실행할 수 있음

AWS Lake Formation
데이터 레이크 생성을 도움
    *데이터 레이크 : 데이터 분석을 위해 모든 데이터를 한 곳으로 모아 주는 중앙 집중식 저장소
ㄴ 데이터 검색, 정제, 변환 주입을 도움
ㄴ 데이터 수집, 정제나 카탈로깅, 복제 같은 복잡한 수작업 자동화하고 기계학습 변환 기능으로 중복제거 수행
ㄴ 정형+비정형 데이터 소스를 결합할 수 있으며 블루프린트 제공
ㄴ Lake Formation에 연결된 애플리케이션에서는 세분화된 액세스 제어가 가능
ㄴ Glue 위에 빌드되지만 Glue와 직접 상호작용하지 않음
ㄴ 소스 크롤러, ETL 및 데이터 준비 도구, 데이터 카탈로깅 도구가 포함됨
ㄴ Ahtena, Redshift, EMR Apache Spark 프레임워크처럼 중앙화된 권한이 필요한 서비스에 사용
ㄴ 보안을 관리할 곳이 많아질 때 Lake Formation에 연결하면 한곳에서 보안 관리

Amazon MSK(Managed Streaming for Apache Kafka)
Apache Kafka용 Amazon 관리형 스트리밍 서비스
Amazon Kinesis의 대안
ㄴ MSK는 그때그때 클러스터를 생성, 업데이트 삭제함
ㄴ 클러스터 내 브로커 노드와 Zookeeper 브로커 노드를 생성 및 관리
ㄴ 고가용성을 위해 VPC의 클러스터를 최대 세 개의 다중 AZ 전역에 배포
ㄴ 일반 Kafka 장애 자동 복구 기능
ㄴ 서버리스
Apache Kafka는 데이터를 스트리밍 하는 방식
ㄴ Kafka 주제로 데이터를 전송하면 해당 데이터는 다른 브로커로 완전 복제
ㄴ 실시간으로 데이터를 스트리망하고 소비자는 데이터를 소비하기 위해 주제를 폴링함
ㄴ Kinesis Data Stream에는 1MB의 메시지 크기 제한이 있지만 MSK는 기본이 1MB, 최대 10MB까지 설정 가능
ㄴ Data Stream에선 샤드로 데이터 스트리밍, MSK에선 파티션을 이용한 Kafka 주제 사용
ㄴ Data Stream에서 용량 확장/축소는 샤드 분할/병합, MSK는 파티션 추가로 주제 확장만 가능(파티션 제거x)
ㄴ Data Stream에는 TLS 전송중 암호화, MSK는 평문 + TLS 전송중 암호화

<AWS 모니터링 및 감사 : CloudWatch, CloudTrail 및 Config>
CloudWatch
AWS의 모든 서비스에 대한 지표를 제공
    *지표(Metric) : 모니터링할 변수
ㄴ 지표는 이름공간(namespaces)에 속하므로 각기 다른 이름공간에 저장되며 서비스당 하나를 가짐
ㄴ 지표의 속성으로 측정 기준(Dimension)이라는 것이 있는데 지표당 최대 측정 기준 30개를 가질 수 있음
ㄴ 지표는 시간을 기반으로 하므로 타임스탬프 필요
ㄴ CloudWatch 대시보드에 추가해 모든 지표를 한 번에 볼 수 있음
ㄴ CloudWatch 지표는 외부로 스트리밍 가능

CloudWatch Logs
AWS에서 애플리케이션 로그를 저장할 수 있는 장소
ㄴ 로그 그룹 정의(이름은 애플리케이션을 나타내는 이름으로), 이 로그 그룹엔 다수의 로그 스트림이 있을것, 애플리케이션 안의 로그 인스턴스나 특정한 로그 파일 또는 클러스터의 일부로 갖고 있는 특정 컨테이너를 나타냄
ㄴ 로그 만료 정책 설정
ㄴ 기본값으로 모든 로그 암호화, KMS 기반 암호화도 원한다면 가능
ㄴ SDK, CloudWatch Logs Agent, CloudWatch Unified Agent 등을 사요하여 로그를 전송할 수 있는데 지금은 CloudWatch Unified Agent를 주로 사용중
ㄴ S3로 배치 내보기에 사용되는데 완료될때까지 최장 12시간까지 걸릴 수 있음, 내보내기 시작하는 API 호출 CreateExportTask
    ㄴ 실시간 스트림을 얻고, 그걸 처리하고 분석하기 위해선 CloudWatch Logs Subscription 사용
ㄴ Subscription Filter로 로그 이벤트의 종류를 지정하거나, 커스텀 람다 함수를 작성하거나 실시간으로 OpenSearch 서비스로 데이터를 전송하는 관리형 람다 함수 사용도 가능

CloudWatch Logs Insights
CloudWatch Logs의 로그를 쿼리할 때 사용(CloudWatch Logs 안의 쿼리 기능)
ㄴ 쿼리를 제작하도록 모든 필드를 자동으로 CloudWatch Logs가 자동으로 탐지함
ㄴ 집계 통계를 계산하고 이벤트를 정렬하거나 이벤트 개수를 제한하는 등의 작업을 할 수 있음
ㄴ 다른 계정에 있어도 한 번에 다수의 로그 그룹을 쿼리할 수 있음
ㄴ 실시간 엔진이 아니라 쿼리 엔진

CloudWatch 에이전트 및 Logs 에이전트
EC2 인스턴스 -> CloudWatch로 로그 옮겨지지 않는데 이때 EC2 인스턴스에 에이전트 라는 작은 프로그램을 실행시켜 로그 파일을 푸시해야함
이때 EC2 인스턴스에 로그를 보낼 수 있게 해주는 IAM 역할이 있어야 함
ㄴ> 한마디로 EC2 인스턴스 같은 컴퓨팅 리소스에 에이전트 라는 프로그램이 설치되어 있어야 하고, 이 에이전트가 로그 파일을 푸시함
ㄴ 에이전트는 온프레미스 환경에서도 셋업이 가능, VM-ware 같은 가상 서버에서도 사용 가능
ㄴ CloudWatch Logs Agent와 CloudWatch Logs Unified Agent의 차이는 일반/통합 버전으로 보면 됨
    ㄴ 일반 버전은 로그만, 통합 버전은 프로세스나 RAM 같은 추가적인 시스템 단계 지표를 수집함
    ㄴ SSM Parameter Store를 이용해서 에이전트를 쉽게 구성할 수 있음
    ㄴ 통합 에이전트를 대상으로 중앙 집중식 환경 구성 가능
ㄴ EC2 인스턴스 모니터링보다 더 세부적이고 많은 지표를 수집함

CloudWatch Alarms
특정 지표 값에 대해 알림을 트리거하는 기능
ㄴ 'Okay' 트리거 되지 않은 상태 / 'Insufficient data' 데이터 부족하여 상태 판단 어려움 / 'Alarm' 임계값 초과되어 알림 활성화
ㄴ Period : 알람이 특정 지표를 평가하는 시간 간격으로 매우 짧게 또는 매우 길게 설정가능
알람의 세 가지 주요 대상
    ㄴ EC2 인스턴스에서 정지, 종료, 재부팅 그리고 복구 작업가능
    ㄴ 오토 스캐일링 트리거
    ㄴ SNS 서비스에 알림을 보낼 수 있음 ex) 람다 함수와 연동하여 알림이 발생했을 때 특정 작업을 자동으로 수행

CloudWatch Alarms - Compute Alarms
CloudWatch Alarms는 단일 지표만 보여주는데 Compute Alarms는 여러 다른 alarms의 상태를 실제로 모니터링 할 수 있음
ㄴ 여러 다른 alarms를 결합하는 작업, and 또는 or 조건을 사용하여 조건을 설정 가능

EC2 인스턴스 리커버
Status Check - EC2 가상 머신의 상태를 검사
System Check - EC2 인스턴스가 실행되는 하드웨어 확인
Attached EBS status - EC2 인스턴스에 연결된 EBS 볼륨 상태 확인

Amazon EventBridge
클라우드에서 CRON 작업 예약 가능, 스크립트 예약
ㄴ 이벤트 패턴에 반응할 수도 있음
ㄴ Amazon EventBridge로 전송되는 이벤트에 필터를 설정할 수 있음(JSON 형식)
ㄴ 특정 이벤트 버스의 권한을 관리할 수 있음 ex) 특정 이벤트 버스가 다른 리전이나 다른 계정의 이벤트를 허용하거나 거부하도록 설정

EventBridge - Schema Registry
애플리케이션의 코드 생성이 가능, 이벤트 버스의 데이터가 어떻게 정형화 되는지 미리 알 수 있음

CloudWatch 인사이트 유형
    CloudWatch Continer Insights
    ㄴ 컨테이너로부터 지표와 로그를 수집, 집계, 요약하는 서비스
    ㄴ ECS나 EKS EC2의 Kubernetes 플랫폼에 직접 실행하는 컨테이너에서 사용 가능
    ㄴ 컨테이너로부터 지표와 로그를 손쉽게 추출해서 대시보드 생성
    ㄴ EKS나 Kubernetes EC2에서 실행되는 Kubernetes에서 사용할 경우 컨테이너화된 버전의 CloudWatch 에이전트를 사용해야 컨테이너를 찾을 수 있음

    Lambda Insights
    서버리스 애플리케이션을 위한 모니터링과 트러블 슈팅 솔루션
    ㄴ 람다 함수 옆에서 실행되며 Lambda Insights라는 대시보드를 생성해 람다 함수의 성능 모니터링에 이용

    Contriubutor Insights
    기고자(Contirbutors) 데이터를 표시하는 시계열 데이터를 생성하고 로그 분석하는 서비스
    ㄴ 네트워크 상위 대화자를 찾고 시스템 성능에 영향을 미치는 대상을 파악 가능
    ㄴ VPC 로그, DNS 로그 등 AWS가 생성한 모든 로그에서 작동

    CloudWatch Application Insights
    모니터링하는 애플리케이션의 잠재적인 문제와 진행 중인 문제를 분리할 수 있도록 자동화된 대시보드 제공
    ㄴ Java나 .NET Microsoft IIS 웹 서버나 특정 데이터베이스를 선택해 선택한 기술로만 애플리케이션 실행
    ㄴ 애플리케이션에 문제가 있는 경우 자동으로 대시보드를 생성하여 서비스의 잠재적인 문제를 보여줌
        ㄴ 이때 백그라운드에서 SageMaker 머신 러닝 서비스 사용

AWS CloudTrail
AWS 계정 안에서 일어난 모든 이벤트와 API 호출 이력을 콘솔, SDK, CLI 또는 기타 AWS 서비스를 통해 얻을 수 있음

AWS Config
AWS 내 리소스에 대한 감사와 규정 준수 여부를 기록할 수 있께 해주는 서비스
ㄴ 설정된 규칙에 기반해 구성과 구성의 시간에 따른 변화를 기록할 수 있음
ㄴ 필요한 경우 인프라를 빠르게 롤백하고 문제점을 찾을 수 있음
ㄴ 리전별 서비스이기 때문에 모든 리전별로 구성해야하며 데이터 중앙화를 위해 리전과 계정 간 데이터를 통합할 수 있음
ㄴ 리소스의 구성을 S3에 저장해 나중에 분석할 수 있음
ㄴ AWS 관리형 Config 규칙이 있음(75종의 규칙 존재, 스스로 Config 규칙 추가도 가능)
ㄴ 각 리전당 기록된 구성 항목별로 3센트를 지불해야하고 리전당 Config 규칙 평가별로 0.1센트씩 비용 지불
ㄴ 리소스 규정 준수 여부, 리소스 구성을 시간별로 볼 수 있음
ㄴ Eventbridge를 사용해 리소스가 규정을 미준수했을 때마다 알림을 보낼 수 있음
ㄴ 모든 구성 변경과 모든 리소스의 규정 준수 여부 알림을 Config에서 SNS로 보낼 수도 있음

CloudTrail, CloudWatch, Config
CloudWatch
ㄴ 지표, CPU 네트워크 등의 성능 모니터링과 대시보드를 만드는 데 사용
ㄴ 이벤트와 알림을 받을 수도 있고 로그 집계 및 분석 도구도 사용할 수 있음
CloudTrail
ㄴ 계정 내에서 만든 API에 대한 모든 호출을 기록함
ㄴ 특성 리소스에 대한 추적도 정의할 수 있음, 글로벌 서비스임
Config
ㄴ 구성 변경을 기록하고 규정 준수 규칙에 따라 리소스를 평가함
ㄴ 변경과 규정 준수에 대한 타임라인을 UI로 보여줌