CLF 취득했으니 강의 섹션 3, 4, 5 & 12 는 패스

<공용 IP와 사설IP, 그리고 탄력적 IP>
- 공용 IP
ㄴ 공용 IP는 곧 기기가 인터넷상에서 식별될 수 있음을 의미
ㄴ 공용 IP는 고유해야됨
ㄴ 구글 검색을 통해 그 위치를 찾을 수 있음

- 사설 IP
ㄴ 사설 네트워크에서만 식별
ㄴ IP가 사설 네트워크 안에서만 유일하면됨
ㄴ 지정된 범위의 IP만 사설 IP로 사용가능

- 탄력적 IP
ㄴ EC2 인스턴스를 시작하고 중지할 때 공용 IP를 바꿀 수 있음
ㄴ IPv4 구조, 한번에 한 인스턴스에만 첨부할 수 있음
ㄴ 계정당 탄력적 IP를 5개 쓸 수 있음
ㄴ 결정적으로 탄력적 IP는 사용하지 않는게 좋음
    ㄴ 매우 좋지 않은 구조적 결정으로 종종 언급됨
    ㄴ 대신 임의의 공용 IP를 써서 DNS 이름을 할당하는 것이 좋음

특정 EC2 인스턴스에 Elastic IPs를 사용하여 인스턴스 실행동안 탄력적 IP 부여 가능 
인스턴스는 생성될 때마다 공용 IPv4 주소를 부여받는데,
종료 후 재실행 시 기존에 사용하던 것과는 다른 공용 IP 주소를 부여받게 된다.
이를 해결하기 위해 탄력적 IP 주소 할당을 시켜주는 것이고
이 탄력적 IP 주소 할당은 인스턴스와 네트워크 인터페이스에 할당할 수 있다.
탄력적 IP를 할당해 줄 경우 인스턴스의 종료 시작 여부에 상관없이 탄력적 IP 주소로 IP 주소가 고정된다.

<배치 그룹>
- 클러스터 배치 그룹
ㄴ 단일 가용 영역 내에서 지연 시간이 짧은 하드웨어 설정으로 인스턴스를 그룹화
ㄴ 높은 성능을 제공하지만 위험 또한 높음
ㄴ 모든 EC2 인스턴스가 동일한 가용영역에 존재
ㄴ 모든 인스턴스 간에 초당 약 10기가비트의 대역폭을 확보하여 향상된 네트워킹을 활성화
ㄴ 지연 시간이 짧고 처리량이 많은 네트워크를 확보
ㄴ 어떤 종류의 계산 작업에서도 뛰어난 성능을 얻을 수 있음
ㄴ 단점으론 가용 영역에 장애가 발생하면 모든 인스턴스가 동시에 장애를 일으킴

- 분산 배치 그룹 - EC2 인스턴스를 여러 AZ에 걸쳐 서로 다른 물리적 하드웨어에 배치
ㄴ 인스턴스가 다른 하드웨어에 분산된다는 의미
ㄴ 가용 영역별로 분산된 배치 그룹당 7개의 EC2 인스턴스만 가질 수 있다는 제한 사항이 있음
ㄴ 크리티컬 애플리케이션이 있는 경우 분산 배치 그룹을 사용
ㄴ 실패 위험을 최소화
ㄴ 모든 EC2 인스턴스가 다른 하드웨어에 위치함
ㄴ 여러 가용 영역에 걸쳐 있을 수 있으며 동시 실패의 위험이 감소
ㄴ 단점으론 가용 영역당 7개의 인스턴스로 제한됨
ex) 사용 사례는 가용성을 극대화 하고 위험을 줄여야 하는 애플리케이션

- 분할 배치 그룹
ㄴ 여러 파티션에 인스턴스가 분할되어 있고 이 파티션은 가용 영역 내의 다양한 하드웨어 랙 세트에 의존
ㄴ 즉 인스턴스가 여전히 분리되어 있지만 다른 실패로부터 격리되지 않음
ㄴ 하지만 다른 오류 파티션과 격리되어야 함
ㄴ 여러 가용 영역 파티션에 인스턴스를 분산 가능 
ㄴ 가용 영역당 최대 7개의 파티션 존재

<탄력적 네트워크 인터페이스(ENI)>
ㄴ VPC의 논리적 구성 요소이며 가상 네트워크 카드를 나타냄
ㄴ ENI는 EC2 인스턴스가 네트워크에 액세스 할 수 있게 해줌
ㄴ 각 ENI는 다음과 같은 속성을 가질 수 있음
    1. 주요 사설 IPv4와 하나 이상의 보조 IPv4를 가질 수 있음
    2. 각 ENI는 사설 IPv4당 탄력적 IPv4를 갖거나 혹은 하나의 공용 IPv4를 가질 수 있으므로 사설 및 공용 IP가
    한개씩 제공됨
    3. ENI에 하나 이상의 보안 그룹을 연결할 수 있음
    4. EC2 인스턴스와 독립적으로 ENI를 생성하고 즉시 연결하거나 장애 조치를 위해 EC2 인스턴스에서 이동시킬 수 있음
ㄴ ENI는 특정 가용 영역 즉 AZ에 바인딩됨
    즉 특정 AZ에서 ENI를 생성하면 해당 AZ에만 바인딩할 수 있음을

    -ENI 실습
    1. 인스턴스가 생성될 때 자동으로 ENI가 하나 생성됨, 인스턴스 생성 후 네트워크 탭의 아래쪽에 가보면
    연결된 ENI를 확인할 수 있음
    2. 왼쪽에 네트워크&시크릿 탭에 네트워크 인터페이스가 있는데 여기서 ENI를 관리할 수 있음
    3. 인스턴스 종료 시 인스턴스 생성 시에 만들어진 ENI는 삭제되지만 사용자가 직접 생성한
    ENI는 삭제되지 않음
    4. ENI를 직접 생성하면 프라이빗 IPv4 주소를 더 많이 활용할 수 있고 따라서 네트워킹 작업도 수월해짐
    ENI는 있어도 비용 발생x

<EC2 절전모드(Hibernate)>
ㄴ EC2 인스턴스가 절전모드가 되면 RAM에 있던 인 메모리 상태는 그대로 보존
ㄴ 인스턴스 부팅이 더 빨라짐    / 운영체제를 완전히 중지하거나 다시 시작하지 않고 그대로 멈춰두었으니까
ㄴ RAM에 기록되었던 인 메모리는 루트 경로의 EBS 볼륨에 기록되기 때문에 
    루트 EBS 볼륨을 암호화해야 하고 볼륨 용량도 RAM을 저장하기에 충분해야함
    (볼륨에 덤프된 데이터를 인스턴스 실행시 그대로 가져오기 때문)
ㄴ 모든 종류의 인스턴스에서 사용 가능
ㄴ 최대 60일까지 절전모드 사용 가능
ex) 오래 실행되는 프로세스를 갖고 있고 중지하지 않을 때, RAM 상태를 저장하고 싶을 때, 빠르게 재부팅하고 싶을때

사용중인 EC2 인스턴스의 상태를 절전모드로 변경하면 EC2 볼륨에 있던 모든 데이터를 EBS 볼륨에 저장함
EC2 인스턴스 운영체제 입장에선 운영체제를 종료한 것이 아니라 절전모드로 두었다가 도로 킨 것이기 때문에
인스턴스 uptime에도 가장 마지막에 인스턴스를 실행한 시간이 출력되는 것

<EBS 볼륨>
EBS 볼륨은 네트워크 USB 스틱(물리적인 드라이브x)
프리티어는 매달 30 GB SSD gp2 or gp3 사용 가능
네트워크로 연동되기에 다른 컴퓨터로 전송될 때 지연이 발생할 수 있음
다른 리전으로 볼륨을 옮기는 것은 불가능하지만 스냅샷을 이용하면 다른 가용 영역으로 볼륨을 옮길 수 있음
IOPS는 단위 초당 전송 수
하나의 인스턴스에 두개의 EBS 볼륨을 연결하는건 문제 없음
종료시 삭제 라는 기능이 있음
ㄴ EC2 인스턴스의 스토리지 오른쪽 끝에 보면 있음

EBS 스냅샷 아카이브와 EBS 스냅샷 휴지통
스냅샷 아카이브는 24~72시간 이내 복구 (즉시 복구x)
EBS 스냅샷 휴지통은 실주로 삭제하는 경우 복원 가능 기간은 1일~1년 사이
FSR(빠른 스냅샷 복원)은 스냅샷을 완전히 초기화 해 첫 사용하는것처럼 지연 시간을 없애는 기능
EC2 인스턴스를 초기화 할때 유용하지만 비용 ↑

<AMI>
EC2 인스턴스를 통해 만든 이미지
AMI에다 원하는 소프트웨어 또는 설정 파일 추가, 별도의 운영체제 설치, 모니터링 툴 추가
AMI는 아마존에서 재공하는 버전이 있고, 유저가 직접 추가해서 쓸 수도 있음
유저 데이터를 사용해 만드는 EC2 인스턴스는 최초 실행 시 약간의 시간을 기다려야함
EC2 인스턴스에 이미지 생성을 눌러 이미지를 만들면 좌측에 AMIs 옵션에 AMI 이미지가 등록됨

그 후에 인스턴스 생성 시에 퀵스타트는 내버려두고 my AMIs 탭으로 가면 내가 소유한 AMI를 기반으로 인스턴스 생성 가능

EC2 인스턴스 스토어는 I/O 성능 향상을 위해 활용 가능
인스턴스를 종료하면 날라가기 때문에 버퍼나 캐시, 스크래치 데이터 또는 임시 데이터 컨텐츠를 저장할때 사용하면 됨
인스턴스가 날아가면 데이터 손실 가능성도 있어서 데이터를 복제나 백업 해두는게 좋음

<EBS 볼륨 종류>
gp2 gp3
    ㄴ 성능과 균형 범용 SSD 볼륨
Io1과 Io2 Block Express
    ㄴ 가장 높은 성능의 SSD 볼륨 ex) 미션 크리티컬, 저지연, 고처리량 작업에 사용
    ㄴ 자주 액세스하고 처리량이 많은 작업을 위해 설계
SC1 볼륨
    ㄴ 가장 저렴한 HDD 볼륨
    ㄴ 액세스빈도가 낮은 작업을 위해 설계

<루팅 볼륨으로 사용 가능한 볼륨들>
gp2, gp3, Io1, Io2만 부팅 볼륨으로 사용 가능
gp2 : 최대 3000 IOP까지 제공, 볼륨의 크기는 IOP과 연관되어 있음, 최대 5334GB(16000 IOPS)까지 제공
gp3 : 기본적으로 3000 IOP와 초당 125MB 처리량 제공, 최대 16000 IOP와 초당 처리량 1GB까지 독립적으로 증가 가능

<프로비저닝된 IOPS 볼륨>
Io1 : 4TB~16TB까지 지원하며 최대 IOP를 프로비저닝 가능, 최대 IOP는 Nitro EC2 인스턴스의 경우 약 64000이고 다른 종류의 인스턴스는 32000,
      스토리지 크기와 별도로 프로비저닝된 IOPS를 늘릴 수 있음
Io2 Block Express : 4 GB ~ 64 TB 지원, 서브 밀리초 발생, IOPS : 기가 바이트비율 -> 1000:1, 최대 IOPS 256000
                    프로비저닝된 IOP 볼륨은 EBS 다중 연결 기능 지원
위 두 볼륨은 하나의 가용영역에 여러 EC2 인스턴스에 연결할 수 있는 다중 연결 기능 활성화
ex) 클러스터링된 Linux 애플리케이션, 애플리케이션에서 동시 쓰기 작업을 관리할 때
한번에 16개의 EC2 인스턴스만 같은 볼륨에 연결 가능
다중 연결을 사용하려면 클러스터 인식 파일 시스템을 사용해야함

EBS 다중 연결 : 동일한 EBS 볼륨을 동일한 AZ에 있는 다수의 EC2 인스턴스에 연결
ㄴ 쉽게 풀자면 동일 AZ에서 하나의 EBS가 여러 EC2 인스턴스에 연결 될 수 있다는 뜻
    여러 EC2 -> 하나의 EBS 볼륨 o / 여러 EBS 볼륨 -> EC2 인스턴스 x
ㄴ io1, io2만 가능 gp2(x)

<루팅 볼륨으로 사용할 수 없는 볼륨>
ST1(HDD)
ㄴ ex) 빅데이터, 데이터 웨어하우징, 로그 처리

SC1(Cold HDD)
ㄴ ex) 아카이브 데이터용(자주 액세스 되지 않는 데이터용)
ㄴ 최대 처리량은 초당 250MB, 최대 IOPS 250

<EBS 볼륨 암호화>
1. EBS 볼륨 생성(암호화x) -> 암호화가 되지 않았다면 생성하는 스냅샷도 암호화x
2. 스냅샷 복사할 때 동일 리전에 복사할 경우 아래쪽에 암호화 버튼이 생김, 활성화 시 스냅샷 암호화됨 이때 KMS 키도 선택
3. 방금 복사한 스냅샷에서 볼륨을 생성할 때 기초가 되는 스냅샷이 암호화되어 있어서 볼륨도 자동으로 암호화

암호화 되지 않은 스냅샷을 클릭해서 볼륨을 통해 새로운 스냅샷 생성하기 -> 동일 리전 시 EBS 볼륨 암호화 활성화, 키는 aws/ebs 키 선택

<EFS>
ex) 콘텐츠 관리, 웹 서빙, 데이터 공유, Wordpress
ㄴ 가격이 비쌈(gp2 EBS 볼륨의 약 3배)
ㄴ 내부적으로 NFS 프로토콜을 사용하며 EFS에 대한 액세스 제어를 하려면 보안 그룹 설정해야함
ㄴ KMS를 사용하여 EFS 드라이브에서 미사용 암호화 활성화
ㄴ 사용량에 따라 비용 청구(완벽한 종량제)
ㄴ EFS 스케일은 NFS 클라이언트 수천 개와 10GB 이상의 처리량 확보 + PB 규모의 네트워크 파일 시스템 자동 확장

성능 모드들이 존재
범용 - 기본값
ㄴ 지연 시간에 민감한 사용 사례에 사용됨
ex)웹서버, CMS

최대 I/O 모드 - 처리량 최대화
ㄴ 지연 시간이 더 긴 네트워크 파일 시스템이지만 처리량 높고 병렬성 높음
ex)빅데이터 애플리케이션, 미디어 처리

처리량 모드들
버스팅 - 초당 50MB~100MB 버스트 더한것 / 스토리지 양에 따른 처리량
프로비저닝 - 스토리지 크기에 관계없이 처리량 설정, 1TB의 스토리지에서 초당 1GB 처리 가능
엘라스틱(종량제) - 워크로드에 따라 처리량 자동으로 조절, 워크로드를 예측하기 어려울 때 유용

<EFS 스토리지 클래스>
스탠다드 - 자주 액세스 하는 파일을 위한 계층
EFS-IA - 자주 액세스 하지 않는 용도, 저장하면 비용 감소하지만 파일 검색 시 비용 발생, 
아카이브 - 거의 액세스 하지 않는 데이터용
수명 주기 정책 구현
스탠다드 - 다중AZ 설정있는 경우 스탠다드 권장, 재해 대비
원존(EFS One Zone-IA) - 개발만 하고 싶고 더 저렴한 옵션을 원한다면 권장, 하나의 AZ에 있고 백업은 기본적으로 활성화

일반 - 엘라스틱 모드 시엔 범용 모드만 선택 가능
프로비저닝과 버스팅 - Max I/O 모드 선택 가능(빅데이터 유형의 설정)
EC2 인스턴스 생성 시 서브넷을 EFS 보안그룹을 적용한 서브넷으로 선택하면 파일 시스템에서 EFS나 FSx를 선택 가능

<고가용성과 확장성>

확장성 : 애플리케이션 시스템이 조정을 통해 더 많은 양을 처리할 수 있다는 의미
확장성은 수직 / 수평 확장성이 있음

수직 확장성 : 인스턴스의 크기를 확장
ex) 능력치가 올라가는것(업그레이드), t2.micro -> t2.large로 만들기
수평 확장성 : 애플리케이션에서 인스턴스나 시스템의 수를 늘리는 방법
ex) 분배 시스템의 확장(증축)

고가용성 : 애플리케이션 또는 시스템을 적어도 둘 이상의 AWS의 AZ나 데이터 센터에 가동중이라는 걸 의미
고가용성의 목표는 데이터 센터에서의 손실에서 살아남는 것(가동시간을 손실 없이 최대로)

수직 확장은 업그레이드 / 수평 확장은 증축의 개념 
고가용성은 가동시간 없이 손실을 최소한으로 하기 위함

<로드 밸런싱>
로드 밸런서 : 서버 혹은 서버셋으로 트래픽을 백엔드나 다운스트림 EC2 인스턴스 또는 서버들로 전달하는 역할
ㄴ 여러 서버에 트래픽을 고르게 분산시켜서 시스템의 안정성과 성능을 높이기 위해
트래픽 분산, 가용성 향상, 확장성 확보, 빠른 응답 제공 등

**CLB는 AWS에서 지원하지 않으며 시험에도 안나옴**
클래식 로드 밸런서(2009년) V1 or CLB(Classic)
ㄴ HTTP, HTTPS, TCP, SSL와 secure TCP 지원

신형 로드 밸런서(2016년) ALB(Application)
ㄴ HTTP, HTTPS, WebSocket 프로토콜 지원

네트워크 로드 밸런서(2017년) NLB(Network)
ㄴ TCP, TLS, secure TCP와 UDP 프로토콜 지원

게이트웨이 로드 밸런서(2020년) GWLB(Gateway Load)
ㄴ 네트워크 층에서 작동하므로 3계층과 IP 프로토콜에서 작동

ALB - 7계층 즉 HTTP 전용 로드 밸런서
ㄴ HTTP/2와 WebSocket 지원
ㄴ 경로 라우팅 지원
ㄴ 도커와 아마존 ECS의 경우 ALB가 가장 적합함
    ㄴ 이유는 포트 매핑 기능이 있어 ECS 인스턴스의 동적 포트로의 리다이렉션을 가능하게 해줌
ㄴ IP 주소들의 앞에 위치할 수도 있음 단 꼭 사설 IP 주소여야만 함
ㄴ 접근하려는 URL에 ?Platform=Mobile인 경우엔 모바일 대상 그룹으로 리다이렉팅 되게 하고,
   ?Platform=Desktop인 경우엔 데스크탑 대상 그룹으로 리다이렉팅 시킬 수 있음 (모바일/데스크탑 화면의 차이)

보안 그룹을 통해 EC2 인스턴스에 오는 트래픽의 허용을 로드 밸런서를 통해서만 접근 가능하게 바꿀 수 있음
ALB -> 리스너 -> 리스너 세부정보 -> 아래쪽에 보면 리스너 규칙이 있는데 이 리스너 규칙을 통해 몇가지 규칙을 추가할 수 있음

NLB - 4계층 TCP/UDP 트래픽 처리
ㄴ 초당 수백만 건의 요청을 처리할 수 있음
ㄴ 지연시간 매우 짧음
ㄴ 가용 영역당 하나의 고정 IP만 가지고 있으며 각 가용 영역에 탄력적 IP를 할당할 수 있음
Q. 애플리케이션이 하나, 두개 또는 세 개의 다른 IP로만 접근할 수 있다면? A. NLB
ㄴ 극한의 성능, TCP 또는 UDP, 고정 IP
ㄴ ALB 앞에 NLB가 올 수 있음
    ㄴ 이렇게 하는 이유는 NLB를 통해 고정 IP 주소를 얻고, ALB를 통해 HTTP 유형의 트래픽에 처리하는 모든 규칙을 적용할 수 있기 때문
ㄴ NLB 타겟 그룹이 수행하는 상태 검사에는 TCP, HTTP, HTTPS 프로토콜을 지원함

GWLB - IP패킷의 네트워크인 3계층
ㄴ 모든 트래픽이 방화벽을 통과하게 하거나 침입 탐지 및 방지 시스템에 사용
ㄴ GWLB를 생성하면 VPC에서 라우팅 테이블이 업데이트됨
    ㄴ 이 라우팅 테이블이 수정되면 모든 사용자 트래픽은 GWLB를 통과
        ㄴ GWLB는 가상 어플라이언스의 대상 그룹 전반으로 트래픽을 확산 -> 모든 트래픽이 어플라이언스에 도달 -> 트래픽 분석&처리     (방화벽같은 과정)
            ㄴ 이상이 없다면 GWLB로 보내고 GWLB로 온 트래픽 -> 애플리케이션
ㄴ **GENEVE 프로토콜을 사용해 6081번 포트를 사용할것
    ㄴ GENEVE는 네트워크 가상화 터널링 프로토콜 / 트래픽을 가상의 캡슐로 감싸서 다른 네트워크 장비로 보내주는 역할
    ㄴ 6081번 포트는 GENEVE 기본 UDP 포트
    ex) 배달 음식으로 비유하자면 음식주문(GWLB) -> 포장(GENEVE 캡슐) -> 배달(UDP 6081번 포트) -> 고객이 배달음식 수령(최종 목적지(집)에서 포장지(GENEVE 캡슐화)를 열고 음식(트래픽)을 확인)

<스티키 세션>
ㄴ 클라이언트가 로드 밸런서에 두 번의 요청을 할 때 백엔드에서 동일한 인스턴스가 요청에 응답하도록 하는 것
ㄴ ALB, NLB에서 활성화 가능
ㄴ 세션 데이터를 잃지 않도록 하는 것

쿠키는 애플리케이션 쿠키 / 지속 시간 기반 쿠키
ㄴ 이 쿠키 이름이 CloudFront에 대해 이야기할 때 고려 사항
애플리케이션 쿠키
커스텀 쿠키 -  애플리케이션 자체에서 생성하는 사용자 정의 쿠키
    AWSLAB, AWSALBAPPOR 또는 AWSALBTG는 이미 ELB 자체에서 예약되어 사용되고 있기 때문에 이름 사용x
애플리케이션 쿠키 - 로드 밸런서 자체에서 생성, 이름은 AWSALBAPP

지속 기반 쿠키 (AWSALB)
ㄴ 로드밸런서에서 생성
ㄴ 특정 지속 시간에 따라 만료되며 그 지속 시간은 로드 밸런서 자체에서 생성

로드 밸런서 -> 타겟 그룹 -> 내 타겟 그룹 -> 액션(속성 편집) -> stickness 아래 스티키세션 설정 가능

교차 영역 밸런싱(Cross-Zone Load Balancing)
on : AZ에 있는 모든 인스턴스를 커다란 하나의 풀(pool)로 보고 트래픽을 균등하게 분배하는 방식
off : 각 AZ에 트래픽을 분배 후, AZ안의 인스턴스의 개수에 따라 트래픽 분배

ALB는 기본적으로 교차 영역 밸런싱이 on
ㄴ 일반적으로 AWS에선 다른 AZ로 데이터를 옮길 때 비용을 지불하지만 ALB는 교차 영역 밸런싱 디폴트값이 on 이기에 데이터 이동 비용 발생x

NLB와 GWLB는 기본적으로 교차 영역 밸런싱이 off
ㄴ 다른 AZ로 데이터를 옮길때 디폴트가 off 라서 교차 영역 밸런싱을 on으로 활성화 시킨 후에 사용해야하기에 데이터 이동 비용 발생

<SSL/TLS>
SSL 인증서는 클라이언트 <-> 로드 밸런서 트래픽이 전송중 암호화
ㄴ SSL은 '보안 소켓 계층'을 의미하고 연결을 암호화 하는데 사용
ㄴ 만료 날짜 존재, 주기적으로 갱신해줘야 함
TLS는 새로운 버전의 SSL, '전송 계층 보안'

HTTPS를 통해 접속 -> 로드 밸런서에서 내부적으로 SSL 종료 수행, 백엔드에서 HTTP <-> EC2 인스턴스 통신(암호화x) 하지만 VPC를 이용한 프라이빗 네트워크를 사용하기에 안전하게 보호됨
로드밸런서는 X.509 인증서 사용(SSL 또는 TLS 서버 인증서)
AWS에는 이 인증서들을 관리할 수 있는 ACM(Certicate Manager)
HTTP 리스너를 구성할 때 반드시 HTTPS 리스너로 해야함

SNI(Server Name Indication)
ㄴ 클라이언트가 서버에 접속할 때 접속하려고 하는 서버(도메인)를 알려주는 서비스
ㄴ 서버는 적절한 인증서를 선택해 클라이언트에게 제시

<오토 스케일링(ASG)>
ASG(Auto Scaling Group)
수요에 따라 EC2 인스턴스를 추가하거나 제거하는 것
ㄴ 로드 밸런서와 페어링 하는 경우 ASG에 속한 모든 EC2 인스턴스가 로드 밸런서에 연결됨
    ㄴ 추가로 ELB(Elastic Load Balancer)는 상태 확인을 통해 EC2 인스턴스의 상태를 확인하고 ASG로 전달 가능
        ㄴ 이로 인해 로드 밸런서가 비정상이라 판단하는 EC2 인스턴스를 종료할 수 있어 매우 편리
ㄴ 무료이며 EC2 인스턴스와 같은, 생성된 하위 리소스에 대한 비용만 청구
ㄴ 인스턴스의 최소~최대 개수를 설정하고 최대 용량 내에서 희망 최대 용량보다 높은 숫자를 설정하면 스케일 아웃이 됨 -> 즉 EC2 인스턴스 추가
ㄴ 시작 탬플릿을 통해 생성함
ㄴ ASG 생성시에 최대 용량(Max Capacity)를 넘어서는 희망 용량을 요청할 경우 인스턴스를 생성할 수 없음
    ex) 최대 용량이 5인 ASG에 희망 용량 6을 요청하면 인스턴스를 생성할 수 없기에 아무 일도 발생하지 않음

오토 스케일링 - 스케일링 정책
동적 스케일링
1. 목표 추적 스케일링(Target Tracking) - 원하는 수치의 점유율을 설정하고 ASG가 확장/축소를 통해 이 희망 점유율 수치를 유지하는것
2. 단순 단계 스케일링(Simple/Step) - ASG에 용량을 추가하거나 제거할 때 알림이 발생하도록 하는 것
3. 예약 스케일링(Scheduled) - 알려진 사용 패턴을 기반으로 스케일링을 예상
4. 예측 스케일링(Example) - 지속적인 부하를 예측한 다음 미리 예약을 시작

스케일링 쿨다운
ㄴ ASG이 인스턴스를 확장/축소한 직후 또 다른 스케일링 액션이 발생하지 않도록 일정 시간 기다리는 시간

<RDS + Aurora + ElastiCache>
ㄴ RDS는 SSH를 통한 인스턴스 접근x / RDS 인스턴스
ㄴ RDS는 스토리지 오토 스케일링
ㄴ RDS는 기저 운영 체제나 사용자 지정 기능에 액세스x
    ㄴ 그러나 RDS Custom은 가능

읽기 전용 복제본
ㄴ 읽기 전용 복제본 최대 15개 생성 가능하며 동일한 AZ 또는 리전에 걸쳐 생성됨
ㄴ 읽기 전용 복제본과 기본 DB 사이에는 비동기식 복제가 발생함
ㄴ 복제본을 DB로 승격시켜 이용할 수 있음, 그 후에 복제본은 복제 매커니즘 탈피, 하지만 자체적인 생애 주기 보유
ㄴ 읽기 복제본은 SELECT 문만 사용 가능 (INSERT, UPDATE, DELETE 사용불가)
ㄴ 가용 영역 간의 데이터 이동에는 비용이 발생하는데 RDS 복제본은 비용이 발생하지 않음
    ㄴ 이는 RDS가 관리형 서비스이기 때문에 복제 트래픽이 다른 가용 영역으로 넘어가도 비용 발생x
    ㄴ 하지만 다른 리전으로 복제할 경우 네트워크 비용에 대한 복제 비용 발생

다중 AZ - 재해 복구
ㄴ 동기식으로 가용 영역의 DB를 복제하여 마스터 DB의 모든 변화를 동기적으로 복제
ㄴ 하나의 DNS 이름으로 통신하여 마스터에 문제 발생 -> 백업용 동기식 DB 사용 으로 재해 복구
ㄴ 단일 AZ -> 다중 AZ 전환 가능하고 다운타임x

RDS Custom
ㄴ 지원하는 데이터베이스 유형은 Oracle, MSSQL
ㄴ 내부 설정 구성, 패치 적용 그리고 네이티브 기능 활성화 가능
ㄴ SSH 또는 SSM 세션 관리자를 사용하여 RDS 뒤에 있는 기저 EC2 인스턴스에 액세스 가능

RDS Vs RDS Custom
ㄴ RDS는 데이터베이스 전체를 관리, 운영체제와 나머지는 AWS에서 관리
ㄴ RDS Custom은 Oracle, MSSQL Server에서만 사용가능, 기저 운영 체제와 데이터베이스에 대한 관리자 권한 가짐
* 기저 운영 체제란? : DB가 설치되어 돌아가는 기반이 되는 운영체제 ex) Amazon RDS는 AWS가 관리하는 리눅스 기반 OS 위에서 실행됨

Aurora
ㄴ AWS 고유 기술(오픈소스x)
ㄴ postgres 및 MySQL과 호환됨
ㄴ Aurora 스토리지는 자동 확장(최대 128TB)
ㄴ 읽기 전용 복제본은 15개까지 만들 수 있음
ㄴ 다중 AZ나 RDS보다 재해 복구 속도가 훨씬 빠름
ㄴ 3개의 AZ에서 무언가를 기록할때마다 6개의 사본 저장
    ㄴ 쓰기에는 6개중 4개만 동작하면 ok / 읽기에는 6개중 3개만 동작하면 ok
        ㄴ> 가용성이 높다는 특징
ㄴ 일부 데이터가 손상되거나 문제가 있으면 백엔드에서 P2P 복제를 통한 자가복구
ㄴ 백트랙(BackTrack) : 데이터베이스를 과거의 특정 시점으로 빠르게 되돌리는 기능 ex) SQL 실수 취소, 반복 테스트, 임시 롤백 등
ㄴ 라이터(Writer) 엔드포인트 : DNS 이름으로 항상 마스터를 가르키는 것 ex) 장바구니 담기, 결제 등
ㄴ 장애 조치 후에도 클라이언트는 라이터 엔드포인트에 의해 올바른 인스턴스로 자동으로 리다이렉트됨
ㄴ 리더(Reader) 엔드포인트 : 모든 읽기 전용 복제본과 자동으로 연결됨(== 연결 로드 밸런싱에 도움이 됨) ex) 책 상세 페이지 조회 등
    ㄴ 세션 지속성이 없음
    ㄴ 쓰기 불가능 오로지 읽기만

RDS 백업
ㄴ 자동으로 매일 데이터베이스의 전체 백업을 수행
ㄴ 5분마다 트랜잭션 로그가 백업되기에 가장 빠른 백업은 5분 전의 백업
ㄴ 자동 백업 기간은 1~35일까지 설정 가능, 0일로 설정하면 자동 백업을 사용하지 않겠다는 의미
ㄴ 수동 DB스냅샷 기능도 있음, 수동으로 한 백업을 원하는 기간 동안 유지 가능
    ㄴ S3에 업로드된 백업 파일을 이용해 RDS 인스턴스에 데이터베이스 복원 가능

Aurora 백업
ㄴ 자동화된 백업 존재, 1~35일까지 설정 가능, 하지만 비활성화 불가능(RDS는 비활성화o)
ㄴ 백트랙 기능 존재 (원하는 시점으로 돌아가는 기능)
ㄴ 수동 DB 스냅샷 
    ㄴ Percona ExtraBackup을 통해 Aurora MySQL 클러스터에 백업 생성 -> S3에 저장(업로드) -> Aurora MySQL 클러스터에 복원 -> 복원 완료 후 데이터베이스 활성화(읽기/쓰기 접근 가능)
ㄴ COW(Copy-On-Write) 프로토콜을 이용한 복제
    * COW(Copy-On-Write)
        ㄴ 데이터 복제하는 시점에 변경 사항이 있으면 복사본 생성, 없으면 생성x (스냅샷과 비슷)
        ㄴ 원본 데이터에 변동 사항이 있을때 복사본을 생성해 사용하기에 파일 시스템, 가상 메모리, 데이터베이스, 컨테이너화된 환경(Docker) 등에 사용
        ㄴ 데이터 변경시마다 복사본을 생성하기에 쓰기 성능 저하, 복사본 개수↑ -> 저장 공간 차지하는 비율↑

RDS & Aurora 보안
ㄴ KMS를 사용해 마스터와 모든 복제본의 암호화, 첫 시작시 암호화 하지 않았다면 기존 DB, 읽기 전용 복제본의 암호화를 할 수 없음
ㄴ RDS 및 Aurora는 전송중 암호화 기능을 갖추고 있음 클라이언트는 데이터베이스에 액세스 하기 위해 대표적으로 아래 3가지 방법을 선택해서 사용
    ㄴ TLS 루트 인증서
    ㄴ IAM 역할
    ㄴ 보안 그룹
ㄴ SSH 액세스x
ㄴ 감사 로그를 활성화하면 RDS 및 Aurora에서 어떤 쿼리가 생성되고 있는지 데이터베이스를 확인할 수 있음
    ㄴ 로그를 장기간 보관하고 싶다면 AWS CloudWatch Logs에 전송하면됨

RDS 프록시
    * 프록시(Proxy)
        ㄴ중계 서버로 클라이언트와 서버 간의 중간에서 요청과 응답을 중계하는 역할을 함 ex) 보안, 성능 최적화, 접근 제어 등
        ㄴ 클라이언트의 요청을 직접 서버로 보내지 않고 요청을 대신 처리하여 결과를 반환하는 방식
            ㄴ 포워드(클라이언트) : 클라이언트 -> 프록시 서버 -> 외부 서버 순으로 통신 / 실사례로 기업 네트워크에서 직원들이 인터넷에 접근할 때 ex) 인터넷 필터링, 캐싱, 익명성 보호
            ㄴ 리버스(서버) : 서버 -> 리버스 프록시 서버 -> 클라이언트 / 웹서버가 여러개일 때 클라이언트가 어떤 서버에 연결하는지 알 수 없게 할 때 ex) 부하 분산, SSL 종료, 보안, 캐싱
            ㄴ VPN(가상 사설망) : 클라이언트 <-> 서버 간의 연결 암호화 ex) 원격 근무, 익명성 보호, 지역 우회 
ㄴ RDS 프록시를 사용하면 일일이 RDS DB 인스턴스에 연결하는 대신 프록시가 하나의 풀에 연결을 모아 RDS 인스턴스로 가는 연결이 줄어듬
ㄴ RDS 인스턴스에 연결이 많은 경우 CPU, RAM 등 데이터베이스 리소스의 부담을 줄여 데이터베이스 효율성 향상 및 개방된 연결과 시간초과를 최소화할 수 있기 때문
ㄴ 완전한 서버리스
ㄴ 오토스케일링을 통해 용량 관리 필요x 가용성↑
ㄴ 다중 AZ 지원
ㄴ 장애조치시 대기 인스턴스가 실행되며 장애 조치 시간을 66%까지 줄일 수 있음
    ㄴ 애플리케이션이 직접 처리하지 않고 RDS 프록시가 장애조치를 해 애플리케이션 상관x, 장애 조치 대응 부담↓
ㄴ IAM 인증을 강제함으로써 IAM 인증을 통해서만 DB에 액세스 가능
    ㄴ 이때 자격 증명은 AWS Secrets Manager 서비스로 함
ㄴ RDS는 퍼블릭 액세스가 절대 불가능한데 VPC 내에서만 액세스 가능함 그렇기에 보안이 훌륭한편

Amazon ElastiCache (를 이용한 검색 및 로그 분석용 Amazon OpenSearch도 있음)
ㄴ 관리형 Redis, Memcached 제공하여 캐시 기술을 활용할 수 있음
ㄴ 캐시 무효화를 사용자의 의도에 맞게 맞춤형으로 수정해서 쓸 수 있는 탬플릿 같은 기능
ㄴ 애플리케이션에서 쿼리문을 실행할 때 ElastiCache에 쿼리문이 저장된 경우 이를 캐시히트라고 하며 바로 ElastiCache에서 답을 얻어 수정함
   캐시 미스의 경우엔 데이터베이스에서 직접 데이터를 가져와야함
   RDS 데이터베이스에 부하를 줄이는 데 도움이 되지만 데이터를 캐시에 저장하기 때문에 항상 최신 데이터를 사용할 수 있도록 캐시 무효화 전략이 필요
ㄴ 사용자 로그인 상태 유지 시에도 ElastiCache를 사용해 세션을 가져옮으로 애플리케이션 상태 비저장으로 만들 수 있음

ElastiCache 보안
ㄴ Redis에서만 IAM 인증 지원, 나머지 경우엔 사용자 이름과 비밀번호 사용
ㄴ IAM 정책을 정의하면 AWS API 수준 보안만 적용
ㄴ Redis AUTH라는 Redis 내 보안을 통해 비밀번호 토큰 설정 가능
ㄴ SSL 전송중 암호화 지원
ㄴ Memcached는 SASL 기반 승인 제공 (이름만 기억)
ㄴ ElastiCache에 데이터를 로드하는 패턴 3가지
    1. 지연 로딩(Lazy Loading) : 모든 데이터가 캐시되고 데이터가 캐시에서 지체될 수 있음
    2. Write Through : DB에 데이터가 기록될 때마다 캐시에 데이터를 추가하거나 업데이트 하는 것
    3. Write Behind : 캐시에 먼저 쓰고, 일정 시간 뒤에 비동기적으로 DB에 반영하는 방식

<Route 53>
DNS amazon.com <- 에서 마지막 "."을 도메인 이름의 루트, .com은 TLD(최상위 도메인)
ㄴ 100% SLA 가용성을 제공하는 유일한 AWS 서비스
    *SLA 가용성 : 서비스가 정상적으로 운영되는 시간을 퍼센트로 표시한 서비스 신뢰성 보장 수치
ㄴ 레코드 종류로 A, AAAA, CNAME, NS 정도 알고 있으면 됨
    A : 호스트 이름과 IPv4 매핑 ex) example.com은 1.2.3.4에 연결
    AAAA : 호스트 이름을 IPv6에 매핑 ex) example.com은 2001:db8::1에 연결
    CNAME : 호스트 이름을 다른 호스트 이름과 매핑 ex) www.example.com -> example.com에 연결
    NS : 호스팅 존의 이름 서버 ex) example.com -> ns-123.awsdns-45.org
ㄴ 호스팅 존엔 두가지 종류가 있는데 퍼블릭과 프라이빗 호스팅 존이 존재
    퍼블릭 존 : 쿼리에 도메인 이름의 IP가 무엇인지 알 수 있음
    프라이빗 호스팅 존 : 공개되지 않은 도메인 이름 지원
        ㄴ 가상 프라이빗 클라우드(VPC)만이 URL을 리졸브 할 수 있음
    ㄴ 호스팅존은 월에 50센트를 지불해야함 (무료x)
ㄴ 도메인을 타사 등록 대행사에서 구매해도 DNS 서비스 제공자로 Route53을 사용 가능

TTL 
데이터나 정보가 얼마나 오래 유효한지를 정하는 시간 또는 횟수
ㄴ 정해둔 시간동안 컴퓨터에 캐시가 저장되어 값을 불러오는 방식으로 레코드의 값이 변경되어도 TTL의 시간이 만료되기 전까진 변경 전 값을 불러옴

CNAME과 Alias의 차이점
ㄴ CNAME은 루트 도메인이 아닌 경우, 호스트 A -> 호스트 B 지정 가능
ㄴ Alias는 호스트 이름 -> 특정 AWS 리소스 지정 가능(EC2 DNS 이름은 x), 무료, 자체적으로 확인 가능
ㄴ Alias는 루트 및 비루트 도메인에 모두 작동
ㄴ Alias 레코드를 사용하면 TTL 설정x (Route 53에 의해 자동으로 설정)
ㄴ Alias 레코드의 대상으로는 ELB, CloudFront, API Gateway, Elastic Beanstalk, 버킷이 웹사이트로 활성화시 S3(기본 S3는 x), Global Accelerator 등

Route53 라우팅
ㄴ 단순, 가중치 기반, 장애 조치 지연 시간 기반, 지리적, 다중 값 응답, 지리 근접 라우팅 정책
    1. 단순 라우팅 정책은 트래픽 -> 단일 리소스로 보내는 방식 foo.example.com으로 가고자 한다면 Route53이 IP 주소를 알려줌(=A 레코드)
       DNS에 의해 여러 개의 값을 받은 경우엔 클라이언트 쪽에서 그 중 하나를 무작위로 고르게됨
       Alias 레코드를 함께 사용하면 하나의 AWS 리소스만을 대상으로 지정 가능
       간단하기에 단순 정책, 그렇기에 상태 확인x
    2. 가중치 라우팅 정책 -> 가중치를 활용해 요청의 일부 비율을 특정 리소스로 보내는 식의 제어가 가능
       서로 다른 지역에 로드밸런싱 할때나 적은 양의 트래픽을 보내 새 어플리케이션을 테스트 하는 경우 사용
       A B C 인스턴스가 있을 때 A 70%, B 20%, C 10%로 트래픽을 보내고 싶을때 사용(가중치의 합이 100이 아니여도 ok)
    3. 지연 시간 기반 라우팅 정책 -> 지연 시간(레코드로 가장 가까운 식별된 AWS 리전에 연결하기까지 걸리는 시간)이 가장 짧은 즉 가장 가까운 리소스로 리다이렉팅 하는 정책
       지연 시간에 민감한 웹사이트나 애플리케이션이 있는 경우 유용함
    4. 장애 조치 라우팅 정책 -> 기본과 보조 유형의 레코드 타입을 선택해 기본 레코드에서 장애 발생시 보조 레코드에서 장애 조치
    5. 지리적 위치 라우팅 정책 -> 사용자의 실제 위치에 따라 특정 리전으로 트래픽을 보내는 방식 ex) 지역별로 다른 콘텐츠나 서비스를 제공하고 싶을 때 사용(넷플릭스)
    6. 지리 근접 라우팅 정책 -> 사용자의 위치와 서버 리전 사이의 물리적 거리를 계산해서 가까운 리전(or 서버)으로 보내는 방식 ex) 금융앱, 쇼핑몰 서비스(쿠팡, 마켓컬리), 영상 스트리밍
       bias를 이용한 가중치 값을 조절해 특정 리전으로 트래픽을 의도적으로 보낼 수 있음 ex) 서울과 부산 서버가 있는데 서울 서버가 더 고사양이라 더 많은 트래픽을 서울로 보내고 싶을 때
    7. IP 주소 기반(CIDR) 라우팅 정책 -> 사용자의 IP 주소 범위를 기준으로 특정 응답을 보내도록 설정
    8. 다중 값 라우팅 정책 -> 트래픽을 다중 리소스로 라우팅 할 때 사용

Route53 상태확인
공용 리소스에 대한 상태를 확인하는 방법, 개인 리소스 확인하는 방법 또한 존재
ㄴ 엔드포인트 모니터링
    ㄴ 전 세계에서 온 15개의 상태 확인이 엔드포인트의 상태를 확인하고 임계값을 정상 or 비정상으로 설정 (HTTP, HTTPS, TCP 등 많은 프로토콜을 지원)
    ㄴ 18% 이상의 상태 확인이 정상이라 판단 -> 정상, 그렇지 않다면 비정상
    ㄴ 위치도 선택 가능
    ㄴ 로드밸런서로부터 2xx나 3xx의 코드를 받아야만 통과
    ㄴ 텍스트 기반 응답일 경우 첫 응답에 5120 바이트를 확인
    ㄴ 네트워크 관점에서 상태 확인 작동 여부를 확인하려면 ALB나 엔드포인트에 접근이 가능해야함 => Route53의 상태 확인 IP 주소 범위에서 들어오는 모든 요청을 허용해야 함(비공개 VPC 엔드포인트나 EC2 웹서버라면 보안 그룹을 열어줘야함)
ㄴ 계산된 상태 확인(Calculated Health Check), 계산된 상태 확인이란 여러 상태 확인 결과를 종합해 최종적으로 살아있는지 판단하는 기능
    여러 상태 확인의 결과를 OR, AND, NOT으로 조합해 최종 상태를 판단함
ㄴ 개인 리소스 상태 확인(Private Hosted Zone)
    ㄴ Route53의 상태 확인이 공용 웹에 존재하기에 VPC 외부에 위치 -> 개인 엔드 포인트 접근x
    ㄴ 그렇기에 CloudWatch 지표를 만들어 CloudWatch 알람을 할당, ALARM 모드 일 때 Route53이 비정상이라 간주하고 트래픽 차단

<Elastic Beanstalk>
용량 프로비저닝, LB 구성, 자동 확장, 애플리케이션 안정성 모니터링과 인스턴스 구성 등을 자동으로 처리해주는 관리형 서비스
ㄴ Elastic Beanstalk 서비스는 무료지만 사용하는 인스턴스나 ASG, ELB 등에 대한 비용은 청구
ㄴ 개발, 테스트, 프로덕션 등의 여러 애플리케이션을 생성 가능
ㄴ 환경 내에서는 하나의 버전만 사용 가능, 환경 내에서 버전 업그레이드 가능
ㄴ 버전 업로드하고 애플리케이션 환경 시작 -> 애플리케이션 생애 주기 관리 가능
ㄴ 개발 목적에 적합한 단일 인스턴스 ex) 개인 개발용 웹앱, 기능 테스트 중인 프로토타입
    ㄴ 탄력적 IP를 가진 EC2 인스턴스, ASG, LB 없음
    ㄴ RDS 사용 가능
ㄴ 운영(프로덕션) 환경에 적합한 로드 밸런서 + 오토스케일링 환경 ex) 다수의 사용자가 접속하는 실서비스(이커머스, 동영상 플랫폼 등), 장애에 민감한 기업용 웹 애플리케이션
    ㄴ ELB를 통한 트래픽 분산
    ㄴ ASG로 인스턴스수 수 자동 조정
    ㄴ Multi AZ RDS 구성
    ㄴ 여러 가용 영역에 인스턴스 배치 -> 고가용성 확보

<고급 S3>
수명 주기 규칙(Lifecycle rules)
ㄴ Transition Actions / 객체를 다른 스토리지 클래스로 자동 전환시키는 작업 ex) 저장 비용 최적화, 자주 접근하지 않는 데이터를 더 저렴한 스토리지로 옮기기 위함
ㄴ Expiration Actions / 설정된 시간 이후에 객체를 자동 삭제하는 작업
    ㄴ 업로드 후 365일이 지난 객체 자동 삭제, 특정 태그가 달린 객체만 90일 후 삭제
    ㄴ 모든 파일 버전을 삭제 -> 이걸 이용하면 불완전한 멀티파트 업로드도 삭제 가능(업로드가 2주 이상 된 경우에도 완료되지 않은 경우 삭제 가능)
    ㄴ 버전 관리가 활성화 된 경우 delete marker, non-currrent version에 대한 만료도 설정 가능

S3 요청자 지불(S3 Requester Pays)
일반적으로 S3 스토리지 및 데이터 전송 비용을 버킷 소유자가 지불하였음, 그러나 대형 파일의 경우엔 이야기가 다름 
ㄴ 대형 파일이 있고 일부 고객이 이를 다운로드 하고자 할 때 버킷 소유자가 아닌 요청자가 객체 데이터 다운로드 비용 지불
ㄴ 대량의 데이터셋을 공유하려고 할 때 사용함
    ㄴ 요청자는 익명x AWS에서 인증을 받아야 함

S3 이벤트 알림
객체가 생성, 삭제, 복구, 복제 등 객체 상태에 변화가 생겼을 때 이벤트가 발생했다고 하고 이를 필터링 할 수 있음
ㄴ 이벤트 알림이 작동하려면 IAM 권한을 갖고 있어야 함
ㄴ 추가 서비스(SNS, SQS, 람다)를 사용해서 이벤트 알림을 설정해도 이벤트는 S3 버킷으로 감 -> 모든 이벤트는 Amazon EventBridge를 통함

S3 퍼포먼스
ㄴ 100MB가 넘는 파일에는 멀티파트 업로드를 사용하는 것이 좋음, 5GB가 넘어갈 시 반드시 사용해야함
    ㄴ 멀티파트 업로드는 업로드를 병렬화 -> 전송속도↑ -> 대역폭 최대화
ㄴ S3 전송 가속은 파일을 AWS 엣지 위치로 전송 => 전송속도↑
        *엣지 위치 : 데이터 전송 지점
    ㄴ 전송 가속은 공공 인터넷의 사용량을 최소화하고 프라이빗 AWS 네트워크의 사용량을 최대화

S3 바이트
파일의 특정 바이트 범위를 가져와 가져오기를 병렬화 하는 것
ㄴ 특정 바이트 범위를 가져오는데 실패한 경우 더 작은 바이트 범위를 다시 시도할 수 있음
ㄴ 실패시 복원력 향상 -> 다운로드 속도를 높이는데 사용

S3 Batch Operations
단일 요청으로 기존 S3 객체에서 대량 작업을 수행하는 서비스
ㄴ S3 버킷 내 암호화되지 않은 모든 객체를 암호화할 수 있음
ㄴ ACL이나 태그를 수정하지 않고 S3 Glacier에서 한 번에 많은 객체를 복원할 수 있음
ㄴ 람다 함수를 호출해 S3 Batch Operations의 모든 객체에서 사용자 지정 작업을 수행할 수 있음
ㄴ 객체 작업에서 원하는 작업은 무엇이든지 수행할 수 있음
ㄴ 직접 하지 않고 Batch Operations을 쓰느냐?
    ㄴ 재시도를 관리할 수 있고
    ㄴ 진행 상황을 추적하고 작업 완료 알림을 보내고 보고서 생성 등을 할 수 있음
ㄴ S3 Inventory라는 기능을 사용해 객체 목록을 가져오고 S3 Select를 사용해 객체를 필터링함
ㄴ 주요 사용 사례는 S3 Inventory를 사용해 암호화되지 않은 모든 객체를 찾아 S3 Batch Operations를 사용해 한번에 모두 암호화 하는 것

S3 스토리지 렌즈(Storage Lens)
S3 사용량 및 스토리지 상태를 시각적으로 분석, 비용 최적화 및 성능 개선을 위한 인사이트를 제공하는 도구
ㄴ 이상 징후를 발견하고 비용 효율성 파악
ㄴ 전체 AWS 조직에 보호 모범 사례 적용
ㄴ 30일 사용량 및 활동 메트릭 제공
ㄴ 조직 계정, 지역 버킷, 접두사별로 데이터를 집계해서 데이터 분석에 도움이 되는 보고서로 집계
    ㄴ 요약 인사이트, 데이터 보소, 비용 효율성을 위해 보고서를 전송하여 S3 사용 최적화
ㄴ 기본 대시보드 제공
    ㄴ 무료 및 고급 지표에 대한 요약된 인사이트와 트렌드 확인, 여러 지역과 여러 계정의 데이터가 표시 -> 필터 설정 필요x
    ㄴ 삭제x 원하는 경우 비활성화o
    ㄴ 중앙 집중식 구성

S3 스토리지 렌즈 메트릭 종류
무료 메트릭과 유료 메트릭으로 나뉨
유료 메트릭의 경우 CloudWatch에 추가 비용 없이 액세스 가능
    ㄴ S3 버킷 내의 접두사 수준에서 메트릭 수집가능
    ㄴ 결제 시 데이터는 15개월 동안 사용 가능

요약 메트릭 (기본)
    ㄴ 일반적인 인사이트 제공
    ㄴ 스토리지 용량, 객체 수, 객체 평균 크기, 활성화된 버킷 수 등을 요약
비용 최적화 메트릭 (기본 + 고급)
    ㄴ 현재 버전이 아닌 버전에 대한 정보 제공
    ㄴ 최신이 아닌 버전의 객체 수, 실제로 차지하는 공간 또는 불완전한 멀티파트 업로드 스토리지 바이트 수 등을 요약
    ㄴ 스토리지 클래스 활용도와 비효율 식별
데이터 보호 메트릭 (기본 + 고급)
    ㄴ 암호화/암호화 되지 않은 객체 용량
    ㄴ 복제 여부에 따른 객체 용량
    ㄴ 이전 버전 객체 만료/삭제 수
    ㄴ 암호화, 복제 상태 등 데이터 안전성 관리
액세스 관리 메트릭 (고급)
    ㄴ 버킷이 현재 어떤 객체 소유권을 설정하고 있는지 식별
    ㄴ 퍼블릭 접근 허용된 버킷 수, 버킷 정책에 의한 접근 허용 상태, ACL 사용 여부 확인
이벤트 메트릭 (고급)
    ㄴ S3 이벤트 알림에 대한 인사이트를 얻고 S3 이벤트 알림이 구성된 버킷의 수 파악
퍼포먼스 메트릭 (고급)
    ㄴ S3 전송 가속에 대한 인사이트를 얻고, S3 전송 가속이 활성화된 버킷의 수 확인
액티비티 메트릭 (고급)
    ㄴ 요청수, 업로드/다운로드된 바이트 수, 요청 오류 수 등
    ㄴ 객체에 대한 작업 및 트래픽 활동 식별
Detail Status Code 메트릭 (고급)
    ㄴ 상태 코드별 응답 수(200OKStatus Count, 403ForbiddenErrorCount)
    ㄴ 요청 제한 발생 수 ex)503 Slow Down

<S3 암호화>
서버 측 암호화(SSE)
S3에서 관리하는 키를 이용한 서버측 암호화 (기본값)
SSE KMS, KMS 키를 이용해서 암호화 키를 관리
SSE-C키, 고객이 제공한 키 사용
클라이언트 측 암호화

S3 > SSE-S3
AWS 처리하고 관리하고 소유한 키를 이용해 암호화
ㄴ 키에 액세스 x
ㄴ 서버측 암호화, 암호화 보안 유형은 AES-256

SSE KMS (SSE라고 적힌건 전부 서버측 암호화) / DSSE-KMS는 KMS를 기반으로 한 이중 암호화, 시험에 출제되지 않으나 이름 정도는 알아두면 좋음
ㄴ 사용자가 키를 통제할 수 있다는 장점
ㄴ CloudTrail을 이용해 키 사용 검사 가능
ㄴ 자체 API 키가 있고 이를 이용해 복호화를 하기에 API 호출을 필요로 함
ㄴ S3 버킷의 처리량이 아주 많고 모든게 KMS키로 암호화 되어 있다면 KMS API 요청 한도에 도달했을때 생기는 현상인 스로틀링 현상이 발생할 수 있음

SSE-C (콘솔이 아니라 CLI에서 다뤄야 함)
키가 AWS 외부에서 관리되지만 서버측 암호화, 이유는 키 -> AWS 전송
ㄴ 사용한 암호화 키는 폐기됨
ㄴ 키를 S3로 전송하기 때문에 HTTPS를 사용 -> 모든 요청에 HTTP 헤더의 일부로서 키 전달 필요

클라이언트 측 암호화(Client-Side Encryption)
클라이언트가 데이터를 직접 암호화 후 -> S3에 전송
ㄴ 데이터 복호화는 S3 외부의 클라이언트 측에서 이루어짐
ㄴ 의료, 금융, 공공기관 등 규제가 엄격한 곳에서 사용
ㄴ 키 분실 시 복구 불가

CORS(Cross-Origin-Resource Sharing) 교차 오리진 리소스 공유
웹 브라우저에서 다른 도메인의 리소스에 접근할 수 있게 해주는 메커니즘
ㄴ 오리진이 다른 경우 사용
    ㄴ 오리진 - 체계(프로토콜)ㆍ호스트(도메인) 포트로 구성

ex) 정적 웹페이지 호스팅하는 버킷 mybucket, 이미지가 저장된 mybucket/images
    브라우저에서 S3 mybucket에게 이미지 요청 -> S3는 CORS 정책 확인 -> S3 응답 헤더에 리소스에 접근하는 권한 여부 확인 -> 권한o 이미지 렌더링 / 권한x 이미지 로드 실패

MFA Delete
추가 보호 기능, 특정 객체 버전의 영구 삭제를 방지하는 역할
ㄴ 객체 버전을 영구적으로 삭제할 때, 버킷에서 버저닝을 중단할 때 MFA가 필요

S3 액세스 로그
감사 목적으로 S3 버킷에 대한 모든 액세스를 기록
ㄴ Amazon Athena 같은 데이터 분석 도구로 분석 가능
ㄴ 로깅 버킷은 같은 AWS 리전에 있어야 하며 로깅 버킷 = 모니터링 버킷 동일 설정x
    ㄴ 동일하면 로깅 루프 생성되고 무한 반복되어 버킷의 크기가 기하급수적으로 증가

S3 미리 서명된 URL(Pre-Signeed URLs)
S3 콘솔, CLI, SDK를 사용하여 생성할 수 있는 URL
ㄴ S3 콘솔로 생성 시 최대 12시간, CLI로 생성 시 168시간까지 사용 가능
ㄴ 사용 사례로는 AWS 외부의 사용자에게 한 파일에 대한 액세스 권한을 부여해야할 때 미리 서명된 URL를 생성하고 제공해 해당 파일에만 액세스 권한을 부여하고, 
   권한이 부여된 시간 동안 S3 버킷에서 파일에 액세스 할 수 있고, 만료 기간 후엔 S3 버킷에서 파일을 다시 가져옴

S3 Glacier Vault Lock
객체를 가져와서 S3 볼트에 넣은 다음 수정이나 삭제할 수 없도록 잠그는 것
ㄴ Glacier 위에 볼트 잠금 정책을 생성 -> 향후 편집을 위해 정책을 잠금
ㄴ 볼트 잠금 정책을 성정하고 잠근 후엔 누구도 변경이나 삭제x -> 규정 준수와 데이터 보존에 유용
ㄴ 객체를 절대 삭제x(관리자 or AWS 서비스 사용해도 안됨)

유사한 기능으로 S3 Object Lock(Versioning 필수)
여기서 WORM 모델 채택
    WORM : '한번 쓰고 여러번 읽는다'는 뜻
ㄴ 버킷 내의 모든 객체에 각각 적용할 수 있는 잠금
ㄴ 특정 시간 동안 삭제되는걸 차단
두가지 모드로 규정 준수 모드와 거버넌스 보존 모드
    규정 준수 모드 ex) 규정 준수를 엄격히 적용할 때 사용
    ㄴ S3 Glacier Vault Lock과 거의 동일
    거버넌스 보존 모드
    ㄴ 관리자 or 일부 권한을 받은 IAM 사용자는 객체의 보존 기간을 변경 or 바로 삭제 가능
두 모드 모두 보존 기간 필요
법적 보존 설정 시 보존 모드나 기관에 상관x 객체가 영구적으로 보호됨

S3 엑세스 포인트
S3 액세스 포인트는 S3 버킷에 대한 접근 경로를 따로 분리해서 설정할 수 있도록 하는 기능
ㄴ S3 버킷의 보안 관리를 간소화, 각각의 액세스 포인트는 각자의 DNS 이름을 가짐 -> 각자의 DNS로 액세스 포인트에 접속
ㄴ 특정 유저/앱마다 별도 접근 경로 제공

S3 객체 람다
S3의 객체를 반환하기 전에 Lambda 함수를 통해 실시간으로 가공 처리할 수 있게 해주는 기능
ㄴ S3에 저장된 데이터의 원본은 그대로 두고, 가공된 형태로 반환하고 싶을때 사용

<CloudFront>
CDN, 서로 다른 엣지 로케이션에서 미리 캐싱하여 읽기 성능을 높이는 것
CloudFront로 접근하는 방식에는 두가지가 있는데 둘 다 퍼블릭이여야 함
    ㄴ 첫번째는 CloudFront와 EC2 인스턴스 둘이 퍼블릭이여야 하고 공용IP가 CE2에 접근할 수 있또록 보안 그룹을 설정해주는 방법
    ㄴ 어플리케이션 로드 밸런서를 사용해 연결하는 방법 (이때 EC2 인스턴스는 프라이빗 설정해도 무관 그 이유는 EC2 인스턴스 -> LB 허용 -> 엣지 로케이션 접근)
ㄴ GeoIP 데이터베이스를 사용함 지리적 제한을 둘 수 있는데 보안탭에서 허용 지역 / 비허용지역 으로 나누어 특정 지역의 CloudFront를 차단할 수 있음
엣지 로케이션마다 전송 비용이 다름(운영 비용 차이, 지역 경제나 환율, 정책 및 세금 등의 이유가 있음)
ㄴ 더 많은 데이터가 전송될수록 비용↓
엣지 로케이션 수를 줄이는 세가지 방법
ㄴ 1. Price Class All, 모든 리전을 사용하며 최상의 성능을 제공하는
ㄴ 2. Price Class 200, 대부분의 리전을 지원하지만 가장 비싼 리전은 제외하는
ㄴ 3. Price Class 100, 가장 저렴한 리전만 사용 

CloudFront 캐시 무효화
항상 백엔드 오리진이 존재
ㄴ /대상 파일 로 특정 파일 무효화 ex) /index.html <- index 파일 캐시 초기화
ㄴ /* 로 전체 캐시 초기화

유니캐스트와 애니캐스트 IP
유니캐스트 IP = 하나의 서버가 하나의 IP 주소를 가짐, 1:1 대응 ex) 특정 친구 집에 찾아가는 것
애니캐스트 IP = 하나의 서버가 다수의 IP 주소를 가짐, 1:N 대응 ex) 가장 가까운 스타벅스 지점을 찾아가는 것 (스타벅스 라는 브랜드 중 내 기준 가장 가까운 지점)

Global Accelerator
애니캐스트 IP 방식을 사용해 네트워크 트래픽을 최적화
ㄴ 두 개의 고정 IP 주소 제공 (그 이상 추가x)
    ㄴ 두 개를 제공하는 이유는 이중화(가용성 + 장애 복원력 증가), 경로 다양성, 멀티 리전 분산 등의 이유
    ㄴ 이 IP는 ALB, NLB, EC2 인스턴스와 연결o , 실제 내부의 EC2 인스턴스나 LB는 사설 IP 사용 가능
ㄴ 아무것도 캐시하지 않기에 캐시 문제x
ㄴ 상태 확인 기능이 있으며 ALB에 대해 상태 확인을 실패하면 자동화된 장애 조치가 이루어지고 정상 엔드포인트로 실행됨

CloudFront와 Global Accelerator의 차이점
ㄴ CloudFront는 이미지나 비디오처럼 캐시 가능한 내용과 API 가속 및 동적 사이트 전달 같은 성능 향상에 사용
    ㄴ 대부분의 경우에 CloudFront는 엣지로부터 캐시된 내용을 가져옴, 즉 엣지 -> 캐시확인 -> 콘텐츠 가져오기 -> 브라우저 출력
ㄴ Global Accelerator는 TCP나 UDP상의 다양한 애플리케이션 성능 향상
    ㄴ 트래픽 라우팅에 집중하며 캐싱x
    ㄴ 하나 이상의 AWS 리전에서 실행되는 애플리케이션으로 전달(프록시)
        *프록시 : 사용자 또는 클라이언트가 다른 네트워크 서비스에 접속할 때 중계 역할을 하는 서버 또는 프로그램
    ex) 게임, IoT, VoIP, 비 HTTP 사용 시 사용

<Snowball Family>
연결이 제한적이거나 대역폭이 제한적이거나, 네트워트 비용이 매우 높거나, 대역폭을 공유 중이라 라이선스를 극대화 할 수 없거나, 연결 안정성에 문제가 있는 경우 snow Family 사용
ㄴ 데이터 전송하는데 일주일 이상 걸리는 겅유 snowball 장치 사용
휴대용 저장장치 콘과 볼 엣지
snowcone(8~14TB) -> snowball edge(80~210TB)
스노우볼 엣지 디바이스의 경우 EC2 인스턴스나 람다 함수를 직접 실행할 수 있음

휴대용 저장장치와 AWS 간의 통신
콘솔 -> 스노우볼 디바이스 요청 -> 서버에 스노우볼 클라이언트 or AWS OpsHub라는 것을 설치하여 데이터 전송 -> 스노우볼 장치를 서버에 연결 -> 클라이언트 복사 시작
ㄴ 스노우볼 디바이스 -> S3 데이터 전송 시 수명 주기 정책을 사용해 두었다면 S3 Glacier로 옮기는게 가능(S3에 전송된 데이터의 스토리지 계층을 이동시키는 것이 가능, 바로 스노우볼 디바이스 -> S3 Glacier 는 안됨)

엣지 컴퓨팅
엣지 위치에서 생성된 데이터를 처리하기 위한 것
    *엣지 위치 : 도로 위의 트럭, 바다 위의 선박, 지상의 채굴장 등의 장소

Amazon FSx
완전 관리형 서비스로 타사 고성능 파일 시스템을 실행시킴
4가지 파일 시스템은 꼭 알아야 됨

1. FSx for Windows File Server
ㄴ 완전 관리형 Windows 파일 서버 공유 드라이브
ㄴ SMB 프로토콜과 Windows NTFS를 지원
ㄴ Microsoft Active Directory 통합을 지원하므로 사용자 보안 추가, ACL로 사용자 할당량 추가해 액세스 제어
ㄴ Linux EC2 인스턴스에도 마운트 가능
ㄴ 초당 수십 GB에 수백만 IOPS, 수백 PB 데이터까지 확장
ㄴ SSD로 지연 시간이 짧아야 하는 워크로드 저장 ex) 데이터베이스, 미디어 처리 데이터 분석 등
ㄴ HDD로 넓은 스펙트럼의 워크로드 저장 ex) 홈 디렉터리, CMS
ㄴ 프라이빗 연결로 온프레미스 인프라에서 액세스 가능

2. FSx for Lustre
    *Lustre : Linux + Cluster의 합성어, 머신러닝 HPC, 즉 고성능 연산에 쓰였음
동영상 처리나 금융 모델링 전자 설계 자동화 등의 애플리케이션에서 쓰이고 확장성↑
ㄴ 초당 수백 GB의 데이터에 수백만 IOPS로 확장, 밀리초보다 짧은 지연 시간
ㄴ 낮은 지연 시간의 SSD, 크기가 작은 무작위 파일 작업이 많으면 IOPS도 사용 가능
ㄴ S3와 무결절성 통합 가능 => FSx로 S3를 파일 시스템처럼 읽어들일 수 있음, FSx의 연산 출력값을 다시 S3에 쓸 수 있음
ㄴ VPN과 직접 연결을 통해 온프레미스 서버에 사용 가능
스크래치 파일 시스템과 영구 파일 시스템
스크래치 파일 시스템 : 임시 스토리지, 데이터 복제x 기저 서버가 오작동하면 파일이 모두 유실됨, 최적화로 초과 버스트 사용하면 영구 파일 시스템보다 여섯배 성능을 보임(TiB 처리량당 초당 200MB 속도)
    ㄴ 단기 처리 데이터에 사용, 데이터 복제가 없어 비용 최적화

영구 파일 시스템 : 장기 스토리지, 동일한 AZ에 데이터 복제, 기저 서버 오작동하면 단 몇분 내에 해당 파일이 대체, 민감한 데이터의 장기 처리 및 스토리지

3. FSx for NetApp ONTAP
관리형 NetApp ONTAP 파일 시스템으로 NFS, SMB, iSCSI 프로토콜과 호환
ㄴ 온프레미스 시스템의 ONTAP이나 NAS에서 실행 중인 워크로드를 AWS로 옮길 수 있음
ㄴ 다양한 운영 체제에서 사용 가능
ㄴ 스토리지 오토 스케일링, 복제와 스냅샷 기능 지원
ㄴ 지정 시간 복제 기능 / 신속히 복제 가능, 스테이징 파일 시스템을 둘 수 있음 ex) 새 워크로드 테스트

4. FSx for OpenZFS
관리형 OpenZFS 파일 시스템으로 여러 버전에서의 NFS 프로토콜과 호환
ㄴ NFS 에서 실행되느 워크로드를 내부적으로 AWS 옮길 때 사용
ㄴ Linux, Mac, Windows 에서 사용 가능
ㄴ 백만 IOPS끼지 확장 가능, 지연 시간은 0.5밀리초 이하
ㄴ 스냅샷, 압축 지원하고 비용이 적지만 데이터 중복제거 기능x
ㄴ 지정 시간 동시 복제 기능 / NetApp ONTAP과 동일

AWS Storage Gateway
온프레미스 데이터와 클라우드 데이터 간의 다리 역할
ㄴ 재해 복구 목적으로 온프레미스 데이터를 클라우드에 백업
ㄴ 백업과 복구 목적으로 클라우드 마이그레이션, 혹은 온프레미스에서 클라우드 간 스토리지 확장을 사용 ex) 클라우드에는 콜드 데이터, 온프레미스에는 더 자주 쓰는 웜 데이터 저장식으로
S3 파일 게이트웨이
애플리케이션 서버가 NFS나 SMB 프로토콜을 사용하도록 함 -> 이 프로토콜을 통해 S3 파일 게이트웨이가 해당 요청을 HTTPS 요청으로 반환 S3 버킷으로 전송
ㄴ 수명 주기 정책을 사용하여 S3 Glacier로도 옮길 수 있음
ㄴ SMB 프로토콜을 사용중인 경우, 사용자 인증을 위해 Active Directory와 통합해야함
FSx 파일 게이트웨이
FSx for Windows File Server에 네이티브 액세스 제공
ㄴ 자주 액세스 하는 데이터의 로컬 캐시를 확보해 액세스 시 지연 시간을 단축시킴 (로컬 캐시는 회사 데이터 센터에 확보)
ㄴ Active Directory가 호환 가능
ㄴ 그룹 파일 공유, 온프레미스를 연결할 홈 디렉터리로 사용
볼륨 게이트웨이
블록 스토리지, S3가 백업하는 iSCSI 프로토콜 사용
ㄴ 볼륨이 EBS 스냅샷으로 저장, 필요에 따라 온프레미스 볼륨을 복구
ㄴ 최근 데이터 액세스 시 지연 시간이 낮은 캐시 볼륨 / 전체 데이터 세트가 온프레미스에 있으며 주기적으로 S3 백업이 따르는 저장 볼륨으로 나뉨
ㄴ 온프레미스 서버에 볼륨을 백업
테이프 게이트웨이(Tape Gateway)
물리적으로 테이프를 사용하는 회사가 테이프 대신 클라우드를 활용해 데이터를 백업할 수 있게 해주는 서비스
ㄴ 가상 테이프 라이브러리(VTL)는 S3 + Glacier
ㄴ 테이프 기반 프로세스의 기존 백업 데이털르 iSCSI 인터페이스를 사용하여 백업

게이트웨이는 회사 데이터 센터에 설치되어 있어야 함 -> 회사 데이터 센터 내에서 운영
    그러나 종종 게이트웨이를 실행할 가상 서버가 없는 경우 AWS의 하드웨어 사용 -> Storage Gateway 어플라이언스라고 하며 온프레미스 서버가 없는 경우 사용할 수 있음

AWS Transfer Family(전송 제품군)
S3또는 EFS의 안팎으로 데이터를 전송하려고 하는데 S3 APIs는 사용하고 싶지 않고 EFS 네트워크 파일 시스템도x FTP 프로토콜만 사용하려는 경우 사용
세가지 프로토콜을 지원(FTP, FTPS, SFTP)
1. FTP(파일 전송 프로토콜)의 AWS 전송 지원 / 비암호화
2. SSL을 통한 파일 전송 프로토콜인 FTPS / 암호화
3. 보안 파일 전송 프로토콜 SFTP / 암호화
시간당 프로비저닝된 엔드 포인트 비용에 전송 제품군 안팎으로 전송된 데이터의 GB당 요금을 더하는 가격 책정 구조

AWS DataSync
데이터를 자동화해서 빠르게 이동시켜주는 완전 관리형 데이터 전송 서비스
ㄴ 온프레미스 -> AWS, AWS -> AWS 간에 대용량 데이터를 빠르고 안정적으로 복제할 수 있음
ㄴ 복사하는 데이터의 메타데이터도 함께 복사

<SQS, SNS, Kinesis>
동기 커뮤니케이션 : 애플리케이션 <-> 애플리케이션 직접 연결 ex) 온라인 물품 판매 서비스가 있을 때 판매 완료 요청 -> 배송 서비스에 연락해 물건을 배송해야함 이 과정이 판매 서비스 <-> 배송 서비스 간의 직접 연결
비동기 or 이벤트 기반 유형 : 대기열
대기열 모델에선 SQS, 비동기 or 이벤트 기반 유형에선 SNS
실시간 스트리밍을 하면서 대용량 데이터를 다룬다면 Kinesis

SQS 개념
핵심은 대기열, 간단한 대기 서비스
SQS 대기열엔 메시지 포함 -> SQS 대기열에 메시지를 전송해야하는데 보내는 주체를 생산자라고 함
생산자는 한 개거나 그 이상
생성한 모든 메시지는 대기열에 들어감
대기열에서 소비자는 메시지 폴링 -> 대기열에게 소비자 앞으로 온 메시지가 있는지 확인 -> 있다면 메시지 폴링 -> 정보 전달 -> 대기열에서 폴링된 메시지 삭제
    *소비자 : 메시지를 처리하고 수신해야 하는 대상
대기열 서비스 : 생산자와 소비자 사이를 분리하는 버퍼 역할

Amazon SQS(Simple Queue Service) - 프론트엔드에서 들어오는 요청을 직접적으로 처리하는 것이 아닌 버퍼로 사용하여 로직 처리하는데 사용
완전 관리형 서비스, 애플리케이션 분리에 대한 문제? -> SQS
ㄴ 무제한 처리량을 얻을 수 있음
ㄴ 메시지 수명이 짦음(기본값으로 4일동안 대기열에 잔류, 최대 시간은 14일)
    ㄴ 대기열에 보내자마자 소비자가 읽고 보존 기간 내에 처리한 후 대기열에서 삭제해야함, 그렇지 않은 경우 소실
ㄴ 지연 시간이 짧아서 SQS는 메시지 보내기&읽기시 10밀리초 이내로 응답
ㄴ 전송된 메시지는 256KB 미만이어야 함
ㄴ SQS는 대기열 서비스라 높은 처리량, 높은 볼륨 등이 있어 중복 메시지가 있을 수 있음
ㄴ 생산자가 SDK 소프트웨어 개발키트를 사용하여 SQS 메시지를 보냄(이때 메시지를 보내는 API를 SendMessage 라고 함)
ㄴ 소비자는 EC2 인스턴스(가상 서버)에서 실행됨, 람다 함수를 사용하여 메시지를 수신할 수도 있음
ㄴ SQS 대기열은 메시지를 동시에 수신하고 처리할 소비자를 여러개 가질 수 있음
    ㄴ 만일 메시지가 소비자에 의해 충분히 빠르게 처리되지 않으면 다른 소비자가 수신하게 됨 -> 이것이 최선의 노력으로 메시지 순서 지정을 하는 이유
    ㄴ 이 경우처럼 더 많은 메시지를 처리하는 처리량을 늘려야 하면 소비자를 추가하고 수평 확장을 수행해서 처리량 개선
ㄴ 분리나 급격히 증가한 로드 혹은 시간초과 등의 문제에서 신속한 스케일링이 필요한 경우엔 SQS 대기열을 사용

SQS 보안
ㄴ HTTPS API를 사용하여 메시지를 보내고 생성함으로 비행 중 암호화, KMS 키를 사용하여 미사용 암호화
ㄴ 원한다면 클라이언트 측 암호화(클라이언트가 자체적으로 암호 해독을 수행)도 가능하지만 SQS에서 기본적으로 지원x
ㄴ 액세스 제어를 위한 IAM 정책은 SQS API에 대한 액세스를 규제할 수 있음
ㄴ S3 버킷 정책과 유사한 SQS 액세스 정책도 있음
    ㄴ SQS 대기열에 대한 교차 계정 액세스, SNS, S3 같은 다른 서비스가 SQS 대기열에 S3 이벤트 같은 것을 쓸 수 있도록 허용하려는 경우 매우 유용함

메시지 가시성 시간초과(Message Visibility Timeout)
대기열에서 소비자가 메시지를 풀링하면 다른 소비자는 그 메시지가 보이지 않게 되는데 이 유지시간을 가시성 시간초과
ㄴ 가시성 시간초과는 기본값으로 30초, 시간 안에 메시지 풀링 안하면 다른 사용자 메시지 풀링 가능
ㄴ 소비자는 메시지를 처리하는 데 시간이 더 필요하다면 ChangeMessageVisibility 라는 API를 호출하여 SQS에 알려야 함
ㄴ 만일 이 가시성 시간초과 값이 큰 경우 소비자가 충돌했을 때 이 메시지가 SQS 대기열에 보이기까지 많은 시간이 걸림 -> 대기열에 많은 메시지가 모이게 됨 -> 지연 시간 증가

롱 풀링
소비자가 큐에서 메시지 요청할 때 현재 큐에 메시지가 없다면 도착할 때까지 기다릴 수 있다는 개념
ㄴ 소비자가 API 호출 수를 줄일 수 있음
ㄴ 소비자는 SQS 큐에 10초동안 메시지를 요청할 수 있음, 또한 API 호출수↓ -> 지연시간↓ => 이유는 SQS에서 메시지 받자마자 소비자에게 전송되기 때문
ㄴ 최소한의 지연시간으로 메시지를 받을 수 있음
ㄴ 롱 풀링은 1~20초 사이로 설정 가능
ㄴ 전체적으로 짧은 풀링보다 롱 풀링을 선호해야 함

Amazon SQS FIFO 큐
선입선출 개념이 적용된 큐, 메시지를 전달받는 순서를 확실히 보장하기에 SQS 대기열 처리량에 제한이 있음
ㄴ 분리가 발생하거나 메시지의 순서를 유지할 필요가 있을 때 FIFO 대기열을 사용
ㄴ .fifo를 붙여야 FIFO 대기열 생성
ㄴ 메시지 중복 풀링 방지 설정도 있음

SQS 오토스케일링(ASG)
ASG 내의 EC2 인스턴스에 메시지를 SQS 대기열에서 풀링함
ㄴ 오토 스케일링 그룹을 자동으로 대기열 크기에 따라 확장시키기 위함 -> CloudWatch 지표인 대기열 길이를 보고 결정할 수 있음
ㄴ 세일 행사 중일때 수많은 고객이 주문 -> RDS나 DynamoDB에 엄청난 주문 및 요청을 처리할텐데 모종의 이유로 트랜잭션에 오류가 발생하면 고객의 요청 처리x -> 비즈니스에 좋지 못함
    ㄴ 이런 경우에 쓰기 대상 데이터베이스말고 SQS를 버퍼로 사용할 수 있음
    ㄴ 이 경우는 클라이언트에게 따로 데이터베이스에 입력됐다는 확인을 전송할 필요가 없을 때 사용 ex) 점심시간 식권 구매 등

Amazon SNS(Simple Notification Service)
Pub/Sub, 게시/구독
어떤 주제에 많은 구독자가 있으며 각 구독자는 SNS 주제에서 해당 메시지를 수신하고 보관 -> Pub/Sub 패턴
ㄴ 이벤트 생산자와 구독자는 해당 주제와 관련한 SNS 알림을 받으려는 사람
ㄴ SNS 주제 구독자는 해당 주제로 전송된 메시지 모두 받게 됨, 메시지 필터링하는 기능 사용가능
ㄴ 주제별 최대 구독자 수는 1200만 이상의 구독자 
ㄴ 계정당 가질 수 있는 주제는 최대 10만개
ㄴ SNS에서 직접 이메일을 보내거나, HTTP 또는 HTTPS 엔드포인트로 직접 데이터를 보내거나, SQS와 같은 특정 AWS 서비스와 통합하여 메시지를 대기열로 보낼 수 있고, Lambda에 보내거나, Firehose를 통해 데이터를 보낼 수도 있음
ㄴ SDK 주제 게시를 사용해 SNS에 메시지를 게시 가능
    ㄴ 주제 만든 후 하나 또는 여러 개의 구독을 만들고 SNS 주제에 게시
ㄴ 보안 기술로는 전송중 암호화, KMS 키를 사용한 저장 데이터 암호화, 클라이언트 측 암호화 등
ㄴ 액세스 제어는 IAM 정책 중심
ㄴ SNS 액세스 정책은 SNS 주제에 교차 계정 액세스 권한을 갖거나, S3 이벤트와 같은 SNS 주제에 작성할 수 있도록 허용하는 경우 유용

SNS + SQS : Fan Out
SNS 토픽으로 메시지 전송 후 원하는 만큼 SQS 대기열을 SNS 토픽에 구독시키는 것
ㄴ 여러 개의 대기열로 동일한 S3 이벤트 알림을 보내고 싶다면 Fan Out 패턴을 사용
ㄴ SNS FIFO = SQS FIFO -> SQS FIFO를 사용해 Fan Out을 할 때 정렬, 중복제거 필요
    ㄴ 구매 서비스는 SNS FIFO 토픽 -> 두 개의 SQS FIFO 토픽으로 Fan Out
    ㄴ 사기 탐지 서비스와 배송 서비스가 FIFO 대기열을 읽을 수 있음
ㄴ 메시지 필터링 : SNS 토픽 구독자들에게 전송할 메시지를 필터링하는 JSON 정책

Amazon Kinesis
실시간 스트리밍 데이터를 손쉽게 수집하고 처리하여 분석할 수 있는 서비스
ㄴ 실시간 데이터엔 애플리케이션 로그, 계측, 웹사이트 클릭 스트림, IoT 원격 측정 데이터
    ㄴ 데이터가 빠르게 실시간으로 생성된다면 모두 실시간 데이터 스트림
ㄴ 크게 4가지 서비스로 구성되어 있음

1. Kinesis Data Stream
스트리밍 데이터를 실시간으로 수집하고 저장하는 데 사용되는 서비스
ㄴ 데이터 스트림을 수집하여 처리하고 저장
ㄴ 실시간 데이터를 Kinesis 데이터 스트림으로 보내기 위해서는 프로듀서라는 도구를 사용함
    *프로듀서 : 애플리케이션이나 실제로 웹사이트나 디바이스에서 데이터를 가져와 Kinesis 데이터 스트림으로 보내기 위해 작성해야 하는 코드, 메트릭과 로그의 경우엔 Kinesis 에이전트라는 것을 설치하는데 이 역시 프로듀서
ㄴ 프로듀서를 사용하는 이유는 consumer 애플리케이션이 이 데이터를 실시간으로 소비하고 활용하기를 원하기 때문
ㄴ 데이터를 최대 365일동안 스트림에 보관할 수 있음
ㄴ 데이터가 지속되므로 소비자에 의해 데이터를 재처리하여 재생할 수 있음
    ㄴ Kinesis 데이터 스트림으로 데이터를 전송한 후에는 삭제할 수 없다는 뜻
ㄴ 최대 1MB의 데이터를 Kinesis 데이터 스트림으로 전송할 수 있음
ㄴ 동일한 파티션 ID를 가진 두 개의 데이터 포인트를 전송하면 데이터가 순서대로 정렬
    ㄴ 동일한 파티션 ID를 공유하여 두 데이터 포인트가 시잔적으로 관련이 있고 미사용, KMS 암호화 및 기내 HTTPS 암호화와 같은 보안 기능을 구현
ㄴ 높은 처리량을 위해 최적화된 프로듀서 애플리케이션을 작성하려면 키네시스 프로듀서 라이브러리 KPL 사용
ㄴ 최적화된 소비자 애플리케이션을 작성하려면 키네시스 클라이언트 라이브러리 or Ksql을 사용해야함
ㄴ 두가지 용량 모드가 있는데
    ㄴ 프로비저닝 모드, 스트림의 샤드(스트림의 크기) 개수를 선택
        ㄴ 시간당 프로비저닝된 각 샤드에 대해 비용을 지불
    ㄴ 온디맨드 모드, Kinesis 데이터 스트림 용량 프로비저닝하거나 관리x
    ㄴ 초당 약 404,000개의 레코드 또는 4MB 기본 용량 제공, 30일 동안 관찰된 처리량에 따라 자동으로 용량 확장
    ㄴ 사용한 스트림의 시간당 요금이 부과, Kinesis 데이터 스트림에 들어오고 나가는 데이터의 양에 따라 요금 청구
    
2. Kinesis Data Firehose
실시간 스트리밍 데이터를 자동으로 수집하고, 변환해서, 저장소로 전송해주는 완전관리형 서비스
ㄴ 데이터 전송하려면 애플리케이션, client와 같은 프로듀서 필요
ㄴ 직접 작성하여 SDK를 사용해 데이터를 파이어호스로 전송
ㄴ Kinesis 에이전트 사용해 서버 로그 등을 자동 수집하여 파이어호스로 전송
ㄴ Kinesis 데이터 스트림, CloudWatch 로그, IoT 같은 서비스에서 직접 데이터를 받을 수 있음
ㄴ 자동 확장 기능
ㄴ 서버리스 방식, 서비스 내에서 사용한 만큼만 비용 지불
ㄴ Near Real-Time은 Amazon 파이어호스를 가리킴
    ㄴ 즉각적인 반응은 필요 없지만, 가능한 한 빨리 데이터를 처리해서 활용할 수 있도록 하는 처리 방식

3. Kinesis Data Analytics
ㄴ SQL 언어나 Apache Flink를 활용하여 데이터 스트림을 분석

4. Kinesis Video Stream
ㄴ 비디오 스트림을 수집하고 처리하여 저장

Amazon Kinesis Data Stream vs Amazon Kinesis Firehose
데이터 스트림은 "실시간 감지·처리"가 필요한 고급 개발자나 데이터 엔지니어용
파이어호스는 복잡한 처리 없이 빠르게 데이터를 저장하고 싶은 사람용

SQS vs SNS, Kinesis
SQS는 소비자가 SQS 대기열에서 메시지를 요청해서 데이터를 가져오는(pull) 모델
ㄴ 데이터를 처리한 후 소비자가 대기열에서 삭제해서 다른 소비자가 못 읽게 해야함
ㄴ 관리된 서비스이므로 처리량을 프로비저닝 할 필요 없음
ㄴ FIFO 대기열을 이용해 순서 보장 가능, 지연 기능도 있음
SNS는 게시/구독 모델로 데이터 푸시 -> 주제를 구독한 다수의 구독자에게 메시지의 복사본 전송
ㄴ 주제별로 약 1250만 명의 구독자 가능, 데이터가 한 번 SNS에 전송되면 지속되지 않음(제대로 전달되지 않으면 데이터 유실 가능성)
ㄴ 팬아웃 아키텍쳐 패턴을 이용하면 SNS와 SQS를 결합하거나 SNS FIFO 주제를 SQS FIFO 대기열과 결합 가능
Kinesis는 두가지 소비 모드가 있음
1. 소비자 -> Kinesis로부터 데이터를 가져오는(pull) 표준 모드
ㄴ 샤드당 2 MB/s의 속도 지원
2. 향상된 팬아웃 유형의 소비 매커니즘
ㄴ 키네시스 -> 소비자 데이터 푸시, 처리량이 훨씬 높아 키네시스 스트림에서 더 많은 애플리케이션 읽기 가능
ㄴ 실시간 빅 데이터 분석, ETL 등에 활용
용량 모드에는 두가지
1. 프로비저닝 용량 모드는 키네시스 데이터 스트림으로부터 원하는 샤드 양을 미리 지정
2. 온디맨드 용량 모드에서는 샤드 수가 키네시스 데이터 스트림에 따라 자동으로 조정