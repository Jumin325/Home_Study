AIF 오답노트

<깃 사용 방법>
https://tinyurl.com/cj4bjrw9
ㄴ 김진용님이 설명해주신 깃&깃허브 사용 캔바 슬라이드

1. VSC로 폴더 오픈 후 git init 으로 깃 로컬 레포지토리로 설정
1-1. 깃 폴더로 지정하지 않았더라면
	git config --global user.email "이메일"
	git config --global user.name "이름"
2. 파일의 변경 사항을 git add + git commit 으로 저장하기
2-1. 변경 사항을 저장하였는지 파일이 잇에 트랙 되어 있는지 파일 이름 확인 후 git status로 확인하기,
2-2. 커밋 내역 조회는 git log --all --oneline 으로 확인 가능
3. GitHub 에서 오리진 링크 지정하고 연동하기 (보통 로컬 리포지토리를 이미 만든 상태에서 브랜치에 연동하니까 그 방법을 기술)
	git remote add origin "주소"
	git branch -M main
	git push -u origin main
	ㄴ 위 내용은 깃허브 온라인 리포지토리 생성하는 곳에서 주소 복사하는게 있음(두번째꺼)
4. 변경 사항이 있을 시 git add, git commit 후 git push 입력 시 온라인 리포지토리에 복제

<추가 사용>
1. 변경 사항이 있을 시 git add, git commit 후 git push 입력해서 온라인 리포지토리에 복제
	ㄴ ** 파일 변동 사항 있으면 꼭 파일 저장 후에 add 할것 **
2. (다른 환경에서 온라인 -> 로컬) 파일을 받을때는 gitHub에서 받고자 하는 리포지토리 선택 후 오른쪽 <>Code 누르고 
	코드 복사 후 git bash에서 git clone "주소" 입력으로 내려받기
2-1. 처음 사용하는 환경이라면 user/"사용하는 리포지토리 폴더" 에 내려받아지므로 그냥 사용
2-2. 원래 사용하던 곳에서 쓰는 리포지토리를 업데이트 하고 싶을때
	git fetch --all  # 원격 저장소 정보 업데이트
	git reset --hard origin/main  # 로컬을 원격(main)과 동일하게 덮어쓰기
	위 두 명령어를 입력하여 로컬 리포지토리 덮어씌우기
	git fetch -- all은 원격 저장소의 최신 정보를 로컬로 받아오는 것이므로 최신 상태 확인을 위해서 필수
	git reset --hard origin/main은 origin/main의 최신 상태로 로컬 리포지토리를 덮어씌우는 명령어
	위 방법과 사용하던 로컬 깃 리포지토리에서 터미널 창에 git pull로 최신 상태를 덮어씌울 수도 있음

Amazon SageMaker는 머신러닝 모델을 구축, 훈련 및 배포할 수 있는 AWS 서비스

Q1. 한 금융 기관이 기초 모델(FM)을 사용하여 대출 승인 결정을 내리기 위한 AI 솔루션을 구축하고 있습니다. 보안 및 감사 목적으로 이 회사는 AI 솔루션의 결정을 설명할 수 있어야 합니다. AI 솔루션의 의사 결정의 설명 가능성과 관련된 요소는 무엇인가요?
-> 모델 복잡성
ㄴ AI 솔루션의 결정에 대한 설명 가능성과 관련된 요소는 (1) 모델 복잡성입니다. AI의 설명 가능성은 모델이 어떻게 결정이나 예측에 도달하는지를 이해하고 해석할 수 있는 능력을 말합니다. 모델이 더 복잡하거나 계층이 많으면 해석하고 설명하기가 더 어려워져 설명 가능성이 낮아질 수 있습니다. 모델 아키텍처를 단순화하고 기능 중요도와 같은 기술을 사용하면 설명 가능성을 향상시킬 수 있습니다.

학습 시간, 하이퍼파라미터 수, 배포 시간은 AI 솔루션 개발 및 배포에 중요한 요소이지만 모델이 내린 결정의 설명 가능성과는 직접적인 관련이 없습니다.

Q2. Amazon Bedrock이 유효성 검사에 사용할 수 있는 새로운 데이터 세트를 업로드 해야 한다. 이때 사용할 수 있는 AWS 서비스는?
-> Amazon S3
ㄴ Amazon Bedrock의 유효성 검사에 사용할 새 데이터 세트를 업로드할 수 있는 확장 가능한 스토리지 서비스가 필요한데
	1. AWS snowcone은 소규모 엣지 컴퓨팅 및 데이터 전송을 위한 물리적 장치임
	2. EBS는 EC2 인스턴스에 연결하는 블록 스토리지, 데이터베이스 저장소로 많이 쓰는데 S3 처럼 독립적으로 데이터를 저장하고 공유하는 용도x
	3. EFS는 리눅스 기반 네트워크 파일 시스템 서비스, EC2 인스턴스가 여러 파일을 공유할 때 유용하지만 웹에서 직접 데이터 업로드 및 관리에는 		부적합

Q3. 생성형 AI 모델에서 토큰은 무엇인가?
-> 토큰은 생성형 AI 모델이 작동하는 기본 입력 및 출력 단위로, 단어, 하위 단어 또는 기타 언어 단위를 나타냄

Q4. 최대 1GB의 대용량 입력 데이터와 최대 1시간의 처리 시간을 가지고 있는 상황, 실시간에 가까운 지연 시간을 필요로 하는데 이때 이 조건을 충족하는 SageMaker의 추론 옵션은?
-> 비동기 추론
ㄴ 대용량 입력 데이터와 긴 처리 시간을 처리하는 동시에 비동기 요청을 통해 실시간에 가까운 상호 작용을 가능하게 함
	일괄 변형 : 오프라인으로 데이터를 처리하며 실시간에 가까운 지연 시간이 아닌 일괄 예측을 위한 것
	실시간 추론 : 지연 시간이 짧지만 페이로드가 많거나 처리 시간이 1시간처럼 긴 경우에는 적합하지 않음 
	지속적인 엔드포인트 사용으로 인해 요청 시간 초과 또는 비용 증가로 이어질 수 있음
	서버리스 추론 : 지연 시간이 짧고 간헐적인 워크로드에는 적합하나 대규모 페이로드나 처리 시간에는 부적합

Q5. 한 회사에서 데이터베이스 오류로 인해 일부 단어가 누락된 문서가 있음, 이 회사는 누락된 텍스트를 채울 수 있는 단어를 제안하는 ML 모델을 구축하려고 하는데 이 요구사항을 충족하는 모델 유형은??
-> BERT 기반 모델
ㄴ 문맥을 이해하고 누락된 단어를 효과적으로 예측할 수 있는 언어 모델을 사용해야 함, BERT 기반 모델은 언어 문맥을 이해하고 텍스트 완성이나 누락된 단어 채우기와 같은 작업을 수행하는 것에 용이한 모델
	클러스터링 모델 : 주어진 데이터를 유사한 그룹(클러스터)으로 자동으로 분류하는 비지도 학습 모델
	규범적 ML 모델 : 특정 목표를 달성하기 위해 최적의 행동(의사결정)을 추천하는 모델
	토픽 모델링 : 문서에서 숨겨진 주체(Topic)를 자동으로 추출하는 비지도 학습 기법

Q6. S3에 업로드된 Amazon Bedrock 및 고객 데이터를 사용하여 대규모 언어 모델(LLM) 애플리케이션을 개발하려고 한다. 회사의 보안 정책에 따르면 각 팀은 해당 팀의 고객에 대해서만 엑세스 할 수 있어야 하는데 이를 요구하는 솔루션은??
-> 각 팀에 대해 팀의 고객 데이터에 액세스 할 수 있는 Amazon Bedrock 사용자 지정 서비스 역할을 만든다
ㄴ 전체 Amazon S3 액세스 권한이 있는 하나의 Amazon Bedrock 역할을 만들어서 각 팀의 고객 폴더에만 액세스 할 수 있는 각 팀에 대한 IAM 역할을 만드는건, 전체 S3 액세스 권한이 있는 단일 Bedrock 역할은 더 광범위한 액세스가 발생할 가능성이 있으므로 팀별 제한 액세스 요구 사항과 모순됨

Q7. 한 회사에서 특정 품목의 가격을 예측하는 새로운 모델을 개발중, 이 모델은 훈련 데이터 세트에서 좋은 성능을 보였으나 프로덕션에 배포했을 때 모델의 성능이 크게 저하되었다. 이 문제를 완화하려면 어떻게 해야 하나?
-> 교육에 사용되는 데이터의 양을 늘린다
ㄴ 학습에 사용되는 데이터의 양을 늘리면 모델의 일반화 기능을 개선하고 프로덕션 환경에서 성능 저하의 원인이 될 수 있는 과적합을 줄이는 데 도움이 될 수 있다. 이 접근 방식은 모델이 데이터에서 더 많은 패턴과 관계를 학습하는 데 도움이 되며, 배포 시 더 나은 성능으로 이어짐

Q8. 텍스트 설명을 기반으로 제품 이미지를 생성하기 위해 Amazon Bedrock 및 Stable Diffusion과 함께 증강 생성(RAG)을 사용하고 있습니다. 결과는 종종 무작위로 생성되고 구체적인 세부 정보가 부족합니다. 이 회사는 생성된 이미지의 구체성을 높이고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇인가요?
-> 분류가 없는 안내(CFG) 척도를 높입니다.
ㄴ  MASK_IIMAGE_BLACK 마스크 소스 옵션을 사용하지 않는 이유는 이 옵션은 일반적으로 이미지의 일부를 재성성하기 위해 마스킹하는 인페인팅 시나리오기 때문
    프롬프트 강도를 높이는 것은 생성 과정에서 텍스트 프롬프트의 가중치에 영향을 주지만, 세부 지침과의 정렬을 구체적으로 계산하기보단 지나치게 딱딱하거나 부자연스러운 결과를 초래할 수 있음
	창의성과 프롬프트 준수 간의 균형을 유지하여 보다 구체적이어야 하는 회사의 요구를 직접적으로 해결하는 분류가 없는 안내(CFG) 척도를 높이는 것이 정답

Q9. 한 회사가 ML 모델을 구축하고 있음, 이 회사는 새로운 데이터를 수집하고 상관관계 행렬을 만들고 통계를 계산하고 데이터를 시각화하여 분석함, 이 회사의 현재 ML 파이프라인은 어느 단계인가?
-> 탐색적 데이터 분석

Q10. 한 회사가 Amazon Bedrock을 사용하여 Amazon Titan 기초 모델(FM)을 구현하고 있습니다. 이 회사는 회사의 개인 데이터 소스에서 관련 데이터를 사용하여 모델을 보완해야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇인가요?
-> Amazon Bedrock 지식창고를 만드세요
ㄴ Amazon Bedrock 지식창고를 통해 조직은 자체 데이터를 기초 모델과 함께 활용하여  특정 데이터 요구 사항에 따라 AI 모델을 정의하고 기능을 향상시킬 수 있음

Q11. 한 회사가 생성적 AI 보안 범위 매트릭스를 사용하여 솔루션에 대한 보안 책임을 평가하고 있습니다. 이 회사는 매트릭스를 기반으로 네 가지 솔루션 범위를 식별했습니다. 어떤 솔루션 범위가 회사에 가장 많은 보안 책임을 부여하나요?
-> 고객이 소유한 특정 데이터를 사용하여 처음부터 생성 AI 모델을 구축 및 학습합니다.
ㄴ 회사에 가장 많은 보안 책임을 부여하는 솔루션 범위를 결정하려면 회사가 솔루션의 보안 측면에 대해 얼마나 많은 통제권을 가지고 있는지 고려해야 함
고객이 소유한 특정 데이터를 사용하여 생성형 AI 모델을 처음부터 구축하고 학습할 때 데이터 처리, 모델 학습 및 배포를 포함한 전체 프로세스를 제어할 수 있으므로 보안 책임에 대한 소유권이 기업에 가장 많이 부여됨

Q12. 리서치 회사에서 Amazon Bedrock의 기초 모델(FM)을 사용하여 챗봇을 구현했다. 이 챗봇은 대규모 연구 논문 데이터베이스에서 질문에 대한 답변을 검색함. 여러 번의 신속한 엔지니어링 시도 끝에 이 회사는 연구 논문의 복잡한 과학 용어 때문에 FM의 성능이 좋지 않다는 것을 알게 되었다.
이 회사는 챗봇의 성능을 어떻게 개선할 수 있을까?
-> 도메인 적응 미세 조정을 사용하여 복잡한 과학 용어에 맞게 FM을 조정할 수 있다.
ㄴ 복잡한 과학 용어를 이해하는 챗봇의 성능을 향상시키려면 도메인 적응 미세 조정을 사용하여 이러한 용어에 맞게 기초 모델을 조정하는 것이 가장 좋은 방법

Q13. 한 회사가 아카이브된 데이터를 분석하기 위해 ML 모델을 구축하고 있다. 이 회사는 수 GB 크기의 대규모 데이터 세트에 대해 추론을 수행해야 한다. 
회사는 모델 예측에 즉시 액세스할 필요가 없다. 이러한 요구 사항을 충족하는 Amazon SageMaker  추론 옵션은 무엇인가?
-> 일괄 변환
ㄴ 일괄 변환은 여러 GB 크기의 대규모 데이터 세트에 대한 추론을 수행하고 모델 예측에 즉시 액세스할 필요가 없는 경우에 가장 적합한 옵션임 배치 변환을 사용하면 대량의 데이터를 오프라인으로 처리하고 나중에 사용할 수 있도록 결과를 저장할 수 있으므로 빠른 응답 시간이 필요하지 않은 시나리오에 적합

Q14. 한 회사에서 물체 감지를 위한 딥러닝 모델을 구축하고 이 모델을 프로덕션에 배포했습니다. 모델이 새 이미지를 분석하여 객체를 식별할 때 어떤 AI 프로세스가 발생하나요?
-> 추론
ㄴ 추론 단계에서는 학습된 모델을 사용하여 새로운 데이터 포인트를 예측하거나 분류함, 이 경우 딥러닝 모델이 새로운 이미지를 분석하여 생산 중인 사물을 식별할 때, 학습 단계에서 학습한 패턴을 기반으로 예측을 수행하여 추론을 수행하는 것

Q15. 한 회사에서 고객 이탈을 예측하기 위한 ML 모델을 개발하고 있습니다. 이 모델은 학습 데이터 세트에서는 잘 작동하지만 새로운 데이터에 대한 이탈을 정확하게 예측하지 못합니다. 이 문제를 해결할 수 있는 솔루션은 무엇인가요?
-> 정규화 매개변수를 늘려 모델 복잡성을 줄입니다.
ㄴ 설명된 문제는 모델이 학습 데이터 세트에서는 잘 작동하지만 새로운 데이터에는 잘 일반화되지 않는 과적합으로 인한 것일 수 있음, 
이 문제를 해결하려면 모델의 복잡성을 줄여야 함 정답으로 제시된 L1 또는 L2 정규화와 같은 정규화 기법은 모델에서 큰 가중치에 불이익을 줌으로써 과적합을 방지하는 데 도움이 된다. 이는 결과적으로 모델을 단순화하고 보이지 않는 데이터에 대한 일반화 성능을 향상시킴

Q16. 컨택 센터 애플리케이션을 구축하면서 고객 대화에서 인사이트를 얻고자 한다. 이 회사는 고객 통화 오디오에서 주요 정보를 분석하고 추출하고자 하는데 이러한 요구 사항을 충족하는 솔루션은??
-> Amazon 트랜스크라이브를 사용하여 통화 녹음을 전시한다
ㄴ 아마존 트랜스크라이브는 음성-텍스트 변환 기능을 제공하는 서비스로, 오디오를 텍스트로 변환할 수 있다.

Q17. 제조 회사에서 AI를 사용하여 제품을 검사하고 손상이나 결함을 발견함. 이 회사는 어떤 유형의 AI 애플리케이션을 사용하고 있나?
-> 컴퓨터 비전
ㄴ 컴퓨터 비전은 AI 알고리즘을 사용하여 현실 세계의 시각적 데이터를 분석하고 해석하는 것을 말함

Q18. 전자 상거래 회사에서 제품에 대한 고객 리뷰를 기반으로 고객 감정을 파악하는 솔루션을 구축하려고 한다. 이러한 요구 사항을 충족하는 AWS 서비스는 무엇인가?
-> Amazon Comprehend(이해), 아마존 베드락
ㄴ 
	Amazon Lex는 챗봇 및 가상 어시스턴트와 같은 대화형 인터페이스를 구축하는 데 사용됨
	Amazon Comprehend는 감정 분석, 엔티티 인식, 텍스트 분류와 같은 자연어 처리(NLP) 작업을 위해 특별히 설계
	Amazon Bedrock을 사용하면 개발자는 광범위한 인프라 없이도 감정 분석을 포함한 텍스트 분석과 같은 작업에 기초 모델을 사용할 수 있음
	이 솔루션은 생성형 AI 및 NLP 기능을 지원하므로 맞춤형 감정 분석 솔루션에 적합

Q19. 한 회사가 고객에게 대화형 검색 환경을 제공하기 위해 지능형 에이전트를 구현하고 있다. 
이 회사는 데이터베이스의 벡터로서 생성형 AI 모델의 임베딩을 저장하고 쿼리를 지원하는 데이터베이스 서비스가 필요한데 이러한 요구 사항을 충족하는 AWS 서비스는 무엇인가?
-> Amazon Aurora PostgreSQL
ㄴ 클라우드용으로 구축된 MySQL 및 PostgreSQL 호환 관계형 데이터베이스은 Amazon Aurora PostgreSQL이 가장 이상적인 서비스

아마존 세이지메이커 클래리파이는 데이터 준비 중 잠재적 편향성 식별

Q20. Amazon Bedrock을 사용하여 애플리케이션을 만들고자 한다. 회사는 예산이 제한되어 있으며 장기 약정없이 유연성을 선호한다. 이러한 요구사항을 충족하는 Amazon Bedrock 요금제는?
-> 온디맨드

Amazon SageMaker JumpStart는 팀의 VPC 내에서 기초 모델을 포함한 머신 러닝 모델을 위한 원클릭 배포 가능한 솔루션을 제공합니다. 이를 통해 AI 개발팀은 기초 모델을 신속하게 배포하고 사용할 수 있습니다.

Q21. 한 AI 실무자가 동물 사전 데이터베이스를 가지고 있다. AI 실무자는 사람의 수작업 없이 사진 속 동물을 자동으로 식별하고 분류하고자 한다. 이러한 요구 사항을 충족하는 전략은??
-> 물체 감지
ㄴ 객체 감지는 이미지 또는 동영상 내에서 객체를 식별하고 분류하는 컴퓨터 비전 기술, 이 문제에서 AI 실무자는 사람의 수작업 없이도 사진 속 동물을 자동으로 식별하고 분류할 수 있어야 하기에 물체(객체) 감지가 정답

벤치마크 데이터 세트는 편향성 및 공정성 평가를 포함하여 모델 및 알고리즘을 평가하기 위해 특별히 선별된 사전 라벨이 저장된 데이터를 제공함.

Q22. AI 및 자연어 처리(NLP) 모델이 텍스트 정보의 이해를 높이기 위해 사용하는 실제 사물과 개념의 수치 표현을 설명하는 용어는?
-> 임베딩
ㄴ 임베딩은 단어, 구문 또는 문서를 연속 벡터 공간에 분산 표현하여 이들 간의 의미 관계를 포착하는 것, 임베딩은 텍스트 분류, 감정 분석, 기계 번역 등과 같은 NLP 작업에서 매우 중요함

Q23. 한 소프트웨어 회사는 고객을 위한 도구를 개발합니다. 이 회사는 AI를 사용하여 소프트웨어 개발 생산성을 높이고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇일까요?
-> 자연어 처리(NLP) 도구를 사용하여 코드를 생성하세요.
ㄴ 회사의 개발자 도구에 코드 추천 소프트웨어를 설치하면 개발자가 코드를 작성하는 동안 제안과 개선 사항을 제공함으로써 소프트웨어 개발 생산성을 높일 수 있습니다. 
   이를 통해 코딩 프로세스를 간소화하고 오류를 줄이며 전반적인 코드 품질을 개선할 수 있습니다. 이는 소프트웨어 개발의 생산성 향상을 위해 AI를 사용한다는 회사의 목표와도 밀접하게 맞닿아 있습니다.

Q24. 한 회사가 광고 캠페인에 사용할 페타바이트 규모의 라벨링되지 않은 고객 데이터를 보유하고 있습니다. 이 회사는 자사 제품을 광고하고 홍보하기 위해 고객을 등급으로 분류하려고 합니다. 이러한 요구 사항을 충족하려면 어떤 방법론을 사용해야 할까요?
-> 비지도 학습
ㄴ 레이블이 지정되지 않은 고객 데이터를 사용하여 고객을 등급으로 분류하려면 비지도 학습을 사용해야 합니다. 비지도 학습은 레이블이 없는 데이터를 다루는 머신 러닝의 한 분야로, 입력 데이터에서 숨겨진 패턴이나 내재적 구조를 찾는 데 사용됩니다.

Q25. 한 은행은 대출 승인 프로세스를 신속하게 처리하기 위해 대규모 언어 모델(LLM)을 미세 조정했습니다. 이 은행은 이 모델에 대한 외부 감사 중에 특정 인구 통계에 대해 다른 인구 통계보다 더 빠른 속도로 대출을 승인하고 있다는 사실을 발견했습니다.
이 은행이 이 문제를 가장 비용 효율적으로 해결하려면 어떻게 해야 할까요?
-> 더 다양한 학습 데이터를 포함하세요. 새 데이터를 사용하여 모델을 다시 미세 조정합니다.
ㄴ 이 시나리오에서는 기존 모델에 더 다양한 학습 데이터를 포함함으로써 특정 인구 통계에 대한 대출 승인 편향 문제를 해결할 수 있습니다.
   미세 조정된 모델에 RAG를 사용하는 옵션은 검색된 정보를 기반으로 응답을 생성하는 데 도움이 될 수 있지만 대출 승인 프로세스의 편향성을 직접적으로 해결하지는 못할 수 있음
   보다 다양한 학습 데이터로 LLM을 사전 학습하는 것은 해결책이 될 수 있지만 기존 모델을 재사용하고 보다 다양한 데이터로 개선하는 것만큼 비용 효율적이지 않을 수 있음

Q26. ML 라이프사이클의 어느 단계에서 규정 준수 및 규제 요구 사항이 결정되나요?
-> 비즈니스 목표 식별
ㄴ 비즈니스 목표 식별 단계에서는 규정 준수 및 규제 요건을 결정합니다. 이 단계에서는 ML 프로젝트를 비즈니스 목표에 맞추고 법적 및 윤리적 표준을 준수하도록 함으로써 ML 프로젝트의 기반을 설정합니다.
   기능 엔지니어링 : 모델 학습을 위한 데이터 준비 및 변환에 중점을 둠
   모델 훈련 : 예측을 위해 데이터를 사용하여 모델을 학습시키는 작업이 포함됩니다.
   데이터 수집 : ML 프로세스에 사용할 원시 데이터를 수집합니다.

Q27. 한 대출 회사는 특정 비즈니스 기준에 따라 신규 신청자에게 할인 혜택을 제공하기 위해 생성형 AI 기반 솔루션을 구축하고 있습니다.
이 회사는 일부 고객에게 부정적인 영향을 미칠 수 있는 편견을 최소화하기 위해 책임감 있게 AI 모델을 구축하여 사용하고자 합니다. 이러한 요구 사항을 충족하기 위해 회사가 취해야 할 조치는 무엇인가요?
-> 회사가 이해관계자에게 툼여성을 제공할 수 있도록 모델의 행동을 평가합니다. / 데이터의 불균형이나 불일치를 감지합니다.
ㄴ 이해관계자에게 투명성을 제공할 수 있도록 모델의 동작을 평가합니다
   데이터의 불균형 또는 불균형을 감지하는 것은 모델 결정의 공정성에 영향을 미칠 수 있는 학습 데이터의 편향을 식별하는 데 도움이 되므로 매우 중요합니다.
   모델의 행동을 평가함으로써 회사는 AI 모델이 올바른 이유로 의사 결정을 내리고 있는지 확인하고 이해관계자에게 모델의 작동 방식과 결정에 영향을 미치는 요인에 대해 투명성을 제공할 수 있습니다.

Q28. 한 AI 실무자가 이미지의 재료 유형을 분류하는 딥러닝 모델을 구축했습니다. 이제 AI 실무자는 모델 성능을 측정하고자 합니다. AI 실무자가 모델의 성능을 평가하는 데 도움이 되는 메트릭은 무엇인가요?
-> 혼동 매트릭스(행렬)
ㄴ 혼동 행렬은 모델에 의한 올바른 예측과 잘못된 예측에 대한 자세한 분석을 제공합니다. 여기에는 정확도, 정밀도, 리콜 및 F1 점수와 같은 다양한 성능 메트릭을 계산하는 데 사용할 수 있는 정탐, 정탐, 오탐 및 미탐이 포함됩니다.
   상관관계 매트릭스는 여러 변수 간의 의존성을 동시에 조사하는 데 사용되며, 분류 작업보다 회귀 분석에 더 적합합니다.
   R2 점수는 분류 모델이 아닌 회귀 모델을 평가하는 데 일반적으로 사용되는 지표
   평균 제곱 오차(MSE)는 오차 또는 편차의 제곱 평균을 측정하기 위해 회귀 작업에 사용되는 또 다른 메트릭

Q29. 한 회사에서 헬프 데스크의 질문에 답변하기 위해 대규모 언어 모델(LLM)을 미세 조정했습니다. 이 회사는 미세 조정으로 모델의 정확도가 향상되었는지 확인하고자 합니다. 이 회사는 어떤 메트릭을 평가에 사용해야 할까요?
-> F1 점수
ㄴ F1 점수는 질문 답변과 같은 자연어 처리(NLP) 작업에서 모델의 정확도와 회상률을 평가하기 위해 일반적으로 사용되는 지표

Q30. 한 디지털 디바이스 회사가 메모리 하드웨어에 대한 고객 수요를 예측하고자 합니다. 이 회사는 코딩 경험이나 ML 알고리즘에 대한 지식이 없으며 데이터 기반 예측 모델을 개발해야 합니다. 
이 회사는 내부 데이터와 외부 데이터에 대한 분석을 수행해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇인가요?
-> 아마존 세이지메이커 캔버스로 데이터를 가져옵니다. 세이지메이커 캔버스에서 데이터의 값을 선택하여 ML 모델 및 수요 예측 예측을 구축합니다.
ㄴ 이 시나리오에서는 코딩 경험이나 ML 알고리즘에 대한 지식이 없으므로 Amazon SageMaker의 기본 제공 알고리즘을 활용하여 ML 모델을 생성하는 것이 가장 좋습니다.
기본 제공 알고리즘을 통해 회사는 광범위한 코딩이나 알고리즘 지식 없이도 내부 및 외부 데이터에 대한 분석을 수행할 수 있습니다. 이 옵션은 데이터 기반 예측 모델 개발에 대한 회사의 요구 사항에 부합합니다.

Q31. 한 회사가 AI 검색 도구에 Amazon Bedrock의 기초 모델(FM)을 사용합니다. 이 회사는 회사의 데이터를 사용하여 모델을 더욱 정확하게 미세 조정하고자 합니다. 
어떤 전략이 모델을 성공적으로 미세 조정할 수 있을까요?
-> 프롬프트 필드와 완료 필드에 레이블이 지정된 데이터를 입력합니다.
ㄴ 회사의 데이터로 Amazon Bedrock의 기초 모델(FM)을 성공적으로 미세 조정하려면 프롬프트 필드와 완료 필드(1)가 있는 레이블이 지정된 데이터를 제공하는 것이 올바른 접근 방식

Q32. 한 회사에서 이미지로 자연어 질문에 응답할 수 있는 챗봇을 구축했습니다. 이 회사는 챗봇이 부적절하거나 원치 않는 이미지를 반환하지 않기를 원합니다. 이러한 요구 사항을 충족하는 솔ㄴ루션은 무엇인가요?
-> 모더레이션 API를 구현합니다
ㄴ 챗봇이 부적절하거나 원치 않는 이미지를 반환하지 않도록 하려면 회사는 모더레이션 API를 구현해야한다. 모더레이션 API는 민감하거나 부적절한 콘텐츠가 표시되는 것을 필터링하고 방지하는 데 도움이 될 수 있다.

Q33. 한 회사가 회사의 개인 데이터만을 기반으로 자체 대규모 언어 모델(LLM)을 구축해야 합니다. 이 회사는 학습 과정의 환경적 영향에 대해 우려하고 있습니다. LLM을 학습할 때 환경 영향이 가장 적은 Amazon EC2 인스턴스 유형은 무엇인가요?
-> Amazon EC2 Trn 시리즈
ㄴ 	G 시리즈는 GPU 가속 기능을 제공하여 그래픽 집약적인 애플리케이션에 적합, 3D 그래픽, 비디오 랜더링, 머신 러닝, 고급 비주얼 컴퓨팅에 유용
	Trn 시리즈는 AWS에서 제공하는 Trainium 칩을 기반으로 한 인스턴스 유형으로, 주로 딥러닝 모델 훈련에 최적화되어 있음, 높은 훈련 성능을 제공하며, 저비용으로 대규모 머신 러닝 훈련 작업을 처리할 수 있음
	P 시리즈는 고성능 머신 러닝, 딥러닝, 고급 과학적 시뮬레이션 및 이미지 및 비디오 처리에 사용, 훈련 및 추론을 위한 대규모 AI 모델에 적합
	C 시리즈는 컴퓨팅 성능을 최적화한 인스턴스로, CPU 집약적인 작업에 적합, 높은 계산 성능을 요구하는 웹 서버, 배치 처리 작업, 게임 서버, 과학적 모델링 및 데이터 분석과 같은 워크로드에 유리함
	문제에선 LLM을 학습할 때 환경 영향이 가장 적은 인스턴스를 고르라 하였으니 환경적 영향을 최소화 하는 에너지 효율에 최적화된 인스턴스인 Trn 시리즈가 정답

Q34. 한 회사에서 언어 모델을 사용하여 엣지 디바이스에서 추론을 위한 애플리케이션을 만들고자 합니다. 추론은 가능한 한 가장 짧은 지연 시간을 가져야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇일까요?
-> 엣지 디바이스에 최적화된 소규모 언어 모델(SLM)을 배포하세요.
ㄴ 엣지 장치에서 추론 대기 시간을 최대한 낮추려면 엣지 장치에 최적화된 소규모 언어 모델(SLM)을 배포하는 것이 가장 좋은 해결책, 
   엣지 디바이스에 소규모 언어 모델을 배포하면 계산 부하와 메모리 요구 사항이 줄어들어 대규모 모델에 비해 지연 시간이 짧고 추론 시간이 빨라짐
   엣지 장치에 최적화된 대규모 언어 모델(LLM)을 배포하면 계산 복잡성과 리소스 요구 사항이 증가하여 지연 시간이 늘어날 수 있음
   엣지 디바이스와의 비동기 통신은 그냥 오답

Q35. 한 회사에서 감정 분석을 위해 Amazon Bedrock의 대규모 언어 모델(LLM)을 사용하려고 합니다. 이 회사는 동일한 입력 프롬프트에 대해 보다 일관된 응답을 생성하기 위해 LLM이 필요합니다.
이러한 요구 사항을 충족하려면 추론 매개 변수에 어떤 조정을 해야 하나요?
-> 온도 값을 낮춥니다.
ㄴ 동일한 입력 프롬프트에 대해 보다 일관된 응답을 얻으려면 Amazon Bedrock의 대규모 언어 모델(LLM)의 추론 매개 변수에서 온도 값을 낮춰야함

Q36. 한 AI 실무자가 기밀 데이터가 포함된 학습 데이터 세트를 사용하여 Amazon Bedrock에서 사용자 지정 모델을 학습시켰습니다.
AI 실무자는 사용자 지정 모델이 기밀 데이터를 기반으로 추론 응답을 생성하지 않도록 하고 싶습니다. AI 실무자가 기밀 데이터에 기반한 응답을 방지하려면 어떻게 해야 하나요?
-> 사용자 지정모델을 삭제합니다. 학습 데이터 세트에서 기밀 데이터를 제거합니다. 사용자 지정 모델을 다시 학습시킵니다.
ㄴ 사용자 지정 모델을 삭제하는 것은 기밀 데이터가 포함된 추론 응답이 생성되지 않도록 하는 포괄적인 방법
   기밀 데이터 없이 사용자 지정 모델을 재학습하면 향후 예측에서 모델이 기밀 데이터의 영향을 받지 않음

Q37. 한 AI 실무자가 다양한 직업에 종사하는 사람의 이미지를 생성하는 모델을 구축하고 있습니다. AI 실무자는 입력 데이터가 편향되어 있으며 특정 속성이 이미지 생성에 영향을 미치고 모델에 편향성을 발생시킨다는 사실을 발견했습니다.
어떤 기술로 문제를 해결할 수 있을까요?
-> 불균형한 클래스를 위한 데이터 보강
ㄴ RAG? 이건 스터디 타입으로 풀어보고 피드백 보내는걸로 키워드는 Data augmentation for imbalanced classes / Retrieval Augmented Generation (RAG) 두개
   문제 해설이 여전히 RAG가 답이라고 하지만 답은 불균형한 클래스를 위한 데이터 보강으로 나온다 / 아마 써티빌더 해설이 잘못 된 듯? 지피티도 불균형한 클래스를 위한 데이터 보강이 답이라고 하긴 하니

Q38. 한 회사가 고객 서비스 챗봇을 구축하고 있습니다. 이 회사는 챗봇이 과거의 상호작용과 온라인 리소스를 통해 학습하여 응답을 개선하기를 원합니다. 이러한 자기 개선 기능을 제공하는 AI 학습 전략은 무엇인가요?
-> 긍정적인 고객 피드백에 대한 보상을 통한 강화 학습
ㄴ 강화 학습은 바람직한 행동에 보상을 제공함으로써 일련의 결정을 내리도록 AI 모델을 훈련시키는 것
   이 접근 방식을 사용하면 챗봇이 과거 상호작용을 통해 학습하고 받은 피드백에 따라 행동을 조정함으로써 시간이 지남에 따라 응답을 개선할 수 있음

Q39. 한 회사에서 직원들이 진행 중인 고객 클레임을 확인하고, 특정 클레임의 세부 정보를 식별하고, 클레임 관련 문서에 액세스 할 수 있도록 지원하는 AI 애플리케이션을 개발하려고 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇인가요?
-> 아마존 베드락용 에이전트와 아마존 베드락 지식 기반을 사용하여 애플리케이션을 구축하세요.
ㄴ Amazon Bedrock용 에이전트를 사용하면 대화형 인터페이스와 챗봇을 만들어 직원들이 진행 중인 고객 클레임을 확인하고, 특정 클레임의 세부 정보를 식별하고, 클레임에 대한 문서에 액세스하는 데 도움을 줄 수 있습니다.
   Amazon Bedrock 지식 기반을 통합하면 정보를 저장하고 검색하는 구조화된 방법을 제공하여 AI 애플리케이션의 기능을 향상시킬 수 있습니다.

Q40. 한 회사에서 기존 데이터를 기반으로 합성 데이터를 생성해야 하는 애플리케이션을 구축하고 있습니다. 이 요구사항을 충족하기 위해 어떤 유형의 모델을 사용할 수 있을까요?
-> 생성적 적대적 네트워크(GAN)
ㄴ 생성적 적대 신경망(GAN)은 주어진 데이터 세트와 유사한 새로운 데이터 인스턴스를 생성할 수 있는 신경망 아키텍처의 한 유형,
   GAN은 일반적으로 주어진 데이터 세트에서 새로운 샘플을 생성하는 이미지 생성, 데이터 생성, 콘텐츠 생성과 같은 작업에 사용